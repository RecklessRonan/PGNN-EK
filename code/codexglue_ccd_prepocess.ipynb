{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import javalang\n",
    "from tqdm import tqdm\n",
    "from javalang.ast import Node"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_code_url = '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/data.jsonl'\n",
    "train_url = '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/train.txt'\n",
    "test_url = '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/test.txt'\n",
    "valid_url = '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/valid.txt' "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_code = pd.read_json(path_or_buf=raw_code_url, lines=True)\n",
    "raw_code.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# use javalang to generate ASTs and depth-first traverse to generate ast nodes corpus\n",
    "def get_token(node):\n",
    "    token = ''\n",
    "    if isinstance(node, str):\n",
    "        token = node\n",
    "    elif isinstance(node, set):\n",
    "        token = 'Modifier'\n",
    "    elif isinstance(node, Node):\n",
    "        token = node.__class__.__name__\n",
    "    return token\n",
    "\n",
    "\n",
    "def get_child(root):\n",
    "    if isinstance(root, Node):\n",
    "        children = root.children\n",
    "    elif isinstance(root, set):\n",
    "        children = list(root)\n",
    "    else:\n",
    "        children = []\n",
    "\n",
    "    def expand(nested_list):\n",
    "        for item in nested_list:\n",
    "            if isinstance(item, list):\n",
    "                for sub_item in expand(item):\n",
    "                    yield sub_item\n",
    "            elif item:\n",
    "                yield item\n",
    "\n",
    "    return list(expand(children))\n",
    "\n",
    "\n",
    "def get_sequence(node, sequence):\n",
    "    token, children = get_token(node), get_child(node)\n",
    "    sequence.append(token)\n",
    "    for child in children:\n",
    "        get_sequence(child, sequence)\n",
    "\n",
    "\n",
    "def parse_program(func):\n",
    "    tokens = javalang.tokenizer.tokenize(func)\n",
    "    parser = javalang.parser.Parser(tokens)\n",
    "    tree = parser.parse_member_declaration()\n",
    "    return tree"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "syntax_error_indices = []\n",
    "syntax_error_ids = []\n",
    "nodes_num = []\n",
    "tree_list = []\n",
    "for i in tqdm(range(len(raw_code))):\n",
    "    try:        \n",
    "        tree = parse_program(raw_code['func'][i])\n",
    "        tree_list.append(tree)\n",
    "    except:\n",
    "        syntax_error_indices.append(i)\n",
    "        syntax_error_ids.append(raw_code['idx'][i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "syntax_error_ids"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "node_nums = [ ]\n",
    "over_1000_ids = [ ]\n",
    "for i in range(len(tree_list)):\n",
    "    sequence = []\n",
    "    get_sequence(tree_list[i], sequence)\n",
    "    node_nums.append(len(sequence))\n",
    "\n",
    "    if len(sequence) > 1000:\n",
    "        over_1000_ids.append(raw_code['idx'][i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(over_1000_ids)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_code = raw_code.set_index('idx')\n",
    "raw_code_index = raw_code.index.tolist()\n",
    "\n",
    "def read_ccd_pairs(url):\n",
    "    data = []\n",
    "    with open(url) as f:\n",
    "        for line in tqdm(f):\n",
    "            line = line.strip()\n",
    "            id1, id2, label = line.split('\\t')\n",
    "            if int(id1) not in raw_code_index or int(id2) not in raw_code_index or int(id1) in over_1000_ids or int(id2) in over_1000_ids:\n",
    "                continue\n",
    "            label = 0 if label == '0' else 1\n",
    "            data.append((int(id1), int(id2), label))\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data = read_ccd_pairs(train_url)\n",
    "valid_data = read_ccd_pairs(valid_url)\n",
    "test_data = read_ccd_pairs(test_url)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(train_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(valid_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(test_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}