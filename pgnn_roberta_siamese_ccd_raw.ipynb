{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import yaml\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd \n",
    "import javalang\n",
    "from javalang.ast import Node\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import (Module, Embedding, LSTM, Sequential, Linear, BatchNorm1d, ReLU, Sigmoid, CrossEntropyLoss, TransformerDecoderLayer,\n",
    "                        TransformerDecoder)\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn.glob import GlobalAttention\n",
    "from torch_geometric.nn import MessagePassing, GatedGraphConv, GCNConv, global_mean_pool, GINEConv, global_add_pool\n",
    "from anytree import AnyNode\n",
    "from torch_geometric.data import Data, DataLoader, ClusterData, ClusterLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import random\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel, DataCollatorWithPadding, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, SequentialSampler, RandomSampler\n",
    "import json\n",
    "from codebert_seq2seq3 import Seq2Seq\n",
    "import bleu\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "config_file = 'config_dgnn.yml'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "config = yaml.load(open(config_file), Loader=yaml.FullLoader)\n",
    "\n",
    "# data source\n",
    "TRAIN_DIR = config['tlc_data']['train']\n",
    "VALID_DIR = config['tlc_data']['valid']\n",
    "TEST_DIR = config['tlc_data']['test']\n",
    "\n",
    "\n",
    "# prepocess design\n",
    "max_source_length = config['preprocess']['max_source_length']\n",
    "max_target_length = config['preprocess']['max_target_length']\n",
    "\n",
    "\n",
    "# training parameter\n",
    "batch_size = config['training']['batch_size']\n",
    "num_epoches = config['training']['num_epoches']\n",
    "lr = config['training']['lr']\n",
    "decay_ratio = config['training']['lr']\n",
    "save_name = config['training']['save_name']\n",
    "warm_up = config['training']['warm_up']\n",
    "patience = config['training']['patience']\n",
    "\n",
    "# model design\n",
    "graph_embedding_size = config['model']['graph_embedding_size']\n",
    "lstm_hidden_size = config['model']['lstm_hidden_size']\n",
    "divide_node_num = config['model']['divide_node_num']\n",
    "gnn_layers_num = config['model']['gnn_layers_num']\n",
    "lstm_layers_num = config['model']['lstm_layers_num']\n",
    "decoder_input_size = config['model']['decoder_input_size']\n",
    "decoder_hidden_size = config['model']['decoder_hidden_size']\n",
    "decoder_num_layers = config['model']['decoder_num_layers']\n",
    "decoder_rnn_dropout = config['model']['decoder_rnn_dropout']\n",
    "siamese_input_size = config['model']['siamese_input_size']\n",
    "\n",
    "# logs\n",
    "info_prefix = config['logs']['info_prefix']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "MAX_NODE_NUM = 450 # the max num of subgraph, set for zero padding \n",
    "max_subgraph_num = int(MAX_NODE_NUM/divide_node_num) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "run_id = datetime.now().strftime('%Y-%m-%d--%H-%M-%S')\n",
    "log_file = 'logs/' + run_id + '.log'\n",
    "exp_dir = 'runs/' + run_id\n",
    "os.mkdir(exp_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class Info(object):\n",
    "    def __init__(self, info_prefix=''):\n",
    "        self.info_prefix = info_prefix\n",
    "    \n",
    "    def print_msg(self, msg):\n",
    "        text = self.info_prefix + ' ' + msg\n",
    "        print(text)\n",
    "        logging.info(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "logging.basicConfig(format='%(asctime)s | %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', filename=log_file, level=logging.DEBUG)\n",
    "msgr = Info(info_prefix)\n",
    "\n",
    "msgr.print_msg('run_id : {}'.format(run_id))\n",
    "msgr.print_msg('log_file : {}'.format(log_file))\n",
    "msgr.print_msg('exp_dir: {}'.format(exp_dir))\n",
    "msgr.print_msg(str(config))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dgnn run_id : 2021-08-27--12-08-40\n",
      "dgnn log_file : logs/2021-08-27--12-08-40.log\n",
      "dgnn exp_dir: runs/2021-08-27--12-08-40\n",
      "dgnn {'data': {'train': '/data/code/represent-code-in-human/data/code-summarization-enhanced-full/train_utf8.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-enhanced-full/valid_utf8.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-enhanced-full/test_utf8.jsonl'}, 'tlc_data': {'train': '/data/code/represent-code-in-human/data/TLC-SUM-enhanced/train.jsonl', 'valid': '/data/code/represent-code-in-human/data/TLC-SUM-enhanced/valid.jsonl', 'test': '/data/code/represent-code-in-human/data/TLC-SUM-enhanced/test.jsonl'}, 'small_data': {'train': '/data/code/represent-code-in-human/data/code-summarization-enhanced-small/train_utf8.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-enhanced-small/valid_utf8.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-enhanced-small/test_utf8.jsonl'}, 'middle_data': {'train': '/data/code/represent-code-in-human/data/code-summarization-enhanced-middle/train_utf8.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-enhanced-middle/valid_utf8.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-enhanced-middle/test_utf8.jsonl'}, 'ccd_data': {'data': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/data.jsonl', 'train': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/train.txt', 'valid': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/test.txt', 'test': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/valid.txt'}, 'ccd_f_data': {'data': '/data/pycharm/BCB2015/BCB_F/function_out_split/data.jsonl', 'train': '/data/pycharm/BCB2015/BCB_F/function_out_split/train.txt', 'valid': '/data/pycharm/BCB2015/BCB_F/function_out_split/test.txt', 'test': '/data/pycharm/BCB2015/BCB_F/function_out_split/valid.txt'}, 'preprocess': {'max_source_length': 256, 'max_target_length': 32}, 'training': {'batch_size': 128, 'num_epoches': 100, 'lr': 0.001, 'decay_ratio': 0.95, 'save_name': '/model.pth', 'warm_up': 5, 'patience': 10}, 'model': {'graph_embedding_size': 768, 'gnn_layers_num': 3, 'lstm_layers_num': 2, 'lstm_hidden_size': 768, 'divide_node_num': 30, 'decoder_input_size': 768, 'decoder_hidden_size': 128, 'decoder_num_layers': 2, 'decoder_rnn_dropout': 0.5, 'gine_dim': 128, 'siamese_input_size': 768}, 'logs': {'info_prefix': 'dgnn'}}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "checkpoint = 'microsoft/codebert-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(checkpoint)\n",
    "ast_tokenizer = RobertaTokenizer.from_pretrained(checkpoint)\n",
    "roberta = RobertaModel.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "roberta_config = RobertaConfig.from_pretrained(checkpoint)\n",
    "javalang_special_tokens = ['CompilationUnit','Import','Documented','Declaration','TypeDeclaration','PackageDeclaration',\n",
    "                            'ClassDeclaration','EnumDeclaration','InterfaceDeclaration','AnnotationDeclaration','Type',\n",
    "                            'BasicType','ReferenceType','TypeArgument','TypeParameter','Annotation','ElementValuePair',\n",
    "                            'ElementArrayValue','Member','MethodDeclaration','FieldDeclaration','ConstructorDeclaration',\n",
    "                            'ConstantDeclaration','ArrayInitializer','VariableDeclaration','LocalVariableDeclaration',\n",
    "                            'VariableDeclarator','FormalParameter','InferredFormalParameter','Statement','IfStatement',\n",
    "                            'WhileStatement','DoStatement','ForStatement','AssertStatement','BreakStatement','ContinueStatement',\n",
    "                            'ReturnStatement','ThrowStatement','SynchronizedStatement','TryStatement','SwitchStatement',\n",
    "                            'BlockStatement','StatementExpression','TryResource','CatchClause','CatchClauseParameter',\n",
    "                            'SwitchStatementCase','ForControl','EnhancedForControl','Expression','Assignment','TernaryExpression',\n",
    "                            'BinaryOperation','Cast','MethodReference','LambdaExpression','Primary','Literal','This',\n",
    "                            'MemberReference','Invocation','ExplicitConstructorInvocation','SuperConstructorInvocation',\n",
    "                            'MethodInvocation','SuperMethodInvocation','SuperMemberReference','ArraySelector','ClassReference',\n",
    "                            'VoidClassReference','Creator','ArrayCreator','ClassCreator','InnerClassCreator','EnumBody',\n",
    "                            'EnumConstantDeclaration','AnnotationMethod', 'Modifier']\n",
    "special_tokens_dict = {'additional_special_tokens': javalang_special_tokens}\n",
    "num_added_toks = ast_tokenizer.add_special_tokens(special_tokens_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class PairData(Data):\n",
    "    def __init__(self, edge_index_s, edge_attr_s, x_s, source_ids_s, subgraph_node_num_s, real_graph_num_s,\n",
    "                    edge_index_t, edge_attr_t, x_t, source_ids_t, subgraph_node_num_t, real_graph_num_t,label):\n",
    "        super(PairData, self).__init__()\n",
    "        self.edge_index_s = edge_index_s\n",
    "        self.edge_attr_s = edge_attr_s\n",
    "        self.x_s = x_s\n",
    "        self.source_ids_s = source_ids_s\n",
    "        self.subgraph_node_num_s = subgraph_node_num_s\n",
    "        self.real_graph_num_s = real_graph_num_s\n",
    "\n",
    "        self.edge_index_t = edge_index_t\n",
    "        self.edge_attr_t = edge_attr_t\n",
    "        self.x_t = x_t\n",
    "        self.source_ids_t = source_ids_t\n",
    "        self.subgraph_node_num_t = subgraph_node_num_t\n",
    "        self.real_graph_num_t = real_graph_num_t\n",
    "\n",
    "        self.label = label\n",
    "    \n",
    "    def __inc__(self, key, value):\n",
    "        if key == 'edge_index_s':\n",
    "            return self.x_s.size(0)\n",
    "        if key == 'edge_index_t':\n",
    "            return self.x_t.size(0)\n",
    "        else:\n",
    "            return super().__inc__(key, value)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_features = torch.load('features/bcb-raw/train_features.pt')\n",
    "valid_features = torch.load('features/bcb-raw/valid_features.pt')\n",
    "test_features = torch.load('features/bcb-raw/test_features.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class GNNEncoder(Module):\n",
    "    def __init__(self, vocab_len, graph_embedding_size, gnn_layers_num, lstm_layers_num, lstm_hidden_size, decoder_input_size, device):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.embeddings = Embedding(vocab_len, graph_embedding_size)\n",
    "        self.edge_embed = Embedding(4, 1) # only two edge types to be set weights, which are AST edge and data flow edge\n",
    "        self.ggnnlayer = GatedGraphConv(graph_embedding_size, gnn_layers_num)\n",
    "        self.mlp_gate = Sequential(\n",
    "            Linear(graph_embedding_size, 300), Sigmoid(), Linear(300, 1), Sigmoid())\n",
    "        self.pool = GlobalAttention(gate_nn=self.mlp_gate)\n",
    "        self.lstm = LSTM(input_size=graph_embedding_size, hidden_size=lstm_hidden_size, num_layers=lstm_layers_num)\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_layers_num = lstm_layers_num\n",
    "        self.fc = Linear(graph_embedding_size + lstm_hidden_size, decoder_input_size)\n",
    "\n",
    "    def subgraph_forward(self, x, edge_index, edge_attr, batch):\n",
    "        if type(edge_attr) == type(None):\n",
    "            edge_weight = None\n",
    "        else:\n",
    "            edge_weight = self.edge_embed(edge_attr)\n",
    "            edge_weight = edge_weight.squeeze(1)\n",
    "        x = self.ggnnlayer(x, edge_index, edge_weight)\n",
    "        return self.pool(x, batch=batch)\n",
    "    \n",
    "    # partitioning multiple subgraphs by dynamic allocating edges\n",
    "    def partition_graph(self, x, edge_index, edge_attr, subgraph_node_num, real_graph_num, ptr):        \n",
    "        nodes_list = [] # record all nodes number for each subgraph in total batch\n",
    "        subgraph_num = max(real_graph_num)\n",
    "        batch_size = subgraph_node_num.size(0)\n",
    "        start_node_num = [1 for _ in range(batch_size)]\n",
    "        for i in range(subgraph_num):\n",
    "            subgraph_nodes_list = []\n",
    "            for j in range(batch_size):\n",
    "                if subgraph_node_num[j][i] != 0:\n",
    "                    for k in range(ptr[j]+start_node_num[j], ptr[j]+start_node_num[j]+subgraph_node_num[j][i]):\n",
    "                        subgraph_nodes_list.append(k)\n",
    "                    start_node_num[j] += subgraph_node_num[j][i]\n",
    "            nodes_list.append(subgraph_nodes_list)\n",
    "\n",
    "        # only count the edge whose target node in subgraph\n",
    "        sub_edge_src = [[] for _ in range(subgraph_num)]\n",
    "        sub_edge_tgt = [[] for _ in range(subgraph_num)]\n",
    "        sub_edge_attr = [[] for _ in range(subgraph_num)]\n",
    "        # print('nodes_list', nodes_list)\n",
    "        node_num = len(x)\n",
    "        node_subgraph_index = [0 for _ in range(node_num)] # use a list to store the subgraph numbers for all nodes\n",
    "        for i in range(len(nodes_list)):\n",
    "            for node in nodes_list[i]:\n",
    "                node_subgraph_index[node] = i\n",
    "\n",
    "        for i in range(len(edge_index[1])):\n",
    "            src = edge_index[0][i].item()\n",
    "            tgt = edge_index[1][i].item()\n",
    "            sub_edge_src[node_subgraph_index[tgt]].append(src)\n",
    "            sub_edge_tgt[node_subgraph_index[tgt]].append(tgt)\n",
    "            sub_edge_attr[node_subgraph_index[tgt]].append(edge_attr[i].item())\n",
    "        edge_index_list = []\n",
    "        edge_attr_list = []\n",
    "        for i in range(subgraph_num):\n",
    "            edge_index_list.append(torch.tensor([sub_edge_src[i], sub_edge_tgt[i]], dtype=torch.long))\n",
    "            edge_attr_list.append(torch.tensor(sub_edge_attr[i], dtype=torch.long))\n",
    "        # print('nodes_list', nodes_list)\n",
    "        return edge_index_list, edge_attr_list  \n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, subgraph_node_num, real_graph_num, batch, ptr):\n",
    "        edge_index_list, edge_attr_list = self.partition_graph(x, edge_index, edge_attr, subgraph_node_num, real_graph_num, ptr)\n",
    "        # print('edge_index_list', edge_index_list)\n",
    "        # print('edge_attr_list', edge_attr_list)\n",
    "        x = self.embeddings(x)\n",
    "        x = x.squeeze(1)\n",
    "        subgraph_pool_list = [\n",
    "            self.subgraph_forward(x, edge_index_list[i].to(self.device), edge_attr_list[i].to(self.device), batch)\n",
    "            for i in range(len(edge_index_list))\n",
    "        ]\n",
    "        graph_pool = self.subgraph_forward(x, edge_index, edge_attr, batch)\n",
    "        # print('graph_pool', graph_pool.shape)\n",
    "        subgraph_pool_seq = torch.stack(subgraph_pool_list)\n",
    "        # print('subgraph_pool_seq', subgraph_pool_seq.shape)\n",
    "        h0 = torch.zeros(self.lstm_layers_num, subgraph_pool_seq.size(1) ,self.lstm_hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.lstm_layers_num, subgraph_pool_seq.size(1) ,self.lstm_hidden_size).to(self.device)\n",
    "        subgraph_output, (_, _) = self.lstm(subgraph_pool_seq, (h0, c0))\n",
    "        return self.fc(torch.cat((subgraph_output[-1], graph_pool), dim=1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class MixEncoder(Module):\n",
    "    def __init__(self, gnn_encoder, roberta, decoder_input_size, hidden_size, siamese_input_size):\n",
    "        super(MixEncoder, self).__init__()\n",
    "        self.gnn_encoder = gnn_encoder\n",
    "        self.roberta = roberta\n",
    "        self.fc = Linear(decoder_input_size + hidden_size, siamese_input_size)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, subgraph_node_num, real_graph_num, batch, ptr, source_ids, source_mask):\n",
    "        output1 = self.gnn_encoder(x, edge_index, edge_attr, subgraph_node_num, real_graph_num, batch, ptr)\n",
    "        output2 = self.roberta(source_ids, source_mask).pooler_output\n",
    "        output = torch.cat((output1, output2), dim=1)\n",
    "        return self.fc(output)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "class Model(Module):\n",
    "    def __init__(self, mix_encoder, siamese_input_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.mix_encoder = mix_encoder\n",
    "        self.fc1 = Linear(2 * siamese_input_size, siamese_input_size)\n",
    "        self.fc2 = Linear(siamese_input_size, 2)\n",
    "    \n",
    "    def forward(self, x1, edge_index1, edge_attr1, subgraph_node_num1, real_graph_num1, batch1, ptr1, source_ids1, source_mask1,\n",
    "                x2, edge_index2, edge_attr2, subgraph_node_num2, real_graph_num2, batch2, ptr2, source_ids2, source_mask2):\n",
    "        output1 = self.mix_encoder(x1, edge_index1, edge_attr1, subgraph_node_num1, real_graph_num1, batch1, ptr1, source_ids1, source_mask1)\n",
    "        output2 = self.mix_encoder(x2, edge_index2, edge_attr2, subgraph_node_num2, real_graph_num2, batch2, ptr2, source_ids2, source_mask2)\n",
    "        output = torch.cat((output1, output2), dim=1)\n",
    "        output = self.fc1(output)\n",
    "        output = self.fc2(output)\n",
    "        return output   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "max_source_length = 400\n",
    "batch_size = 4\n",
    "lr = 5e-5\n",
    "warmup_steps = 0\n",
    "train_steps = 500000\n",
    "weight_decay = 0.0\n",
    "adam_epsilon = 1e-8\n",
    "valid_loss_steps = 5000\n",
    "output_dir = exp_dir"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "device = torch.device('cuda:0')\n",
    "gnn_encoder = GNNEncoder(vocab_len=tokenizer.vocab_size+num_added_toks, graph_embedding_size=graph_embedding_size,\n",
    "                         gnn_layers_num=gnn_layers_num, lstm_layers_num=lstm_layers_num, lstm_hidden_size=lstm_hidden_size,\n",
    "                        decoder_input_size=decoder_input_size, device=device)\n",
    "mix_encoder = MixEncoder(gnn_encoder=gnn_encoder, roberta=roberta, decoder_input_size=decoder_input_size, \n",
    "                         hidden_size=roberta_config.hidden_size, siamese_input_size=siamese_input_size)\n",
    "model = Model(mix_encoder=mix_encoder, siamese_input_size=siamese_input_size)\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Model(\n",
       "  (mix_encoder): MixEncoder(\n",
       "    (gnn_encoder): GNNEncoder(\n",
       "      (embeddings): Embedding(50336, 768)\n",
       "      (edge_embed): Embedding(4, 1)\n",
       "      (ggnnlayer): GatedGraphConv(768, num_layers=3)\n",
       "      (mlp_gate): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=300, bias=True)\n",
       "        (1): Sigmoid()\n",
       "        (2): Linear(in_features=300, out_features=1, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "      (pool): GlobalAttention(gate_nn=Sequential(\n",
       "        (0): Linear(in_features=768, out_features=300, bias=True)\n",
       "        (1): Sigmoid()\n",
       "        (2): Linear(in_features=300, out_features=1, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      ), nn=None)\n",
       "      (lstm): LSTM(768, 768, num_layers=2)\n",
       "      (fc): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    )\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=1536, out_features=768, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=1536, out_features=768, bias=True)\n",
       "  (fc2): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# optimizer and schedule\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': weight_decay},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=adam_epsilon)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=5000,\n",
    "#                                             num_training_steps=30000)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=train_steps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "train_dataloader = DataLoader(train_features, batch_size=batch_size, shuffle=True, follow_batch=['x_s', 'x_t'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def get_ptr_from_batch(batch):\n",
    "#     print(batch[-1])\n",
    "    ptr = [batch.tolist().index(i) for i in range(batch[-1] + 1)]\n",
    "    ptr.append(batch.size(0))\n",
    "    return torch.tensor(ptr, dtype=torch.long)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from itertools import cycle\n",
    "\n",
    "#Start training\n",
    "msgr.print_msg(\"***** Running training *****\")\n",
    "msgr.print_msg(\"  Num examples = {}\".format(len(train_features)))\n",
    "msgr.print_msg(\"  Batch size = {}\".format(batch_size))\n",
    "msgr.print_msg(\"  lr= {}\".format(lr))\n",
    "msgr.print_msg(\"  Num epoch = {}\".format(batch_size//len(train_features)))\n",
    "model.train()\n",
    "nb_tr_examples, nb_tr_steps, tr_loss, global_step, best_f1, best_loss = 0, 0, 0, 0, 0, 1e6\n",
    "bar = tqdm(range(train_steps), total=train_steps)\n",
    "train_dataloader = cycle(train_dataloader)\n",
    "loss_func = CrossEntropyLoss()\n",
    "\n",
    "for step in bar:\n",
    "    data = next(train_dataloader)\n",
    "    data = data.to(device)\n",
    "    x1 = data.x_s\n",
    "    edge_index1 = data.edge_index_s\n",
    "    edge_attr1 = data.edge_attr_s    \n",
    "    subgraph_node_num1 = torch.stack(torch.split(data.subgraph_node_num_s, max_subgraph_num))\n",
    "    real_graph_num1 = torch.stack(torch.split(data.real_graph_num_s, 1))\n",
    "    source_ids1 = torch.stack(torch.split(data.source_ids_s, max_source_length))\n",
    "    source_mask1 = torch.stack(torch.split(data.source_ids_s.ne(1), max_source_length))\n",
    "    batch1 = data.x_s_batch\n",
    "    ptr1 = get_ptr_from_batch(batch1).to(device)\n",
    "\n",
    "    x2 = data.x_t\n",
    "    edge_index2 = data.edge_index_t\n",
    "    edge_attr2 = data.edge_attr_t    \n",
    "    subgraph_node_num2 = torch.stack(torch.split(data.subgraph_node_num_t, max_subgraph_num))\n",
    "    real_graph_num2 = torch.stack(torch.split(data.real_graph_num_t, 1))\n",
    "    source_ids2 = torch.stack(torch.split(data.source_ids_t, max_source_length))\n",
    "    source_mask2 = torch.stack(torch.split(data.source_ids_t.ne(1), max_source_length))\n",
    "    batch2 = data.x_t_batch\n",
    "    ptr2 = get_ptr_from_batch(batch2).to(device)\n",
    "\n",
    "    probs = model(x1, edge_index1, edge_attr1, subgraph_node_num1, real_graph_num1, batch1, ptr1, source_ids1, source_mask1,\n",
    "                x2, edge_index2, edge_attr2, subgraph_node_num2, real_graph_num2, batch2, ptr2, source_ids2, source_mask2)\n",
    "    loss = loss_func(probs, data.label)\n",
    "#     print('probs', probs)\n",
    "#     print('labels', data.label)\n",
    "    tr_loss += loss.item()\n",
    "#     print('loss', loss.item())\n",
    "    train_loss = round(tr_loss / (nb_tr_steps + 1), 4)\n",
    "    bar.set_description('loss {}'.format(train_loss))\n",
    "    nb_tr_examples += data.label.size(0)\n",
    "    nb_tr_steps += 1\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    scheduler.step()\n",
    "    global_step += 1\n",
    "\n",
    "    if (global_step + 1) % valid_loss_steps == 0:\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        valid_sampler = RandomSampler(valid_features, replacement=True, num_samples=10000)\n",
    "        valid_dataloader = DataLoader(valid_features, sampler=valid_sampler, batch_size=batch_size, follow_batch=['x_s', 'x_t'])\n",
    "        msgr.print_msg(\"\\n***** Running evaluation *****\")\n",
    "        msgr.print_msg(\"  Num examples = {}\".format(len(valid_features)))\n",
    "        msgr.print_msg(\"  Batch size = {}\".format(batch_size))\n",
    "\n",
    "\n",
    "        #Start Evaling model\n",
    "        model.eval()\n",
    "        valid_loss, tokens_num = 0, 10000\n",
    "        logits = []\n",
    "        y_trues = []\n",
    "        for data in valid_dataloader:\n",
    "            data = data.to(device)\n",
    "            x1 = data.x_s\n",
    "            edge_index1 = data.edge_index_s\n",
    "            edge_attr1 = data.edge_attr_s    \n",
    "            subgraph_node_num1 = torch.stack(torch.split(data.subgraph_node_num_s, max_subgraph_num))\n",
    "            real_graph_num1 = torch.stack(torch.split(data.real_graph_num_s, 1))\n",
    "            source_ids1 = torch.stack(torch.split(data.source_ids_s, max_source_length))\n",
    "            source_mask1 = torch.stack(torch.split(data.source_ids_s.ne(1), max_source_length))\n",
    "            batch1 = data.x_s_batch\n",
    "            ptr1 = get_ptr_from_batch(batch1).to(device)\n",
    "\n",
    "            x2 = data.x_t\n",
    "            edge_index2 = data.edge_index_t\n",
    "            edge_attr2 = data.edge_attr_t    \n",
    "            subgraph_node_num2 = torch.stack(torch.split(data.subgraph_node_num_t, max_subgraph_num))\n",
    "            real_graph_num2 = torch.stack(torch.split(data.real_graph_num_t, 1))\n",
    "            source_ids2 = torch.stack(torch.split(data.source_ids_t, max_source_length))\n",
    "            source_mask2 = torch.stack(torch.split(data.source_ids_t.ne(1), max_source_length))\n",
    "            batch2 = data.x_t_batch\n",
    "            ptr2 = get_ptr_from_batch(batch2).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                probs = model(x1, edge_index1, edge_attr1, subgraph_node_num1, real_graph_num1, batch1, ptr1, source_ids1, source_mask1,\n",
    "                                x2, edge_index2, edge_attr2, subgraph_node_num2, real_graph_num2, batch2, ptr2, source_ids2, source_mask2)\n",
    "            loss = loss_func(probs, data.label)\n",
    "            probs = F.softmax(probs)\n",
    "            logits.append(probs.cpu().numpy())\n",
    "            y_trues.append(data.label.cpu().numpy())\n",
    "            valid_loss += loss.item()\n",
    "        valid_loss /= tokens_num\n",
    "        result = { 'valid_loss': valid_loss,\n",
    "                    'global_step': global_step+1,\n",
    "                    'train_loss': round(train_loss, 5)}\n",
    "        for key in sorted(result.keys()):\n",
    "            msgr.print_msg(\"{}= {}\".format(key, str(result[key])))\n",
    "        msgr.print_msg(\"  \"+\"*\"*20)   \n",
    "\n",
    "        #save last checkpoint\n",
    "        last_output_dir = os.path.join(output_dir, 'checkpoint-last')\n",
    "        if not os.path.exists(last_output_dir):\n",
    "            os.makedirs(last_output_dir)\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "        output_model_file = os.path.join(last_output_dir, \"pytorch_model.bin\")\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        if valid_loss < best_loss:\n",
    "            msgr.print_msg(\"  Best valid_loss:{}\".format(valid_loss))\n",
    "            msgr.print_msg(\"  \" + \"*\" * 20)\n",
    "            best_loss = valid_loss\n",
    "            # Save best checkpoint for best loss\n",
    "            best_output_dir = os.path.join(output_dir, 'checkpoint-best-loss')\n",
    "            if not os.path.exists(best_output_dir):\n",
    "                os.makedirs(best_output_dir)\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "            output_model_file = os.path.join(best_output_dir, \"pytorch_model.bin\")\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)  \n",
    "\n",
    "\n",
    "        logits=np.concatenate(logits,0)\n",
    "        y_trues=np.concatenate(y_trues,0)\n",
    "#         msgr.print_msg(\"logits: {}\".format(logits[0:100]))\n",
    "#         msgr.print_msg(\"y_trues: {}\".format(y_trues[0:100]))\n",
    "        best_threshold=0\n",
    "        best_f1=0\n",
    "        for i in range(1,100):\n",
    "            threshold=i/100\n",
    "            y_preds=logits[:,1]>threshold\n",
    "            from sklearn.metrics import recall_score\n",
    "            recall=recall_score(y_trues, y_preds, average='macro')\n",
    "            from sklearn.metrics import precision_score\n",
    "            precision=precision_score(y_trues, y_preds, average='macro')   \n",
    "            from sklearn.metrics import f1_score\n",
    "            f1=f1_score(y_trues, y_preds, average='macro') \n",
    "            if f1>best_f1:\n",
    "                best_f1=f1\n",
    "                best_threshold=threshold\n",
    "\n",
    "        y_preds=logits[:,1]>best_threshold\n",
    "        from sklearn.metrics import recall_score\n",
    "        recall=recall_score(y_trues, y_preds, average='macro')\n",
    "        from sklearn.metrics import precision_score\n",
    "        precision=precision_score(y_trues, y_preds, average='macro')   \n",
    "        from sklearn.metrics import f1_score\n",
    "        f1=f1_score(y_trues, y_preds, average='macro')             \n",
    "        result = {\n",
    "            \"eval_recall\": float(recall),\n",
    "            \"eval_precision\": float(precision),\n",
    "            \"eval_f1\": float(f1),\n",
    "            \"eval_threshold\":best_threshold,\n",
    "            \n",
    "        }\n",
    "\n",
    "        msgr.print_msg(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            msgr.print_msg(\"{}= {}\".format(key, str(round(result[key],4))))\n",
    "\n",
    "        if f1>best_f1:\n",
    "            msgr.print_msg(\"  Best f1:{}\".format(f1))\n",
    "            msgr.print_msg(\"  \"+\"*\"*20)\n",
    "            best_f1=f1\n",
    "            # Save best checkpoint for best bleu\n",
    "            best_output_dir = os.path.join(output_dir, 'checkpoint-best-f1')\n",
    "            if not os.path.exists(best_output_dir):\n",
    "                os.makedirs(best_output_dir)\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "            output_model_file = os.path.join(best_output_dir, \"pytorch_model.bin\")\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        \n",
    "        model.train()         \n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dgnn ***** Running training *****\n",
      "dgnn   Num examples = 696789\n",
      "dgnn   Batch size = 4\n",
      "dgnn   lr= 5e-05\n",
      "dgnn   Num epoch = 0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "896ee1157c004aaf95e231e8d36ba3e5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 327645\n",
      "dgnn   Batch size = 4\n",
      "dgnn global_step= 5000\n",
      "dgnn train_loss= 0.4617\n",
      "dgnn valid_loss= 0.1093575640693307\n",
      "dgnn   ********************\n",
      "dgnn   Best valid_loss:0.1093575640693307\n",
      "dgnn   ********************\n",
      "dgnn ***** Eval results *****\n",
      "dgnn eval_f1= 0.7656\n",
      "dgnn eval_precision= 0.8404\n",
      "dgnn eval_recall= 0.7244\n",
      "dgnn eval_threshold= 0.81\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 327645\n",
      "dgnn   Batch size = 4\n",
      "dgnn global_step= 10000\n",
      "dgnn train_loss= 0.3981\n",
      "dgnn valid_loss= 0.09985736321285367\n",
      "dgnn   ********************\n",
      "dgnn   Best valid_loss:0.09985736321285367\n",
      "dgnn   ********************\n",
      "dgnn ***** Eval results *****\n",
      "dgnn eval_f1= 0.8085\n",
      "dgnn eval_precision= 0.9064\n",
      "dgnn eval_recall= 0.7569\n",
      "dgnn eval_threshold= 0.84\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 327645\n",
      "dgnn   Batch size = 4\n",
      "dgnn global_step= 15000\n",
      "dgnn train_loss= 0.3889\n",
      "dgnn valid_loss= 0.10030904236510396\n",
      "dgnn   ********************\n",
      "dgnn ***** Eval results *****\n",
      "dgnn eval_f1= 0.8429\n",
      "dgnn eval_precision= 0.9359\n",
      "dgnn eval_recall= 0.7903\n",
      "dgnn eval_threshold= 0.81\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 327645\n",
      "dgnn   Batch size = 4\n",
      "dgnn global_step= 20000\n",
      "dgnn train_loss= 0.3824\n",
      "dgnn valid_loss= 0.0908714403219521\n",
      "dgnn   ********************\n",
      "dgnn   Best valid_loss:0.0908714403219521\n",
      "dgnn   ********************\n",
      "dgnn ***** Eval results *****\n",
      "dgnn eval_f1= 0.8372\n",
      "dgnn eval_precision= 0.9282\n",
      "dgnn eval_recall= 0.7853\n",
      "dgnn eval_threshold= 0.74\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 327645\n",
      "dgnn   Batch size = 4\n",
      "dgnn global_step= 25000\n",
      "dgnn train_loss= 0.3721\n",
      "dgnn valid_loss= 0.10772368708252907\n",
      "dgnn   ********************\n",
      "dgnn ***** Eval results *****\n",
      "dgnn eval_f1= 0.8339\n",
      "dgnn eval_precision= 0.9105\n",
      "dgnn eval_recall= 0.7872\n",
      "dgnn eval_threshold= 0.82\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 327645\n",
      "dgnn   Batch size = 4\n",
      "dgnn global_step= 30000\n",
      "dgnn train_loss= 0.3635\n",
      "dgnn valid_loss= 0.10638979276046157\n",
      "dgnn   ********************\n",
      "dgnn ***** Eval results *****\n",
      "dgnn eval_f1= 0.8251\n",
      "dgnn eval_precision= 0.9136\n",
      "dgnn eval_recall= 0.7747\n",
      "dgnn eval_threshold= 0.85\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 327645\n",
      "dgnn   Batch size = 4\n",
      "dgnn global_step= 35000\n",
      "dgnn train_loss= 0.3626\n",
      "dgnn valid_loss= 0.10349829099699855\n",
      "dgnn   ********************\n",
      "dgnn ***** Eval results *****\n",
      "dgnn eval_f1= 0.8553\n",
      "dgnn eval_precision= 0.9357\n",
      "dgnn eval_recall= 0.8061\n",
      "dgnn eval_threshold= 0.81\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 327645\n",
      "dgnn   Batch size = 4\n",
      "dgnn global_step= 40000\n",
      "dgnn train_loss= 0.357\n",
      "dgnn valid_loss= 0.10858369197323918\n",
      "dgnn   ********************\n",
      "dgnn ***** Eval results *****\n",
      "dgnn eval_f1= 0.8435\n",
      "dgnn eval_precision= 0.9381\n",
      "dgnn eval_recall= 0.7901\n",
      "dgnn eval_threshold= 0.82\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 327645\n",
      "dgnn   Batch size = 4\n",
      "dgnn global_step= 45000\n",
      "dgnn train_loss= 0.345\n",
      "dgnn valid_loss= 0.10730039311051369\n",
      "dgnn   ********************\n",
      "dgnn ***** Eval results *****\n",
      "dgnn eval_f1= 0.8566\n",
      "dgnn eval_precision= 0.9498\n",
      "dgnn eval_recall= 0.8025\n",
      "dgnn eval_threshold= 0.83\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 327645\n",
      "dgnn   Batch size = 4\n",
      "dgnn global_step= 50000\n",
      "dgnn train_loss= 0.3493\n",
      "dgnn valid_loss= 0.10310680603310465\n",
      "dgnn   ********************\n",
      "dgnn ***** Eval results *****\n",
      "dgnn eval_f1= 0.8487\n",
      "dgnn eval_precision= 0.9421\n",
      "dgnn eval_recall= 0.7951\n",
      "dgnn eval_threshold= 0.82\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_dataloader = DataLoader(test_features, batch_size=batch_size, shuffle=True, follow_batch=['x_s', 'x_t'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_bleu_model = output_dir + '/checkpoint-best-loss/pytorch_model.bin' \n",
    "model.load_state_dict(torch.load(best_bleu_model))\n",
    "model.eval()\n",
    "\n",
    "logits = []\n",
    "y_trues = []\n",
    "for data in valid_dataloader:\n",
    "    data = data.to(device)\n",
    "    x1 = data.x_s\n",
    "    edge_index1 = data.edge_index_s\n",
    "    edge_attr1 = data.edge_attr_s    \n",
    "    subgraph_node_num1 = torch.stack(torch.split(data.subgraph_node_num_s, max_subgraph_num))\n",
    "    real_graph_num1 = torch.stack(torch.split(data.real_graph_num_s, 1))\n",
    "    source_ids1 = torch.stack(torch.split(data.source_ids_s, max_source_length))\n",
    "    source_mask1 = torch.stack(torch.split(data.source_ids_s.ne(1), max_source_length))\n",
    "    batch1 = data.x_s_batch\n",
    "    ptr1 = get_ptr_from_batch(batch1).to(device)\n",
    "\n",
    "    x2 = data.x_t\n",
    "    edge_index2 = data.edge_index_t\n",
    "    edge_attr2 = data.edge_attr_t    \n",
    "    subgraph_node_num2 = torch.stack(torch.split(data.subgraph_node_num_t, max_subgraph_num))\n",
    "    real_graph_num2 = torch.stack(torch.split(data.real_graph_num_t, 1))\n",
    "    source_ids2 = torch.stack(torch.split(data.source_ids_t, max_source_length))\n",
    "    source_mask2 = torch.stack(torch.split(data.source_ids_t.ne(1), max_source_length))\n",
    "    batch2 = data.x_t_batch\n",
    "    ptr2 = get_ptr_from_batch(batch2).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs = model(x1, edge_index1, edge_attr1, subgraph_node_num1, real_graph_num1, batch1, ptr1, source_ids1, source_mask1,\n",
    "                        x2, edge_index2, edge_attr2, subgraph_node_num2, real_graph_num2, batch2, ptr2, source_ids2, source_mask2)\n",
    "    loss = loss_func(probs, data.label)\n",
    "    probs = F.softmax(probs)\n",
    "    logits.append(probs.cpu().numpy())\n",
    "    y_trues.append(data.label.cpu().numpy())\n",
    "\n",
    "logits=np.concatenate(logits,0)\n",
    "y_trues=np.concatenate(y_trues,0)\n",
    "#         msgr.print_msg(\"logits: {}\".format(logits[0:100]))\n",
    "#         msgr.print_msg(\"y_trues: {}\".format(y_trues[0:100]))\n",
    "# best_threshold=0\n",
    "# best_f1=0\n",
    "# for i in range(1,100):\n",
    "#     threshold=i/100\n",
    "#     y_preds=logits[:,1]>threshold\n",
    "#     from sklearn.metrics import recall_score\n",
    "#     recall=recall_score(y_trues, y_preds, average='binary')\n",
    "#     from sklearn.metrics import precision_score\n",
    "#     precision=precision_score(y_trues, y_preds, average='binary')   \n",
    "#     from sklearn.metrics import f1_score\n",
    "#     f1=f1_score(y_trues, y_preds, average='binary') \n",
    "#     if f1>best_f1:\n",
    "#         best_f1=f1\n",
    "#         best_threshold=threshold\n",
    "\n",
    "best_threshold = 0.5\n",
    "y_preds=logits[:,1]>best_threshold\n",
    "from sklearn.metrics import recall_score\n",
    "recall=recall_score(y_trues, y_preds, average='binary')\n",
    "from sklearn.metrics import precision_score\n",
    "precision=precision_score(y_trues, y_preds, average='binary')   \n",
    "from sklearn.metrics import f1_score\n",
    "f1=f1_score(y_trues, y_preds, average='binary')             \n",
    "result = {\n",
    "    \"eval_recall\": float(recall),\n",
    "    \"eval_precision\": float(precision),\n",
    "    \"eval_f1\": float(f1),\n",
    "    \"eval_threshold\":best_threshold,\n",
    "    \n",
    "}\n",
    "\n",
    "msgr.print_msg(\"***** Eval results *****\")\n",
    "for key in sorted(result.keys()):\n",
    "    msgr.print_msg(\"{}= {}\".format(key, str(round(result[key],4))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "last_model = output_dir + '/checkpoint-best-f1/pytorch_model.bin' \n",
    "model.load_state_dict(torch.load(best_bleu_model))\n",
    "model.eval()\n",
    "\n",
    "logits = []\n",
    "y_trues = []\n",
    "for data in valid_dataloader:\n",
    "    data = data.to(device)\n",
    "    x1 = data.x_s\n",
    "    edge_index1 = data.edge_index_s\n",
    "    edge_attr1 = data.edge_attr_s    \n",
    "    subgraph_node_num1 = torch.stack(torch.split(data.subgraph_node_num_s, max_subgraph_num))\n",
    "    real_graph_num1 = torch.stack(torch.split(data.real_graph_num_s, 1))\n",
    "    source_ids1 = torch.stack(torch.split(data.source_ids_s, max_source_length))\n",
    "    source_mask1 = torch.stack(torch.split(data.source_ids_s.ne(1), max_source_length))\n",
    "    batch1 = data.x_s_batch\n",
    "    ptr1 = get_ptr_from_batch(batch1).to(device)\n",
    "\n",
    "    x2 = data.x_t\n",
    "    edge_index2 = data.edge_index_t\n",
    "    edge_attr2 = data.edge_attr_t    \n",
    "    subgraph_node_num2 = torch.stack(torch.split(data.subgraph_node_num_t, max_subgraph_num))\n",
    "    real_graph_num2 = torch.stack(torch.split(data.real_graph_num_t, 1))\n",
    "    source_ids2 = torch.stack(torch.split(data.source_ids_t, max_source_length))\n",
    "    source_mask2 = torch.stack(torch.split(data.source_ids_t.ne(1), max_source_length))\n",
    "    batch2 = data.x_t_batch\n",
    "    ptr2 = get_ptr_from_batch(batch2).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs = model(x1, edge_index1, edge_attr1, subgraph_node_num1, real_graph_num1, batch1, ptr1, source_ids1, source_mask1,\n",
    "                        x2, edge_index2, edge_attr2, subgraph_node_num2, real_graph_num2, batch2, ptr2, source_ids2, source_mask2)\n",
    "    loss = loss_func(probs, data.label)\n",
    "    probs = F.softmax(probs)\n",
    "    logits.append(probs.cpu().numpy())\n",
    "    y_trues.append(data.label.cpu().numpy())\n",
    "\n",
    "logits=np.concatenate(logits,0)\n",
    "y_trues=np.concatenate(y_trues,0)\n",
    "#         msgr.print_msg(\"logits: {}\".format(logits[0:100]))\n",
    "#         msgr.print_msg(\"y_trues: {}\".format(y_trues[0:100]))\n",
    "# best_threshold=0\n",
    "# best_f1=0\n",
    "# for i in range(1,100):\n",
    "#     threshold=i/100\n",
    "#     y_preds=logits[:,1]>threshold\n",
    "#     from sklearn.metrics import recall_score\n",
    "#     recall=recall_score(y_trues, y_preds, average='binary')\n",
    "#     from sklearn.metrics import precision_score\n",
    "#     precision=precision_score(y_trues, y_preds, average='binary')   \n",
    "#     from sklearn.metrics import f1_score\n",
    "#     f1=f1_score(y_trues, y_preds, average='binary') \n",
    "#     if f1>best_f1:\n",
    "#         best_f1=f1\n",
    "#         best_threshold=threshold\n",
    "\n",
    "best_threshold = 0.5\n",
    "y_preds=logits[:,1]>best_threshold\n",
    "from sklearn.metrics import recall_score\n",
    "recall=recall_score(y_trues, y_preds, average='binary')\n",
    "from sklearn.metrics import precision_score\n",
    "precision=precision_score(y_trues, y_preds, average='binary')   \n",
    "from sklearn.metrics import f1_score\n",
    "f1=f1_score(y_trues, y_preds, average='binary')             \n",
    "result = {\n",
    "    \"eval_recall\": float(recall),\n",
    "    \"eval_precision\": float(precision),\n",
    "    \"eval_f1\": float(f1),\n",
    "    \"eval_threshold\":best_threshold,\n",
    "    \n",
    "}\n",
    "\n",
    "msgr.print_msg(\"***** Eval results *****\")\n",
    "for key in sorted(result.keys()):\n",
    "    msgr.print_msg(\"{}= {}\".format(key, str(round(result[key],4))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_bleu_model = output_dir + '/checkpoint-last/pytorch_model.bin' \n",
    "model.load_state_dict(torch.load(best_bleu_model))\n",
    "model.eval()\n",
    "\n",
    "logits = []\n",
    "y_trues = []\n",
    "for data in valid_dataloader:\n",
    "    data = data.to(device)\n",
    "    x1 = data.x_s\n",
    "    edge_index1 = data.edge_index_s\n",
    "    edge_attr1 = data.edge_attr_s    \n",
    "    subgraph_node_num1 = torch.stack(torch.split(data.subgraph_node_num_s, max_subgraph_num))\n",
    "    real_graph_num1 = torch.stack(torch.split(data.real_graph_num_s, 1))\n",
    "    source_ids1 = torch.stack(torch.split(data.source_ids_s, max_source_length))\n",
    "    source_mask1 = torch.stack(torch.split(data.source_ids_s.ne(1), max_source_length))\n",
    "    batch1 = data.x_s_batch\n",
    "    ptr1 = get_ptr_from_batch(batch1).to(device)\n",
    "\n",
    "    x2 = data.x_t\n",
    "    edge_index2 = data.edge_index_t\n",
    "    edge_attr2 = data.edge_attr_t    \n",
    "    subgraph_node_num2 = torch.stack(torch.split(data.subgraph_node_num_t, max_subgraph_num))\n",
    "    real_graph_num2 = torch.stack(torch.split(data.real_graph_num_t, 1))\n",
    "    source_ids2 = torch.stack(torch.split(data.source_ids_t, max_source_length))\n",
    "    source_mask2 = torch.stack(torch.split(data.source_ids_t.ne(1), max_source_length))\n",
    "    batch2 = data.x_t_batch\n",
    "    ptr2 = get_ptr_from_batch(batch2).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs = model(x1, edge_index1, edge_attr1, subgraph_node_num1, real_graph_num1, batch1, ptr1, source_ids1, source_mask1,\n",
    "                        x2, edge_index2, edge_attr2, subgraph_node_num2, real_graph_num2, batch2, ptr2, source_ids2, source_mask2)\n",
    "    loss = loss_func(probs, data.label)\n",
    "    probs = F.softmax(probs)\n",
    "    logits.append(probs.cpu().numpy())\n",
    "    y_trues.append(data.label.cpu().numpy())\n",
    "\n",
    "logits=np.concatenate(logits,0)\n",
    "y_trues=np.concatenate(y_trues,0)\n",
    "#         msgr.print_msg(\"logits: {}\".format(logits[0:100]))\n",
    "#         msgr.print_msg(\"y_trues: {}\".format(y_trues[0:100]))\n",
    "# best_threshold=0\n",
    "# best_f1=0\n",
    "# for i in range(1,100):\n",
    "#     threshold=i/100\n",
    "#     y_preds=logits[:,1]>threshold\n",
    "#     from sklearn.metrics import recall_score\n",
    "#     recall=recall_score(y_trues, y_preds, average='binary')\n",
    "#     from sklearn.metrics import precision_score\n",
    "#     precision=precision_score(y_trues, y_preds, average='binary')   \n",
    "#     from sklearn.metrics import f1_score\n",
    "#     f1=f1_score(y_trues, y_preds, average='binary') \n",
    "#     if f1>best_f1:\n",
    "#         best_f1=f1\n",
    "#         best_threshold=threshold\n",
    "\n",
    "best_threshold = 0.5\n",
    "y_preds=logits[:,1]>best_threshold\n",
    "from sklearn.metrics import recall_score\n",
    "recall=recall_score(y_trues, y_preds, average='binary')\n",
    "from sklearn.metrics import precision_score\n",
    "precision=precision_score(y_trues, y_preds, average='binary')   \n",
    "from sklearn.metrics import f1_score\n",
    "f1=f1_score(y_trues, y_preds, average='binary')             \n",
    "result = {\n",
    "    \"eval_recall\": float(recall),\n",
    "    \"eval_precision\": float(precision),\n",
    "    \"eval_f1\": float(f1),\n",
    "    \"eval_threshold\":best_threshold,\n",
    "    \n",
    "}\n",
    "\n",
    "msgr.print_msg(\"***** Eval results *****\")\n",
    "for key in sorted(result.keys()):\n",
    "    msgr.print_msg(\"{}= {}\".format(key, str(round(result[key],4))))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}