{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd \n",
    "import javalang\n",
    "from javalang.ast import Node\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import (Module, Embedding, LSTM, Sequential, Linear, BatchNorm1d, ReLU, Sigmoid, CrossEntropyLoss, TransformerDecoderLayer,\n",
    "                        TransformerDecoder, Dropout)\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn.glob import GlobalAttention\n",
    "from torch_geometric.nn import MessagePassing, GatedGraphConv, GCNConv, global_mean_pool, GINEConv, global_add_pool\n",
    "from anytree import AnyNode\n",
    "from torch_geometric.data import Data, DataLoader, ClusterData, ClusterLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import random\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel, DataCollatorWithPadding, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, SequentialSampler\n",
    "import json\n",
    "from codebert_seq2seq4 import Seq2Seq\n",
    "import bleu\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config_dgnn.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(config_file), Loader=yaml.FullLoader)\n",
    "\n",
    "# data source\n",
    "TRAIN_DIR = config['tlc_data']['train']\n",
    "VALID_DIR = config['tlc_data']['valid']\n",
    "TEST_DIR = config['tlc_data']['test']\n",
    "\n",
    "\n",
    "# prepocess design\n",
    "max_source_length = config['preprocess']['max_source_length']\n",
    "max_target_length = config['preprocess']['max_target_length']\n",
    "\n",
    "\n",
    "# training parameter\n",
    "batch_size = config['training']['batch_size']\n",
    "num_epoches = config['training']['num_epoches']\n",
    "lr = config['training']['lr']\n",
    "decay_ratio = config['training']['lr']\n",
    "save_name = config['training']['save_name']\n",
    "warm_up = config['training']['warm_up']\n",
    "patience = config['training']['patience']\n",
    "\n",
    "# model design\n",
    "graph_embedding_size = config['model']['graph_embedding_size']\n",
    "lstm_hidden_size = config['model']['lstm_hidden_size']\n",
    "divide_node_num = config['model']['divide_node_num']\n",
    "gnn_layers_num = config['model']['gnn_layers_num']\n",
    "lstm_layers_num = config['model']['lstm_layers_num']\n",
    "decoder_input_size = config['model']['decoder_input_size']\n",
    "decoder_hidden_size = config['model']['decoder_hidden_size']\n",
    "decoder_num_layers = config['model']['decoder_num_layers']\n",
    "decoder_rnn_dropout = config['model']['decoder_rnn_dropout']\n",
    "\n",
    "# logs\n",
    "info_prefix = config['logs']['info_prefix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NODE_NUM = 300 # the max num of subgraph, set for zero padding \n",
    "max_subgraph_num = int(MAX_NODE_NUM/divide_node_num) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = datetime.now().strftime('%Y-%m-%d--%H-%M-%S')\n",
    "log_file = 'logs/' + run_id + '.log'\n",
    "exp_dir = 'runs/' + run_id\n",
    "os.mkdir(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Info(object):\n",
    "    def __init__(self, info_prefix=''):\n",
    "        self.info_prefix = info_prefix\n",
    "    \n",
    "    def print_msg(self, msg):\n",
    "        text = self.info_prefix + ' ' + msg\n",
    "        print(text)\n",
    "        logging.info(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn run_id : 2021-08-14--02-57-49\n",
      "dgnn log_file : logs/2021-08-14--02-57-49.log\n",
      "dgnn exp_dir: runs/2021-08-14--02-57-49\n",
      "dgnn {'data': {'train': '/data/code/represent-code-in-human/data/code-summarization-enhanced-full/train_utf8.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-enhanced-full/valid_utf8.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-enhanced-full/test_utf8.jsonl'}, 'tlc_data': {'train': '/data/code/represent-code-in-human/data/TLC-SUM-enhanced/train.jsonl', 'valid': '/data/code/represent-code-in-human/data/TLC-SUM-enhanced/valid.jsonl', 'test': '/data/code/represent-code-in-human/data/TLC-SUM-enhanced/test.jsonl'}, 'small_data': {'train': '/data/code/represent-code-in-human/data/code-summarization-enhanced-small/train_utf8.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-enhanced-small/valid_utf8.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-enhanced-small/test_utf8.jsonl'}, 'middle_data': {'train': '/data/code/represent-code-in-human/data/code-summarization-enhanced-middle/train_utf8.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-enhanced-middle/valid_utf8.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-enhanced-middle/test_utf8.jsonl'}, 'ccd_data': {'data': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/data.jsonl', 'train': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/train.txt', 'valid': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/test.txt', 'test': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/valid.txt'}, 'preprocess': {'max_source_length': 256, 'max_target_length': 32}, 'training': {'batch_size': 128, 'num_epoches': 100, 'lr': 0.001, 'decay_ratio': 0.95, 'save_name': '/model.pth', 'warm_up': 5, 'patience': 10}, 'model': {'graph_embedding_size': 768, 'gnn_layers_num': 3, 'lstm_layers_num': 2, 'lstm_hidden_size': 768, 'divide_node_num': 30, 'decoder_input_size': 768, 'decoder_hidden_size': 128, 'decoder_num_layers': 2, 'decoder_rnn_dropout': 0.5, 'gine_dim': 128}, 'logs': {'info_prefix': 'dgnn'}}\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s | %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', filename=log_file, level=logging.DEBUG)\n",
    "msgr = Info(info_prefix)\n",
    "\n",
    "msgr.print_msg('run_id : {}'.format(run_id))\n",
    "msgr.print_msg('log_file : {}'.format(log_file))\n",
    "msgr.print_msg('exp_dir: {}'.format(exp_dir))\n",
    "msgr.print_msg(str(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'microsoft/codebert-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(checkpoint)\n",
    "ast_tokenizer = RobertaTokenizer.from_pretrained(checkpoint)\n",
    "roberta = RobertaModel.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "config = RobertaConfig.from_pretrained(checkpoint)\n",
    "javalang_special_tokens = ['CompilationUnit','Import','Documented','Declaration','TypeDeclaration','PackageDeclaration',\n",
    "                            'ClassDeclaration','EnumDeclaration','InterfaceDeclaration','AnnotationDeclaration','Type',\n",
    "                            'BasicType','ReferenceType','TypeArgument','TypeParameter','Annotation','ElementValuePair',\n",
    "                            'ElementArrayValue','Member','MethodDeclaration','FieldDeclaration','ConstructorDeclaration',\n",
    "                            'ConstantDeclaration','ArrayInitializer','VariableDeclaration','LocalVariableDeclaration',\n",
    "                            'VariableDeclarator','FormalParameter','InferredFormalParameter','Statement','IfStatement',\n",
    "                            'WhileStatement','DoStatement','ForStatement','AssertStatement','BreakStatement','ContinueStatement',\n",
    "                            'ReturnStatement','ThrowStatement','SynchronizedStatement','TryStatement','SwitchStatement',\n",
    "                            'BlockStatement','StatementExpression','TryResource','CatchClause','CatchClauseParameter',\n",
    "                            'SwitchStatementCase','ForControl','EnhancedForControl','Expression','Assignment','TernaryExpression',\n",
    "                            'BinaryOperation','Cast','MethodReference','LambdaExpression','Primary','Literal','This',\n",
    "                            'MemberReference','Invocation','ExplicitConstructorInvocation','SuperConstructorInvocation',\n",
    "                            'MethodInvocation','SuperMethodInvocation','SuperMemberReference','ArraySelector','ClassReference',\n",
    "                            'VoidClassReference','Creator','ArrayCreator','ClassCreator','InnerClassCreator','EnumBody',\n",
    "                            'EnumConstantDeclaration','AnnotationMethod', 'Modifier']\n",
    "special_tokens_dict = {'additional_special_tokens': javalang_special_tokens}\n",
    "num_added_toks = ast_tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example(object):\n",
    "    def __init__(self, idx, source, ast_des, target):\n",
    "        self.idx = idx\n",
    "        self.source = source\n",
    "        self.ast_des = ast_des\n",
    "        self.target = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "def read_examples(filename):\n",
    "    examples = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            js = json.loads(line)\n",
    "            if 'idx' not in js:\n",
    "                js['idx'] = idx\n",
    "            \n",
    "            code = js['code']\n",
    "            nl = ' '.join(js['docstring_tokens']).replace('\\n', '')\n",
    "            nl = ' '.join(nl.strip().split())\n",
    "            ast_des = js['ast_des']\n",
    "            examples.append(\n",
    "                Example(\n",
    "                    idx = idx,\n",
    "                    source = code,\n",
    "                    ast_des = ast_des,\n",
    "                    target = nl,\n",
    "                )\n",
    "            )\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn train size: 69708, valid size: 8714, test size: 8714\n"
     ]
    }
   ],
   "source": [
    "train_examples = read_examples(TRAIN_DIR)\n",
    "valid_examples = read_examples(VALID_DIR)\n",
    "test_examples = read_examples(TEST_DIR)\n",
    "msgr.print_msg('train size: {}, valid size: {}, test size: {}'.format(len(train_examples), len(valid_examples), len(test_examples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.load('features/tlc/train_features.pt')\n",
    "valid_features = torch.load('features/tlc/valid_features.pt')\n",
    "test_features = torch.load('features/tlc/test_features.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(Module):\n",
    "    def __init__(self, vocab_len, graph_embedding_size, gnn_layers_num, lstm_layers_num, lstm_hidden_size, decoder_input_size, device):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.embeddings = Embedding(vocab_len, graph_embedding_size)\n",
    "        self.edge_embed = Embedding(4, 1) # only two edge types to be set weights, which are AST edge and data flow edge\n",
    "        self.ggnnlayer = GatedGraphConv(graph_embedding_size, gnn_layers_num)\n",
    "        # self.mlp_gate = Sequential(\n",
    "        #     Linear(graph_embedding_size, 300), Sigmoid(), Linear(300, 1), Sigmoid())\n",
    "        # self.pool = GlobalAttention(gate_nn=self.mlp_gate)\n",
    "        self.lstm = LSTM(input_size=graph_embedding_size, hidden_size=lstm_hidden_size, num_layers=lstm_layers_num, dropout=0.2)\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_layers_num = lstm_layers_num\n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.fc1 = Linear(graph_embedding_size + lstm_hidden_size, graph_embedding_size + lstm_hidden_size)\n",
    "        self.fc2 = Linear(graph_embedding_size + lstm_hidden_size, decoder_input_size)\n",
    "\n",
    "    def subgraph_forward(self, x, edge_index, edge_attr, batch):\n",
    "        if type(edge_attr) == type(None):\n",
    "            edge_weight = None\n",
    "        else:\n",
    "            edge_weight = self.edge_embed(edge_attr)\n",
    "            edge_weight = edge_weight.squeeze(1)\n",
    "        x = self.ggnnlayer(x, edge_index, edge_weight)\n",
    "        return global_mean_pool(x, batch=batch)\n",
    "    \n",
    "    # partitioning multiple subgraphs by dynamic allocating edges\n",
    "    def partition_graph(self, x, edge_index, edge_attr, subgraph_node_num, real_graph_num, ptr):        \n",
    "        nodes_list = [] # record all nodes number for each subgraph in total batch\n",
    "        subgraph_num = max(real_graph_num)\n",
    "\n",
    "        batch_size = subgraph_node_num.size(0)\n",
    "        start_node_num = [1 for _ in range(batch_size)]\n",
    "        for i in range(subgraph_num):\n",
    "            subgraph_nodes_list = []\n",
    "            for j in range(batch_size):\n",
    "                if subgraph_node_num[j][i] != 0:\n",
    "                    for k in range(ptr[j]+start_node_num[j], ptr[j]+start_node_num[j]+subgraph_node_num[j][i]):\n",
    "                        subgraph_nodes_list.append(k)\n",
    "                    start_node_num[j] += subgraph_node_num[j][i]\n",
    "            nodes_list.append(subgraph_nodes_list)\n",
    "\n",
    "        # only count the edge whose target node in subgraph\n",
    "        sub_edge_src = [[] for _ in range(subgraph_num)]\n",
    "        sub_edge_tgt = [[] for _ in range(subgraph_num)]\n",
    "        sub_edge_attr = [[] for _ in range(subgraph_num)]\n",
    "        # print('nodes_list', nodes_list)\n",
    "        node_num = len(x)\n",
    "        node_subgraph_index = [0 for _ in range(node_num)] # use a list to store the subgraph numbers for all nodes\n",
    "        for i in range(len(nodes_list)):\n",
    "            for node in nodes_list[i]:\n",
    "                node_subgraph_index[node] = i\n",
    "\n",
    "        for i in range(len(edge_index[1])):\n",
    "            src = edge_index[0][i].item()\n",
    "            tgt = edge_index[1][i].item()\n",
    "            sub_edge_src[node_subgraph_index[tgt]].append(src)\n",
    "            sub_edge_tgt[node_subgraph_index[tgt]].append(tgt)\n",
    "            sub_edge_attr[node_subgraph_index[tgt]].append(edge_attr[i].item())\n",
    "        edge_index_list = []\n",
    "        edge_attr_list = []\n",
    "        for i in range(subgraph_num):\n",
    "            edge_index_list.append(torch.tensor([sub_edge_src[i], sub_edge_tgt[i]], dtype=torch.long))\n",
    "            edge_attr_list.append(torch.tensor(sub_edge_attr[i], dtype=torch.long))\n",
    "        # print('nodes_list', nodes_list)\n",
    "        return edge_index_list, edge_attr_list  \n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, subgraph_node_num, real_graph_num, batch, ptr):\n",
    "        edge_index_list, edge_attr_list = self.partition_graph(x, edge_index, edge_attr, subgraph_node_num, real_graph_num, ptr)\n",
    "        # print('edge_index_list', edge_index_list)\n",
    "        # print('edge_attr_list', edge_attr_list)\n",
    "        x = self.embeddings(x)\n",
    "        x = x.squeeze(1)\n",
    "        subgraph_pool_list = [\n",
    "            self.subgraph_forward(x, edge_index_list[i].to(self.device), edge_attr_list[i].to(self.device), batch)\n",
    "            for i in range(len(edge_index_list))\n",
    "        ]\n",
    "        graph_pool = self.subgraph_forward(x, edge_index, edge_attr, batch)\n",
    "        # print('graph_pool', graph_pool.shape)\n",
    "        subgraph_pool_seq = torch.stack(subgraph_pool_list)\n",
    "        # print('subgraph_pool_seq', subgraph_pool_seq.shape)\n",
    "        h0 = torch.zeros(self.lstm_layers_num, subgraph_pool_seq.size(1) ,self.lstm_hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.lstm_layers_num, subgraph_pool_seq.size(1) ,self.lstm_hidden_size).to(self.device)\n",
    "        subgraph_output, (_, _) = self.lstm(subgraph_pool_seq, (h0, c0))\n",
    "        output = self.fc1(torch.cat((subgraph_output[-1], graph_pool), dim=1))\n",
    "        output = self.dropout(output)\n",
    "        return self.fc2(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): GNNEncoder(\n",
       "    (embeddings): Embedding(50336, 768)\n",
       "    (edge_embed): Embedding(4, 1)\n",
       "    (ggnnlayer): GatedGraphConv(768, num_layers=3)\n",
       "    (lstm): LSTM(768, 768, num_layers=2, dropout=0.2)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (fc1): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "    (fc2): Linear(in_features=1536, out_features=768, bias=True)\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  (lsm): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "gnn_encoder = GNNEncoder(vocab_len=tokenizer.vocab_size+num_added_toks, graph_embedding_size=graph_embedding_size,\n",
    "                         gnn_layers_num=gnn_layers_num, lstm_layers_num=lstm_layers_num, lstm_hidden_size=lstm_hidden_size,\n",
    "                        decoder_input_size=decoder_input_size, device=device)\n",
    "decoder_layer = TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "decoder = TransformerDecoder(decoder_layer, num_layers=6)\n",
    "model = Seq2Seq(encoder=gnn_encoder, decoder=decoder, config=config, beam_size=10, max_length=max_target_length, \n",
    "                sos_id=tokenizer.cls_token_id, eos_id=tokenizer.sep_token_id)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_source_length = 256\n",
    "max_target_length = 32\n",
    "batch_size = 32\n",
    "beam_size = 10\n",
    "lr = 2e-4\n",
    "warmup_steps = 0\n",
    "train_steps = 40000\n",
    "weight_decay = 0.0\n",
    "adam_epsilon = 1e-8\n",
    "valid_loss_steps = 500\n",
    "valid_bleu_steps = 2000\n",
    "output_dir = exp_dir\n",
    "\n",
    "train_url = TRAIN_DIR\n",
    "valid_url = VALID_DIR\n",
    "test_url = TEST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_features, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer and schedule\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': weight_decay},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn ***** Running training *****\n",
      "dgnn   Num examples = 69708\n",
      "dgnn   Batch size = 32\n",
      "dgnn   Num epoch = 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f933cb216a554b99863e3b8b7b0a01cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 500\n",
      "dgnn train_loss= 12.1827\n",
      "dgnn valid_loss= 8.934193044535105\n",
      "dgnn valid_ppl= 7587.01145\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:7587.01145\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 1000\n",
      "dgnn train_loss= 8.2703\n",
      "dgnn valid_loss= 6.759162849425959\n",
      "dgnn valid_ppl= 861.92034\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:861.92034\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 1500\n",
      "dgnn train_loss= 7.1635\n",
      "dgnn valid_loss= 6.2932908489731645\n",
      "dgnn valid_ppl= 540.93052\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:540.93052\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 2000\n",
      "dgnn train_loss= 6.4886\n",
      "dgnn valid_loss= 5.78151828058472\n",
      "dgnn valid_ppl= 324.25112\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:324.25112\n",
      "dgnn   ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn   bleu-4 = 11.13\n",
      "dgnn   ********************\n",
      "dgnn   Best bleu:11.13\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 2500\n",
      "dgnn train_loss= 5.9338\n",
      "dgnn valid_loss= 5.429160269441838\n",
      "dgnn valid_ppl= 227.95774\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:227.95774\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 3000\n",
      "dgnn train_loss= 5.4852\n",
      "dgnn valid_loss= 5.1247368057474345\n",
      "dgnn valid_ppl= 168.12989\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:168.12989\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 3500\n",
      "dgnn train_loss= 5.1544\n",
      "dgnn valid_loss= 4.960104932716462\n",
      "dgnn valid_ppl= 142.60876\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:142.60876\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 4000\n",
      "dgnn train_loss= 4.9625\n",
      "dgnn valid_loss= 4.80160431038037\n",
      "dgnn valid_ppl= 121.70551\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:121.70551\n",
      "dgnn   ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn   bleu-4 = 13.37\n",
      "dgnn   ********************\n",
      "dgnn   Best bleu:13.37\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 4500\n",
      "dgnn train_loss= 4.765\n",
      "dgnn valid_loss= 4.664884689291026\n",
      "dgnn valid_ppl= 106.15334\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:106.15334\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 5000\n",
      "dgnn train_loss= 4.5703\n",
      "dgnn valid_loss= 4.54448708070969\n",
      "dgnn valid_ppl= 94.11214\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:94.11214\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 5500\n",
      "dgnn train_loss= 4.4148\n",
      "dgnn valid_loss= 4.45789958172314\n",
      "dgnn valid_ppl= 86.30604\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:86.30604\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 6000\n",
      "dgnn train_loss= 4.2947\n",
      "dgnn valid_loss= 4.3698264983493305\n",
      "dgnn valid_ppl= 79.02992\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:79.02992\n",
      "dgnn   ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn   bleu-4 = 15.3\n",
      "dgnn   ********************\n",
      "dgnn   Best bleu:15.3\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 6500\n",
      "dgnn train_loss= 4.1875\n",
      "dgnn valid_loss= 4.289396670612242\n",
      "dgnn valid_ppl= 72.92246\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:72.92246\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 7000\n",
      "dgnn train_loss= 4.0428\n",
      "dgnn valid_loss= 4.225498003519639\n",
      "dgnn valid_ppl= 68.40856\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:68.40856\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 7500\n",
      "dgnn train_loss= 3.9342\n",
      "dgnn valid_loss= 4.156329871841089\n",
      "dgnn valid_ppl= 63.8368\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:63.8368\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 8000\n",
      "dgnn train_loss= 3.814\n",
      "dgnn valid_loss= 4.119725908270423\n",
      "dgnn valid_ppl= 61.54237\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:61.54237\n",
      "dgnn   ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn   bleu-4 = 16.2\n",
      "dgnn   ********************\n",
      "dgnn   Best bleu:16.2\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 8500\n",
      "dgnn train_loss= 3.7625\n",
      "dgnn valid_loss= 4.0575911045962405\n",
      "dgnn valid_ppl= 57.83483\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:57.83483\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 9000\n",
      "dgnn train_loss= 3.6431\n",
      "dgnn valid_loss= 4.028926622622753\n",
      "dgnn valid_ppl= 56.20055\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:56.20055\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 9500\n",
      "dgnn train_loss= 3.533\n",
      "dgnn valid_loss= 3.9626904967862675\n",
      "dgnn valid_ppl= 52.59865\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:52.59865\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 10000\n",
      "dgnn train_loss= 3.4393\n",
      "dgnn valid_loss= 3.9450469712279954\n",
      "dgnn valid_ppl= 51.67877\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:51.67877\n",
      "dgnn   ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn   bleu-4 = 17.61\n",
      "dgnn   ********************\n",
      "dgnn   Best bleu:17.61\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 10500\n",
      "dgnn train_loss= 3.3885\n",
      "dgnn valid_loss= 3.92965186995704\n",
      "dgnn valid_ppl= 50.88926\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:50.88926\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 11000\n",
      "dgnn train_loss= 3.3067\n",
      "dgnn valid_loss= 3.917768260906397\n",
      "dgnn valid_ppl= 50.28809\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:50.28809\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 11500\n",
      "dgnn train_loss= 3.2114\n",
      "dgnn valid_loss= 3.84961306800401\n",
      "dgnn valid_ppl= 46.97488\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:46.97488\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 12000\n",
      "dgnn train_loss= 3.1317\n",
      "dgnn valid_loss= 3.860597282700342\n",
      "dgnn valid_ppl= 47.49371\n",
      "dgnn   ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn   bleu-4 = 18.87\n",
      "dgnn   ********************\n",
      "dgnn   Best bleu:18.87\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 12500\n",
      "dgnn train_loss= 3.0916\n",
      "dgnn valid_loss= 3.7846292119111022\n",
      "dgnn valid_ppl= 44.01935\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:44.01935\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 13000\n",
      "dgnn train_loss= 3.0128\n",
      "dgnn valid_loss= 3.8461744424072495\n",
      "dgnn valid_ppl= 46.81363\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 13500\n",
      "dgnn train_loss= 2.94\n",
      "dgnn valid_loss= 3.7955431247197913\n",
      "dgnn valid_ppl= 44.5024\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 14000\n",
      "dgnn train_loss= 2.8714\n",
      "dgnn valid_loss= 3.7772896453964857\n",
      "dgnn valid_ppl= 43.69745\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:43.69745\n",
      "dgnn   ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn   bleu-4 = 20.37\n",
      "dgnn   ********************\n",
      "dgnn   Best bleu:20.37\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 14500\n",
      "dgnn train_loss= 2.8175\n",
      "dgnn valid_loss= 3.8015302014174925\n",
      "dgnn valid_ppl= 44.76964\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 15000\n",
      "dgnn train_loss= 2.7963\n",
      "dgnn valid_loss= 3.705470563193208\n",
      "dgnn valid_ppl= 40.66918\n",
      "dgnn   ********************\n",
      "dgnn   Best ppl:40.66918\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 15500\n",
      "dgnn train_loss= 2.7254\n",
      "dgnn valid_loss= 3.7365303944342987\n",
      "dgnn valid_ppl= 41.95218\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 16000\n",
      "dgnn train_loss= 2.652\n",
      "dgnn valid_loss= 3.79196974906813\n",
      "dgnn valid_ppl= 44.34366\n",
      "dgnn   ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn   bleu-4 = 21.59\n",
      "dgnn   ********************\n",
      "dgnn   Best bleu:21.59\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 16500\n",
      "dgnn train_loss= 2.611\n",
      "dgnn valid_loss= 3.7210333317409265\n",
      "dgnn valid_ppl= 41.30706\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 17000\n",
      "dgnn train_loss= 2.5942\n",
      "dgnn valid_loss= 3.739247936835676\n",
      "dgnn valid_ppl= 42.06634\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 17500\n",
      "dgnn train_loss= 2.5391\n",
      "dgnn valid_loss= 3.756448547891742\n",
      "dgnn valid_ppl= 42.79617\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 18000\n",
      "dgnn train_loss= 2.4732\n",
      "dgnn valid_loss= 3.775724997622009\n",
      "dgnn valid_ppl= 43.62913\n",
      "dgnn   ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn   bleu-4 = 22.14\n",
      "dgnn   ********************\n",
      "dgnn   Best bleu:22.14\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 18500\n",
      "dgnn train_loss= 2.46\n",
      "dgnn valid_loss= 3.7276303568112032\n",
      "dgnn valid_ppl= 41.58046\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 19000\n",
      "dgnn train_loss= 2.4384\n",
      "dgnn valid_loss= 3.727862843090401\n",
      "dgnn valid_ppl= 41.59013\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 19500\n",
      "dgnn train_loss= 2.4028\n",
      "dgnn valid_loss= 3.7677652192283326\n",
      "dgnn valid_ppl= 43.28323\n",
      "dgnn   ********************\n",
      "dgnn \n",
      "***** Running evaluation *****\n",
      "dgnn   Num examples = 8714\n",
      "dgnn   Batch size = 32\n",
      "dgnn global_step= 20000\n",
      "dgnn train_loss= 2.3776\n",
      "dgnn valid_loss= 3.7421539477125254\n",
      "dgnn valid_ppl= 42.18876\n",
      "dgnn   ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn   bleu-4 = 22.89\n",
      "dgnn   ********************\n",
      "dgnn   Best bleu:22.89\n",
      "dgnn   ********************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "#Start training\n",
    "msgr.print_msg(\"***** Running training *****\")\n",
    "msgr.print_msg(\"  Num examples = {}\".format(len(train_features)))\n",
    "msgr.print_msg(\"  Batch size = {}\".format(batch_size))\n",
    "msgr.print_msg(\"  Num epoch = {}\".format(batch_size//len(train_features)))\n",
    "model.train()\n",
    "valid_dataset = {}\n",
    "nb_tr_examples, nb_tr_steps, tr_loss, global_step, best_bleu, best_loss = 0, 0, 0, 0, 0, 1e6\n",
    "bar = tqdm(range(train_steps), total=train_steps)\n",
    "train_dataloader = cycle(train_dataloader)\n",
    "\n",
    "for step in bar:\n",
    "    data = next(train_dataloader)\n",
    "    data = data.to(device)\n",
    "    subgraph_node_num = torch.stack(torch.split(data.subgraph_node_num, max_subgraph_num))\n",
    "    real_graph_num = torch.stack(torch.split(data.real_graph_num, 1))\n",
    "    target_ids = torch.stack(torch.split(data.target_ids, max_target_length))\n",
    "    target_mask = torch.stack(torch.split(data.target_mask, max_target_length))  \n",
    "    loss, _, _, = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, subgraph_node_num=subgraph_node_num, \n",
    "                        real_graph_num=real_graph_num, batch=data.batch, ptr=data.ptr, target_ids=target_ids, target_mask=target_mask)\n",
    "\n",
    "    tr_loss += loss.item()\n",
    "    train_loss = round(tr_loss / (nb_tr_steps + 1), 4) \n",
    "    bar.set_description('loss {}'.format(train_loss))\n",
    "    nb_tr_examples += data.x.size(0)\n",
    "    nb_tr_steps += 1\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    scheduler.step()\n",
    "    global_step += 1\n",
    "    \n",
    "    if (global_step + 1) % valid_loss_steps == 0:\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        valid_sampler = SequentialSampler(valid_features)\n",
    "        valid_dataloader = DataLoader(valid_features, sampler=valid_sampler, batch_size=batch_size)\n",
    "\n",
    "        msgr.print_msg(\"\\n***** Running evaluation *****\")\n",
    "        msgr.print_msg(\"  Num examples = {}\".format(len(valid_features)))\n",
    "        msgr.print_msg(\"  Batch size = {}\".format(batch_size))\n",
    "\n",
    "        #Start Evaling model\n",
    "        model.eval()\n",
    "        valid_loss, tokens_num = 0, 0\n",
    "        for data in valid_dataloader:\n",
    "            data = data.to(device)\n",
    "            subgraph_node_num = torch.stack(torch.split(data.subgraph_node_num, max_subgraph_num))\n",
    "            real_graph_num = torch.stack(torch.split(data.real_graph_num, 1))\n",
    "            target_ids = torch.stack(torch.split(data.target_ids, max_target_length))\n",
    "            target_mask = torch.stack(torch.split(data.target_mask, max_target_length))            \n",
    "\n",
    "            with torch.no_grad():\n",
    "                _,loss,num = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, batch=data.batch, \n",
    "                                    subgraph_node_num=subgraph_node_num, real_graph_num=real_graph_num,  ptr=data.ptr,\n",
    "                                    target_ids=target_ids, target_mask=target_mask)    \n",
    "            valid_loss += loss.sum().item()\n",
    "            tokens_num += num.sum().item()\n",
    "        #Pring loss of valid dataset    \n",
    "        model.train()\n",
    "        valid_loss = valid_loss / tokens_num\n",
    "        result = { 'valid_loss': valid_loss,\n",
    "                    'valid_ppl': round(np.exp(valid_loss), 5),\n",
    "                    'global_step': global_step+1,\n",
    "                    'train_loss': round(train_loss, 5)}\n",
    "        for key in sorted(result.keys()):\n",
    "            msgr.print_msg(\"{}= {}\".format(key, str(result[key])))\n",
    "        msgr.print_msg(\"  \"+\"*\"*20)   \n",
    "        \n",
    "        #save last checkpoint\n",
    "        last_output_dir = os.path.join(output_dir, 'checkpoint-last')\n",
    "        if not os.path.exists(last_output_dir):\n",
    "            os.makedirs(last_output_dir)\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "        output_model_file = os.path.join(last_output_dir, \"pytorch_model.bin\")\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)                    \n",
    "        if valid_loss < best_loss:\n",
    "            msgr.print_msg(\"  Best ppl:{}\".format(round(np.exp(valid_loss), 5)))\n",
    "            msgr.print_msg(\"  \" + \"*\" * 20)\n",
    "            best_loss = valid_loss\n",
    "            # Save best checkpoint for best ppl\n",
    "            best_output_dir = os.path.join(output_dir, 'checkpoint-best-ppl')\n",
    "            if not os.path.exists(best_output_dir):\n",
    "                os.makedirs(best_output_dir)\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "            output_model_file = os.path.join(best_output_dir, \"pytorch_model.bin\")\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)  \n",
    "                    \n",
    "\n",
    "    if (global_step + 1) % valid_bleu_steps == 0:\n",
    "        model.eval() \n",
    "        p=[]\n",
    "        for data in valid_dataloader:\n",
    "            data = data.to(device)\n",
    "            subgraph_node_num = torch.stack(torch.split(data.subgraph_node_num, max_subgraph_num))\n",
    "            real_graph_num = torch.stack(torch.split(data.real_graph_num, 1))\n",
    "            target_ids = torch.stack(torch.split(data.target_ids, max_target_length))\n",
    "            target_mask = torch.stack(torch.split(data.target_mask, max_target_length))                  \n",
    "            with torch.no_grad():\n",
    "                preds = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, batch=data.batch, \n",
    "                                subgraph_node_num=subgraph_node_num, real_graph_num=real_graph_num, ptr=data.ptr)\n",
    "                for pred in preds:\n",
    "                    t=pred[0].cpu().numpy()\n",
    "                    t=list(t)\n",
    "                    if 0 in t:\n",
    "                        t=t[:t.index(0)]\n",
    "                    text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "                    p.append(text)\n",
    "        predictions=[]\n",
    "        with open(os.path.join(output_dir,\"valid.output\"),'w', encoding='utf-8') as f, open(os.path.join(output_dir,\"valid.gold\"),'w', encoding='utf-8') as f1:\n",
    "            for ref, gold in zip(p, valid_examples):\n",
    "                predictions.append(str(gold.idx)+'\\t'+ref)\n",
    "                f.write(str(gold.idx)+'\\t'+ref+'\\n')\n",
    "                f1.write(str(gold.idx)+'\\t'+gold.target+'\\n')     \n",
    "\n",
    "        (goldMap, predictionMap) = bleu.computeMaps(predictions, os.path.join(output_dir, \"valid.gold\")) \n",
    "        valid_bleu=round(bleu.bleuFromMaps(goldMap, predictionMap)[0],2)\n",
    "        msgr.print_msg(\"  {} = {}\".format(\"bleu-4\", str(valid_bleu)))\n",
    "        msgr.print_msg(\"  \"+\"*\"*20)    \n",
    "        if valid_bleu>best_bleu:\n",
    "            msgr.print_msg(\"  Best bleu:{}\".format(valid_bleu))\n",
    "            msgr.print_msg(\"  \"+\"*\"*20)\n",
    "            best_bleu=valid_bleu\n",
    "            # Save best checkpoint for best bleu\n",
    "            best_output_dir = os.path.join(output_dir, 'checkpoint-best-bleu')\n",
    "            if not os.path.exists(best_output_dir):\n",
    "                os.makedirs(best_output_dir)\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "            output_model_file = os.path.join(best_output_dir, \"pytorch_model.bin\")\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        \n",
    "    model.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fcaf9ee760485a9137ef34614f8b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=273), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn  bleu-4 = 20.98 \n",
      "dgnn   ********************\n"
     ]
    }
   ],
   "source": [
    "# Calculate bleu\n",
    "test_sampler = SequentialSampler(test_features)\n",
    "test_dataloader = DataLoader(test_features, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "best_ppl_model = output_dir + '/checkpoint-best-ppl/pytorch_model.bin' \n",
    "model.load_state_dict(torch.load(best_ppl_model))\n",
    "model.eval() \n",
    "p=[]\n",
    "for data in tqdm(test_dataloader,total=len(test_dataloader)):\n",
    "    data = data.to(device)\n",
    "    subgraph_node_num = torch.stack(torch.split(data.subgraph_node_num, max_subgraph_num))\n",
    "    real_graph_num = torch.stack(torch.split(data.real_graph_num, 1))\n",
    "    target_ids = torch.stack(torch.split(data.target_ids, max_target_length))\n",
    "    target_mask = torch.stack(torch.split(data.target_mask, max_target_length))                     \n",
    "    with torch.no_grad():\n",
    "        preds = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, subgraph_node_num=subgraph_node_num, \n",
    "                        real_graph_num=real_graph_num, batch=data.batch, ptr=data.ptr)\n",
    "        for pred in preds:\n",
    "            t=pred[0].cpu().numpy()\n",
    "            t=list(t)\n",
    "            if 0 in t:\n",
    "                t=t[:t.index(0)]\n",
    "            text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "            p.append(text)\n",
    "model.train()\n",
    "predictions=[]\n",
    "with open(os.path.join(output_dir,\"test.output\"),'w', encoding='utf-8') as f, open(os.path.join(output_dir,\"test.gold\"),'w', encoding='utf-8') as f1:\n",
    "    for ref,gold in zip(p,test_examples):\n",
    "        predictions.append(str(gold.idx)+'\\t'+ref)\n",
    "        f.write(str(gold.idx)+'\\t'+ref+'\\n')\n",
    "        f1.write(str(gold.idx)+'\\t'+gold.target+'\\n')     \n",
    "\n",
    "(goldMap, predictionMap) = bleu.computeMaps(predictions, os.path.join(output_dir, \"test.gold\")) \n",
    "dev_bleu=round(bleu.bleuFromMaps(goldMap, predictionMap)[0],2)\n",
    "msgr.print_msg(\" {} = {} \".format(\"bleu-4\", str(dev_bleu)))\n",
    "msgr.print_msg(\"  \"+\"*\"*20)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447f6a0e249045d395d9a46db51cefad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=273), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn  bleu-4 = 23.13 \n",
      "dgnn   ********************\n"
     ]
    }
   ],
   "source": [
    "best_bleu_model = output_dir + '/checkpoint-best-bleu/pytorch_model.bin' \n",
    "model.load_state_dict(torch.load(best_bleu_model))\n",
    "model.eval() \n",
    "p=[]\n",
    "for data in tqdm(test_dataloader,total=len(test_dataloader)):\n",
    "    data = data.to(device)\n",
    "    subgraph_node_num = torch.stack(torch.split(data.subgraph_node_num, max_subgraph_num))\n",
    "    real_graph_num = torch.stack(torch.split(data.real_graph_num, 1))\n",
    "    target_ids = torch.stack(torch.split(data.target_ids, max_target_length))\n",
    "    target_mask = torch.stack(torch.split(data.target_mask, max_target_length))                 \n",
    "    with torch.no_grad():\n",
    "        preds = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, subgraph_node_num=subgraph_node_num, \n",
    "                        real_graph_num=real_graph_num, batch=data.batch, ptr=data.ptr)\n",
    "        for pred in preds:\n",
    "            t=pred[0].cpu().numpy()\n",
    "            t=list(t)\n",
    "            if 0 in t:\n",
    "                t=t[:t.index(0)]\n",
    "            text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "            p.append(text)\n",
    "model.train()\n",
    "predictions=[]\n",
    "with open(os.path.join(output_dir,\"checkpoint-best-bleu/test.output\"),'w', encoding='utf-8') as f, open(os.path.join(output_dir,\"checkpoint-best-bleu/test.gold\"),'w', encoding='utf-8') as f1:\n",
    "    for ref,gold in zip(p,test_examples):\n",
    "        predictions.append(str(gold.idx)+'\\t'+ref)\n",
    "        f.write(str(gold.idx)+'\\t'+ref+'\\n')\n",
    "        f1.write(str(gold.idx)+'\\t'+gold.target+'\\n')     \n",
    "\n",
    "(goldMap, predictionMap) = bleu.computeMaps(predictions, os.path.join(output_dir, \"test.gold\")) \n",
    "dev_bleu=round(bleu.bleuFromMaps(goldMap, predictionMap)[0],2)\n",
    "msgr.print_msg(\" {} = {} \".format(\"bleu-4\", str(dev_bleu)))\n",
    "msgr.print_msg(\"  \"+\"*\"*20)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173eb5a6539f4f978c2effea257eb342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=273), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total: 8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn  bleu-4 = 23.13 \n",
      "dgnn   ********************\n"
     ]
    }
   ],
   "source": [
    "last_model = output_dir + '/checkpoint-last/pytorch_model.bin' \n",
    "model.load_state_dict(torch.load(last_model))\n",
    "model.eval() \n",
    "p=[]\n",
    "for data in tqdm(test_dataloader,total=len(test_dataloader)):\n",
    "    data = data.to(device)\n",
    "    subgraph_node_num = torch.stack(torch.split(data.subgraph_node_num, max_subgraph_num))\n",
    "    real_graph_num = torch.stack(torch.split(data.real_graph_num, 1))\n",
    "    target_ids = torch.stack(torch.split(data.target_ids, max_target_length))\n",
    "    target_mask = torch.stack(torch.split(data.target_mask, max_target_length))                   \n",
    "    with torch.no_grad():\n",
    "        preds = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, subgraph_node_num=subgraph_node_num, \n",
    "                        real_graph_num=real_graph_num, batch=data.batch, ptr=data.ptr)\n",
    "        for pred in preds:\n",
    "            t=pred[0].cpu().numpy()\n",
    "            t=list(t)\n",
    "            if 0 in t:\n",
    "                t=t[:t.index(0)]\n",
    "            text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "            p.append(text)\n",
    "model.train()\n",
    "predictions=[]\n",
    "with open(os.path.join(output_dir,\"checkpoint-last/test.output\"),'w', encoding='utf-8') as f, open(os.path.join(output_dir,\"checkpoint-last/test.gold\"),'w', encoding='utf-8') as f1:\n",
    "    for ref,gold in zip(p,test_examples):\n",
    "        predictions.append(str(gold.idx)+'\\t'+ref)\n",
    "        f.write(str(gold.idx)+'\\t'+ref+'\\n')\n",
    "        f1.write(str(gold.idx)+'\\t'+gold.target+'\\n')     \n",
    "\n",
    "(goldMap, predictionMap) = bleu.computeMaps(predictions, os.path.join(output_dir, \"test.gold\")) \n",
    "dev_bleu=round(bleu.bleuFromMaps(goldMap, predictionMap)[0],2)\n",
    "msgr.print_msg(\" {} = {} \".format(\"bleu-4\", str(dev_bleu)))\n",
    "msgr.print_msg(\"  \"+\"*\"*20)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
