{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import yaml\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd \n",
    "import javalang\n",
    "from javalang.ast import Node\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import (Module, Embedding, LSTM, Sequential, Linear, BatchNorm1d, ReLU, Sigmoid, CrossEntropyLoss, TransformerDecoderLayer,\n",
    "                        TransformerDecoder)\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn.glob import GlobalAttention\n",
    "from torch_geometric.nn import MessagePassing, GatedGraphConv, GCNConv, global_mean_pool, GINEConv, global_add_pool\n",
    "from anytree import AnyNode\n",
    "from torch_geometric.data import Data, DataLoader, ClusterData, ClusterLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import random\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel, DataCollatorWithPadding, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, SequentialSampler\n",
    "import json\n",
    "from codebert_seq2seq4 import Seq2Seq\n",
    "import bleu\n",
    "import bleu\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "config_file = 'config_dgnn.yml'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "config = yaml.load(open(config_file), Loader=yaml.FullLoader)\n",
    "\n",
    "# data source\n",
    "TRAIN_DIR = config['data']['train']\n",
    "VALID_DIR = config['data']['valid']\n",
    "TEST_DIR = config['data']['test']\n",
    "\n",
    "\n",
    "# prepocess design\n",
    "max_source_length = config['preprocess']['max_source_length']\n",
    "max_target_length = config['preprocess']['max_target_length']\n",
    "\n",
    "\n",
    "# training parameter\n",
    "batch_size = config['training']['batch_size']\n",
    "num_epoches = config['training']['num_epoches']\n",
    "lr = config['training']['lr']\n",
    "decay_ratio = config['training']['lr']\n",
    "save_name = config['training']['save_name']\n",
    "warm_up = config['training']['warm_up']\n",
    "patience = config['training']['patience']\n",
    "\n",
    "# model design\n",
    "graph_embedding_size = config['model']['graph_embedding_size']\n",
    "lstm_hidden_size = config['model']['lstm_hidden_size']\n",
    "divide_node_num = config['model']['divide_node_num']\n",
    "gnn_layers_num = config['model']['gnn_layers_num']\n",
    "lstm_layers_num = config['model']['lstm_layers_num']\n",
    "decoder_input_size = config['model']['decoder_input_size']\n",
    "decoder_hidden_size = config['model']['decoder_hidden_size']\n",
    "decoder_num_layers = config['model']['decoder_num_layers']\n",
    "decoder_rnn_dropout = config['model']['decoder_rnn_dropout']\n",
    "\n",
    "# logs\n",
    "info_prefix = config['logs']['info_prefix']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "MAX_NODE_NUM = 300 # the max num of subgraph, set for zero padding \n",
    "max_subgraph_num = int(MAX_NODE_NUM/divide_node_num) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "run_id = datetime.now().strftime('%Y-%m-%d--%H-%M-%S')\n",
    "log_file = 'logs/' + run_id + '.log'\n",
    "exp_dir = 'runs/' + run_id\n",
    "os.mkdir(exp_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Info(object):\n",
    "    def __init__(self, info_prefix=''):\n",
    "        self.info_prefix = info_prefix\n",
    "    \n",
    "    def print_msg(self, msg):\n",
    "        text = self.info_prefix + ' ' + msg\n",
    "        print(text)\n",
    "        logging.info(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "logging.basicConfig(format='%(asctime)s | %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', filename=log_file, level=logging.DEBUG)\n",
    "msgr = Info(info_prefix)\n",
    "\n",
    "msgr.print_msg('run_id : {}'.format(run_id))\n",
    "msgr.print_msg('log_file : {}'.format(log_file))\n",
    "msgr.print_msg('exp_dir: {}'.format(exp_dir))\n",
    "msgr.print_msg(str(config))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dgnn run_id : 2021-08-03--15-15-07\n",
      "dgnn log_file : logs/2021-08-03--15-15-07.log\n",
      "dgnn exp_dir: runs/2021-08-03--15-15-07\n",
      "dgnn {'data': {'train': '/data/code/represent-code-in-human/data/code-summarization-enhanced-full/train_utf8.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-enhanced-full/valid_utf8.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-enhanced-full/test_utf8.jsonl'}, 'small_data': {'train': '/data/code/represent-code-in-human/data/code-summarization-enhanced-small/train_utf8.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-enhanced-small/valid_utf8.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-enhanced-small/test_utf8.jsonl'}, 'middle_data': {'train': '/data/code/represent-code-in-human/data/code-summarization-enhanced-middle/train_utf8.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-enhanced-middle/valid_utf8.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-enhanced-middle/test_utf8.jsonl'}, 'ccd_data': {'data': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/data.jsonl', 'train': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/train.txt', 'valid': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/test.txt', 'test': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/valid.txt'}, 'preprocess': {'max_source_length': 256, 'max_target_length': 32}, 'training': {'batch_size': 128, 'num_epoches': 100, 'lr': 0.001, 'decay_ratio': 0.95, 'save_name': '/model.pth', 'warm_up': 5, 'patience': 10}, 'model': {'graph_embedding_size': 768, 'gnn_layers_num': 2, 'lstm_layers_num': 3, 'lstm_hidden_size': 128, 'divide_node_num': 30, 'decoder_input_size': 768, 'decoder_hidden_size': 128, 'decoder_num_layers': 2, 'decoder_rnn_dropout': 0.5, 'gine_dim': 128}, 'logs': {'info_prefix': 'dgnn'}}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepocess"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# use javalang to generate ASTs and depth-first traverse to generate ast nodes corpus\n",
    "def get_token(node):\n",
    "    token = 'None'\n",
    "    if isinstance(node, str):\n",
    "        token = node\n",
    "    elif isinstance(node, set):\n",
    "        token = 'Modifier'\n",
    "    elif isinstance(node, Node):\n",
    "        token = node.__class__.__name__\n",
    "    return token\n",
    "\n",
    "\n",
    "def get_child(root):\n",
    "    if isinstance(root, Node):\n",
    "        children = root.children\n",
    "    elif isinstance(root, set):\n",
    "        children = list(root)\n",
    "    else:\n",
    "        children = []\n",
    "\n",
    "    def expand(nested_list):\n",
    "        for item in nested_list:\n",
    "            if isinstance(item, list):\n",
    "                for sub_item in expand(item):\n",
    "                    yield sub_item\n",
    "            elif item:\n",
    "                yield item\n",
    "\n",
    "    return list(expand(children))\n",
    "\n",
    "\n",
    "def get_sequence(node, sequence):\n",
    "    token, children = get_token(node), get_child(node)\n",
    "    sequence.append(token)\n",
    "    for child in children:\n",
    "        get_sequence(child, sequence)\n",
    "\n",
    "\n",
    "def parse_program(func):\n",
    "    tokens = javalang.tokenizer.tokenize(func)\n",
    "    parser = javalang.parser.Parser(tokens)\n",
    "    tree = parser.parse_member_declaration()\n",
    "    return tree"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "checkpoint = 'microsoft/codebert-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(checkpoint)\n",
    "ast_tokenizer = RobertaTokenizer.from_pretrained(checkpoint)\n",
    "roberta = RobertaModel.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "config = RobertaConfig.from_pretrained(checkpoint)\n",
    "javalang_special_tokens = ['CompilationUnit','Import','Documented','Declaration','TypeDeclaration','PackageDeclaration',\n",
    "                            'ClassDeclaration','EnumDeclaration','InterfaceDeclaration','AnnotationDeclaration','Type',\n",
    "                            'BasicType','ReferenceType','TypeArgument','TypeParameter','Annotation','ElementValuePair',\n",
    "                            'ElementArrayValue','Member','MethodDeclaration','FieldDeclaration','ConstructorDeclaration',\n",
    "                            'ConstantDeclaration','ArrayInitializer','VariableDeclaration','LocalVariableDeclaration',\n",
    "                            'VariableDeclarator','FormalParameter','InferredFormalParameter','Statement','IfStatement',\n",
    "                            'WhileStatement','DoStatement','ForStatement','AssertStatement','BreakStatement','ContinueStatement',\n",
    "                            'ReturnStatement','ThrowStatement','SynchronizedStatement','TryStatement','SwitchStatement',\n",
    "                            'BlockStatement','StatementExpression','TryResource','CatchClause','CatchClauseParameter',\n",
    "                            'SwitchStatementCase','ForControl','EnhancedForControl','Expression','Assignment','TernaryExpression',\n",
    "                            'BinaryOperation','Cast','MethodReference','LambdaExpression','Primary','Literal','This',\n",
    "                            'MemberReference','Invocation','ExplicitConstructorInvocation','SuperConstructorInvocation',\n",
    "                            'MethodInvocation','SuperMethodInvocation','SuperMemberReference','ArraySelector','ClassReference',\n",
    "                            'VoidClassReference','Creator','ArrayCreator','ClassCreator','InnerClassCreator','EnumBody',\n",
    "                            'EnumConstantDeclaration','AnnotationMethod', 'Modifier']\n",
    "special_tokens_dict = {'additional_special_tokens': javalang_special_tokens}\n",
    "num_added_toks = ast_tokenizer.add_special_tokens(special_tokens_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#  generate tree for AST Node\n",
    "def create_tree(root, node, node_list, sub_id_list, leave_list, tokenizer, parent=None):\n",
    "    id = len(node_list)\n",
    "    node_list.append(node)\n",
    "    token, children = get_token(node), get_child(node)\n",
    "\n",
    "    if children == []:\n",
    "        # print('this is a leaf:', token, id)\n",
    "        leave_list.append(id)\n",
    "\n",
    "    # Use roberta.tokenizer to generate subtokens\n",
    "    # If a token can be divided into multiple(>1) subtokens, the first subtoken will be set as the previous node, \n",
    "    # and the other subtokens will be set as its new children\n",
    "    token = token.encode('utf-8','ignore').decode(\"utf-8\")   \n",
    "    sub_token_list = tokenizer.tokenize(token)\n",
    "    \n",
    "    if id == 0:\n",
    "        root.token = sub_token_list[0] # the root node is one of the tokenizer's special tokens\n",
    "        root.data = node\n",
    "        # record the num of nodes for every children of root\n",
    "        root_children_node_num = []\n",
    "        for child in children:\n",
    "            node_num = len(node_list)\n",
    "            create_tree(root, child, node_list, sub_id_list, leave_list, tokenizer, parent=root)\n",
    "            root_children_node_num.append(len(node_list) - node_num)        \n",
    "        return root_children_node_num\n",
    "    else:\n",
    "        # print(sub_token_list)\n",
    "        new_node = AnyNode(id=id, token=sub_token_list[0], data=node, parent=parent)\n",
    "        if len(sub_token_list) > 1:\n",
    "            sub_id_list.append(id)\n",
    "            for sub_token in sub_token_list[1:]:\n",
    "                id += 1\n",
    "                AnyNode(id=id, token=sub_token, data=node, parent=new_node)\n",
    "                node_list.append(sub_token)\n",
    "                sub_id_list.append(id)\n",
    "        \n",
    "        for child in children:\n",
    "            create_tree(root, child, node_list, sub_id_list, leave_list, tokenizer, parent=new_node)\n",
    "    # print(token, id)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# traverse the AST tree to get all the nodes and edges\n",
    "def get_node_and_edge(node, node_index_list, tokenizer, src, tgt, variable_token_list, variable_id_list):\n",
    "    token = node.token\n",
    "    node_index_list.append(tokenizer.convert_tokens_to_ids(token))\n",
    "    # node_index_list.append([vocab_dict.word2id.get(token, UNK)])\n",
    "    # find out all variables\n",
    "    if token in ['VariableDeclarator', 'MemberReference']:\n",
    "        variable_token_list.append(node.children[0].token)\n",
    "        variable_id_list.append(node.children[0].id)   \n",
    "    \n",
    "    for child in node.children:\n",
    "        src.append(node.id)\n",
    "        tgt.append(child.id)\n",
    "        src.append(child.id)\n",
    "        tgt.append(node.id)\n",
    "        get_node_and_edge(child, node_index_list, tokenizer, src, tgt, variable_token_list, variable_id_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# generate pytorch_geometric input format data from ast\n",
    "def get_pyg_data_from_ast(ast, tokenizer):\n",
    "    node_list = []\n",
    "    sub_id_list = [] # record the ids of node that can be divide into multple subtokens\n",
    "    leave_list = [] # record the ids of leave \n",
    "    new_tree = AnyNode(id=0, token=None, data=None)\n",
    "    root_children_node_num = create_tree(new_tree, ast, node_list, sub_id_list, leave_list, tokenizer)\n",
    "    # print('root_children_node_num', root_children_node_num)\n",
    "    x = []\n",
    "    edge_src = []\n",
    "    edge_tgt = []\n",
    "    # record variable tokens and ids to add data flow edge in AST graph\n",
    "    variable_token_list = []\n",
    "    variable_id_list = []\n",
    "    get_node_and_edge(new_tree, x, tokenizer, edge_src, edge_tgt, variable_token_list, variable_id_list)\n",
    "\n",
    "    ast_edge_num = len(edge_src)\n",
    "    edge_attr = [[0] for _ in range(ast_edge_num)]\n",
    "    # set subtoken edge type to 2\n",
    "    for i in range(len(edge_attr)):\n",
    "        if edge_src[i] in sub_id_list and edge_tgt[i] in sub_id_list:\n",
    "            edge_attr[i] = [2]\n",
    "    # add data flow edge\n",
    "    variable_dict = {}\n",
    "    for i in range(len(variable_token_list)):\n",
    "        # print('variable_dict', variable_dict)\n",
    "        if variable_token_list[i] not in variable_dict:\n",
    "            variable_dict.setdefault(variable_token_list[i], variable_id_list[i])\n",
    "        else:\n",
    "            # print('edge', variable_dict.get(variable_token_list[i]), variable_id_list[i])\n",
    "            edge_src.append(variable_dict.get(variable_token_list[i]))\n",
    "            edge_tgt.append(variable_id_list[i])\n",
    "            edge_src.append(variable_id_list[i])\n",
    "            edge_tgt.append(variable_dict.get(variable_token_list[i]))\n",
    "            variable_dict[variable_token_list[i]] = variable_id_list[i]\n",
    "    dataflow_edge_num = len(edge_src) - ast_edge_num\n",
    "\n",
    "    # add next-token edge\n",
    "    nexttoken_edge_num = len(leave_list)-1\n",
    "    for i in range(nexttoken_edge_num):\n",
    "        edge_src.append(leave_list[i])\n",
    "        edge_tgt.append(leave_list[i+1])\n",
    "        edge_src.append(leave_list[i+1])\n",
    "        edge_tgt.append(leave_list[i])\n",
    "\n",
    "    edge_index = [edge_src, edge_tgt]\n",
    "\n",
    "    # set data flow edge type to 1\n",
    "    for _ in range(dataflow_edge_num):\n",
    "        edge_attr.append([1])\n",
    "    \n",
    "    # set data flow edge type to 3\n",
    "    for _ in range(nexttoken_edge_num * 2):\n",
    "        edge_attr.append([3])\n",
    "    \n",
    "    return x, edge_index, edge_attr, root_children_node_num"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# def get_ast_statistic(data):\n",
    "#     node_num = []\n",
    "#     edge_num = []\n",
    "#     sub_node_num = []\n",
    "#     for code in tqdm(data['code']):\n",
    "#         x, edge_index, edge_attr, root_children_node_num = get_pyg_data_from_ast(parse_program(code), tokenizer)\n",
    "#         node_num.append(len(x))\n",
    "#         edge_num.append(len(edge_attr))\n",
    "#         sub_node_num.append(sum(root_children_node_num))\n",
    "#     return node_num, edge_num, sub_node_num\n",
    "\n",
    "# train_data = pd.read_json(TRAIN_DIR, lines=True)\n",
    "# valid_data = pd.read_json(VALID_DIR, lines=True)\n",
    "# test_data = pd.read_json(TEST_DIR, lines=True)\n",
    "\n",
    "# train_node_num, train_edge_num, train_sub_node_num = get_ast_statistic(train_data)\n",
    "# valid_node_num, valid_edge_num, valid_sub_node_num = get_ast_statistic(valid_data)\n",
    "# test_node_num, test_edge_num, test_sub_node_num = get_ast_statistic(test_data)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=164814), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8f40358687a4c6493a2e5331d16edcc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5179), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9aecf51989e412cb2749a7feaadf240"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10952), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfe94fea78f9492fba2cd380fe854000"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# train_sub_node_series = pd.Series(train_sub_node_num)\n",
    "# train_sub_node_series.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    164814.000000\n",
       "mean        136.569824\n",
       "std         120.903685\n",
       "min          20.000000\n",
       "25%          59.000000\n",
       "50%          94.000000\n",
       "75%         166.000000\n",
       "max        3240.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "\n",
    "def get_subgraph_node_num(root_children_node_num, divide_node_num):\n",
    "    subgraph_node_num = []\n",
    "    node_sum = 0\n",
    "    real_graph_num = 0\n",
    "    for num in root_children_node_num:\n",
    "        node_sum += num\n",
    "        if node_sum >= divide_node_num:\n",
    "            subgraph_node_num.append(node_sum)\n",
    "            node_sum = 0    \n",
    "    \n",
    "    subgraph_node_num.append(node_sum)\n",
    "    real_graph_num = len(subgraph_node_num)\n",
    "\n",
    "    if real_graph_num >= max_subgraph_num:\n",
    "        return subgraph_node_num[: max_subgraph_num], max_subgraph_num\n",
    "\n",
    "    # print(len(subgraph_node_num))\n",
    "    # if the last subgraph node num < divide_node_num, then put the last subgraph to the second to last subgraph\n",
    "    # if subgraph_node_num[-1] < divide_node_num:\n",
    "    #     subgraph_node_num[-2] = subgraph_node_num[-2] + subgraph_node_num[-1]\n",
    "    #     subgraph_node_num[-1] = 0\n",
    "    #     real_graph_num -= 1\n",
    "\n",
    "    # zero padding for tensor transforming\n",
    "    for _ in range(real_graph_num, max_subgraph_num):\n",
    "        subgraph_node_num.append(0)\n",
    "    \n",
    "    return subgraph_node_num, real_graph_num"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def convert_examples_to_features(examples, ast_tokenizer, tokenizer, stage=None):\n",
    "    features = []\n",
    "    for example in tqdm(examples):\n",
    "        # pyg\n",
    "        ast = parse_program(example.source)\n",
    "        x, edge_index, edge_attr, root_children_node_num = get_pyg_data_from_ast(ast, ast_tokenizer)\n",
    "        subgraph_node_num, real_graph_num = get_subgraph_node_num(root_children_node_num, divide_node_num)\n",
    "\n",
    "        # source\n",
    "        source_tokens = tokenizer.tokenize(example.ast_des)[: max_source_length-2]\n",
    "        source_tokens = [tokenizer.cls_token] + source_tokens + [tokenizer.sep_token]\n",
    "        source_ids = tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "        source_mask = [1] * (len(source_ids))\n",
    "        padding_length = max_source_length - len(source_ids)\n",
    "        source_ids += [tokenizer.pad_token_id] * padding_length\n",
    "        source_mask += [0] * padding_length\n",
    "\n",
    "        # target\n",
    "        if stage == 'test':\n",
    "            target_tokens = tokenizer.tokenize('None')\n",
    "        else:\n",
    "            target_tokens = tokenizer.tokenize(example.target)[: max_target_length-2]\n",
    "        target_tokens = [tokenizer.cls_token] + target_tokens + [tokenizer.sep_token]\n",
    "        target_ids = tokenizer.convert_tokens_to_ids(target_tokens)\n",
    "        target_mask = [1] * len(target_ids)\n",
    "        padding_length = max_target_length - len(target_ids)\n",
    "        target_ids += [tokenizer.pad_token_id] * padding_length\n",
    "        target_mask += [0] * padding_length\n",
    "\n",
    "        features.append(\n",
    "            Data(\n",
    "                x= torch.tensor(x, dtype=torch.long),\n",
    "                edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
    "                edge_attr=torch.tensor(edge_attr, dtype=torch.long),\n",
    "                source_ids=torch.tensor(source_ids, dtype=torch.long),\n",
    "                source_mask=torch.tensor(source_mask, dtype=torch.long),\n",
    "                target_ids=torch.tensor(target_ids, dtype=torch.long),\n",
    "                target_mask=torch.tensor(target_mask, dtype=torch.long),\n",
    "                subgraph_node_num=torch.tensor(subgraph_node_num, dtype=torch.long),\n",
    "                real_graph_num=torch.tensor(real_graph_num, dtype=torch.long)\n",
    "            )\n",
    "        )\n",
    "    return features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "class Example(object):\n",
    "    def __init__(self, idx, source, ast_des, target):\n",
    "        self.idx = idx\n",
    "        self.source = source\n",
    "        self.ast_des = ast_des\n",
    "        self.target = target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# read dataset\n",
    "def read_examples(filename):\n",
    "    examples = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            js = json.loads(line)\n",
    "            if 'idx' not in js:\n",
    "                js['idx'] = idx\n",
    "            \n",
    "            code = js['code']\n",
    "            nl = ' '.join(js['docstring_tokens']).replace('\\n', '')\n",
    "            nl = ' '.join(nl.strip().split())\n",
    "            ast_des = js['ast_des']\n",
    "            examples.append(\n",
    "                Example(\n",
    "                    idx = idx,\n",
    "                    source = code,\n",
    "                    ast_des = ast_des,\n",
    "                    target = nl,\n",
    "                )\n",
    "            )\n",
    "    return examples"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "train_examples = read_examples(TRAIN_DIR)\n",
    "valid_examples = read_examples(VALID_DIR)\n",
    "test_examples = read_examples(TEST_DIR)\n",
    "msgr.print_msg('train size: {}, valid size: {}, test size: {}'.format(len(train_examples), len(valid_examples), len(test_examples)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dgnn train size: 164814, valid size: 5179, test size: 10952\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "train_features = convert_examples_to_features(train_examples, ast_tokenizer, tokenizer, stage='train')\n",
    "valid_features = convert_examples_to_features(valid_examples, ast_tokenizer, tokenizer, stage='valid')\n",
    "test_features = convert_examples_to_features(test_examples, ast_tokenizer, tokenizer, stage='test')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=164814), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6edf5584149341df8e89a7bcdb30c465"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5179), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f422164984db4a1892e6ce99f5bc98be"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10952), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93bd99fbf4a84478935e98dd586b2c8f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "torch.save(train_features,'features/pgnn/train_features.pt')\n",
    "torch.save(valid_features,'features/pgnn/valid_features.pt')\n",
    "torch.save(test_features,'features/pgnn/test_features.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_features = torch.load('features/pgnn/train_features.pt')\n",
    "valid_features = torch.load('features/pgnn/valid_features.pt')\n",
    "test_features = torch.load('features/pgnn/test_features.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class GNNEncoder(Module):\n",
    "    def __init__(self, vocab_len, graph_embedding_size, gnn_layers_num, lstm_layers_num, lstm_hidden_size, decoder_input_size, device):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.embeddings = Embedding(vocab_len, graph_embedding_size)\n",
    "        self.edge_embed = Embedding(4, 1) # only two edge types to be set weights, which are AST edge and data flow edge\n",
    "        self.ggnnlayer = GatedGraphConv(graph_embedding_size, gnn_layers_num)\n",
    "        self.mlp_gate = Sequential(\n",
    "            Linear(graph_embedding_size, 300), Sigmoid(), Linear(300, 1), Sigmoid())\n",
    "        self.pool = GlobalAttention(gate_nn=self.mlp_gate)\n",
    "        self.lstm = LSTM(input_size=graph_embedding_size, hidden_size=lstm_hidden_size, num_layers=lstm_layers_num)\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_layers_num = lstm_layers_num\n",
    "        self.fc = Linear(graph_embedding_size + lstm_hidden_size, decoder_input_size)\n",
    "\n",
    "    def subgraph_forward(self, x, edge_index, edge_attr, batch):\n",
    "        if type(edge_attr) == type(None):\n",
    "            edge_weight = None\n",
    "        else:\n",
    "            edge_weight = self.edge_embed(edge_attr)\n",
    "            edge_weight = edge_weight.squeeze(1)\n",
    "        x = self.ggnnlayer(x, edge_index, edge_weight)\n",
    "        return self.pool(x, batch=batch)\n",
    "    \n",
    "    # partitioning multiple subgraphs by dynamic allocating edges\n",
    "    def partition_graph(self, x, edge_index, edge_attr, subgraph_node_num, real_graph_num, ptr):        \n",
    "        nodes_list = [] # record all nodes number for each subgraph in total batch\n",
    "        subgraph_num = max(real_graph_num)\n",
    "\n",
    "        batch_size = subgraph_node_num.size(0)\n",
    "        start_node_num = [1 for _ in range(batch_size)]\n",
    "        for i in range(subgraph_num):\n",
    "            subgraph_nodes_list = []\n",
    "            for j in range(batch_size):\n",
    "                if subgraph_node_num[j][i] != 0:\n",
    "                    for k in range(ptr[j]+start_node_num[j], ptr[j]+start_node_num[j]+subgraph_node_num[j][i]):\n",
    "                        subgraph_nodes_list.append(k)\n",
    "                    start_node_num[j] += subgraph_node_num[j][i]\n",
    "            nodes_list.append(subgraph_nodes_list)\n",
    "\n",
    "        # only count the edge whose target node in subgraph\n",
    "        sub_edge_src = [[] for _ in range(subgraph_num)]\n",
    "        sub_edge_tgt = [[] for _ in range(subgraph_num)]\n",
    "        sub_edge_attr = [[] for _ in range(subgraph_num)]\n",
    "        # print('nodes_list', nodes_list)\n",
    "        node_num = len(x)\n",
    "        node_subgraph_index = [0 for _ in range(node_num)] # use a list to store the subgraph numbers for all nodes\n",
    "        for i in range(len(nodes_list)):\n",
    "            for node in nodes_list[i]:\n",
    "                node_subgraph_index[node] = i\n",
    "\n",
    "        for i in range(len(edge_index[1])):\n",
    "            src = edge_index[0][i].item()\n",
    "            tgt = edge_index[1][i].item()\n",
    "            sub_edge_src[node_subgraph_index[tgt]].append(src)\n",
    "            sub_edge_tgt[node_subgraph_index[tgt]].append(tgt)\n",
    "            sub_edge_attr[node_subgraph_index[tgt]].append(edge_attr[i].item())\n",
    "        edge_index_list = []\n",
    "        edge_attr_list = []\n",
    "        for i in range(subgraph_num):\n",
    "            edge_index_list.append(torch.tensor([sub_edge_src[i], sub_edge_tgt[i]], dtype=torch.long))\n",
    "            edge_attr_list.append(torch.tensor(sub_edge_attr[i], dtype=torch.long))\n",
    "        # print('nodes_list', nodes_list)\n",
    "        return edge_index_list, edge_attr_list  \n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, subgraph_node_num, real_graph_num, batch, ptr):\n",
    "        edge_index_list, edge_attr_list = self.partition_graph(x, edge_index, edge_attr, subgraph_node_num, real_graph_num, ptr)\n",
    "        # print('edge_index_list', edge_index_list)\n",
    "        # print('edge_attr_list', edge_attr_list)\n",
    "        x = self.embeddings(x)\n",
    "        x = x.squeeze(1)\n",
    "        subgraph_pool_list = [\n",
    "            self.subgraph_forward(x, edge_index_list[i].to(self.device), edge_attr_list[i].to(self.device), batch)\n",
    "            for i in range(len(edge_index_list))\n",
    "        ]\n",
    "        graph_pool = self.subgraph_forward(x, edge_index, edge_attr, batch)\n",
    "        # print('graph_pool', graph_pool.shape)\n",
    "        subgraph_pool_seq = torch.stack(subgraph_pool_list)\n",
    "        # print('subgraph_pool_seq', subgraph_pool_seq.shape)\n",
    "        h0 = torch.zeros(self.lstm_layers_num, subgraph_pool_seq.size(1) ,self.lstm_hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.lstm_layers_num, subgraph_pool_seq.size(1) ,self.lstm_hidden_size).to(self.device)\n",
    "        subgraph_output, (_, _) = self.lstm(subgraph_pool_seq, (h0, c0))\n",
    "        return self.fc(torch.cat((subgraph_output[-1], graph_pool), dim=1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "device = torch.device('cuda: 0')\n",
    "gnn_encoder = GNNEncoder(vocab_len=tokenizer.vocab_size+num_added_toks, graph_embedding_size=graph_embedding_size,\n",
    "                         gnn_layers_num=gnn_layers_num, lstm_layers_num=lstm_layers_num, lstm_hidden_size=lstm_hidden_size,\n",
    "                        decoder_input_size=decoder_input_size, device=device)\n",
    "decoder_layer = TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "decoder = TransformerDecoder(decoder_layer, num_layers=6)\n",
    "model = Seq2Seq(encoder=gnn_encoder, decoder=decoder, config=config, beam_size=10, max_length=max_target_length, \n",
    "                sos_id=tokenizer.cls_token_id, eos_id=tokenizer.sep_token_id)\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): GNNEncoder(\n",
       "    (embeddings): Embedding(50336, 768)\n",
       "    (edge_embed): Embedding(4, 1)\n",
       "    (ggnnlayer): GatedGraphConv(768, num_layers=2)\n",
       "    (mlp_gate): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=300, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=300, out_features=1, bias=True)\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "    (pool): GlobalAttention(gate_nn=Sequential(\n",
       "      (0): Linear(in_features=768, out_features=300, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=300, out_features=1, bias=True)\n",
       "      (3): Sigmoid()\n",
       "    ), nn=None)\n",
       "    (lstm): LSTM(768, 128, num_layers=3)\n",
       "    (fc): Linear(in_features=896, out_features=768, bias=True)\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  (lsm): LogSoftmax()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "max_source_length = 256\n",
    "max_target_length = 32\n",
    "batch_size = 32\n",
    "beam_size = 10\n",
    "lr = 5e-5\n",
    "warmup_steps = 0\n",
    "train_steps = 50000\n",
    "weight_decay = 0.0\n",
    "adam_epsilon = 1e-8\n",
    "valid_steps = 500\n",
    "output_dir = exp_dir\n",
    "\n",
    "train_url = TRAIN_DIR\n",
    "valid_url = VALID_DIR\n",
    "test_url = TEST_DIR"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "train_dataloader = DataLoader(train_features, batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# optimizer and schedule\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': weight_decay},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=train_steps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "from itertools import cycle\n",
    "\n",
    "#Start training\n",
    "msgr.print_msg(\"***** Running training *****\")\n",
    "msgr.print_msg(\"  Num examples = {}\".format(len(train_examples)))\n",
    "msgr.print_msg(\"  Batch size = {}\".format(batch_size))\n",
    "msgr.print_msg(\"  Num epoch = {}\".format(batch_size//len(train_examples)))\n",
    "model.train()\n",
    "valid_dataset = {}\n",
    "nb_tr_examples, nb_tr_steps, tr_loss, global_step, best_bleu, best_loss = 0, 0, 0, 0, 0, 1e6\n",
    "bar = tqdm(range(train_steps), total=train_steps)\n",
    "train_dataloader = cycle(train_dataloader)\n",
    "\n",
    "for step in bar:\n",
    "    data = next(train_dataloader)\n",
    "    data = data.to(device)\n",
    "    subgraph_node_num = torch.stack(torch.split(data.subgraph_node_num, max_subgraph_num))\n",
    "    real_graph_num = torch.stack(torch.split(data.real_graph_num, 1))\n",
    "    target_ids = torch.stack(torch.split(data.target_ids, max_target_length))\n",
    "    target_mask = torch.stack(torch.split(data.target_mask, max_target_length))  \n",
    "    loss, _, _, = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, subgraph_node_num=subgraph_node_num, \n",
    "                        real_graph_num=real_graph_num, batch=data.batch, ptr=data.ptr, target_ids=target_ids, target_mask=target_mask)\n",
    "\n",
    "    tr_loss += loss.item()\n",
    "    train_loss = round(tr_loss / (nb_tr_steps + 1), 4) \n",
    "    bar.set_description('loss {}'.format(train_loss))\n",
    "    nb_tr_examples += data.x.size(0)\n",
    "    nb_tr_steps += 1\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    scheduler.step()\n",
    "    global_step += 1\n",
    "    \n",
    "    if (global_step + 1) % valid_steps == 0:\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        valid_sampler = SequentialSampler(valid_features)\n",
    "        valid_dataloader = DataLoader(valid_features, sampler=valid_sampler, batch_size=batch_size)\n",
    "\n",
    "        msgr.print_msg(\"\\n***** Running evaluation *****\")\n",
    "        msgr.print_msg(\"  Num examples = {}\".format(len(valid_examples)))\n",
    "        msgr.print_msg(\"  Batch size = {}\".format(batch_size))\n",
    "\n",
    "        #Start Evaling model\n",
    "        model.eval()\n",
    "        valid_loss, tokens_num = 0, 0\n",
    "        for data in valid_dataloader:\n",
    "            data = data.to(device)\n",
    "            subgraph_node_num = torch.stack(torch.split(data.subgraph_node_num, max_subgraph_num))\n",
    "            real_graph_num = torch.stack(torch.split(data.real_graph_num, 1))\n",
    "            target_ids = torch.stack(torch.split(data.target_ids, max_target_length))\n",
    "            target_mask = torch.stack(torch.split(data.target_mask, max_target_length))            \n",
    "\n",
    "            with torch.no_grad():\n",
    "                _,loss,num = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, subgraph_node_num=subgraph_node_num, \n",
    "                        real_graph_num=real_graph_num, batch=data.batch, ptr=data.ptr)    \n",
    "            valid_loss += loss.sum().item()\n",
    "            tokens_num += num.sum().item()\n",
    "        #Pring loss of valid dataset    \n",
    "        model.train()\n",
    "        valid_loss = valid_loss / tokens_num\n",
    "        result = { 'valid_loss': valid_loss,\n",
    "                    'valid_ppl': round(np.exp(valid_loss), 5),\n",
    "                    'global_step': global_step+1,\n",
    "                    'train_loss': round(train_loss, 5)}\n",
    "        for key in sorted(result.keys()):\n",
    "            msgr.print_msg(\"{}= {}\".format(key, str(result[key])))\n",
    "        msgr.print_msg(\"  \"+\"*\"*20)   \n",
    "        \n",
    "        #save last checkpoint\n",
    "        last_output_dir = os.path.join(output_dir, 'checkpoint-last')\n",
    "        if not os.path.exists(last_output_dir):\n",
    "            os.makedirs(last_output_dir)\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "        output_model_file = os.path.join(last_output_dir, \"pytorch_model.bin\")\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)                    \n",
    "        if valid_loss < best_loss:\n",
    "            msgr.print_msg(\"  Best ppl:{}\".format(round(np.exp(valid_loss), 5)))\n",
    "            msgr.print_msg(\"  \" + \"*\" * 20)\n",
    "            best_loss = valid_loss\n",
    "            # Save best checkpoint for best ppl\n",
    "            best_output_dir = os.path.join(output_dir, 'checkpoint-best-ppl')\n",
    "            if not os.path.exists(best_output_dir):\n",
    "                os.makedirs(best_output_dir)\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "            output_model_file = os.path.join(best_output_dir, \"pytorch_model.bin\")\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)  \n",
    "                    \n",
    "                    \n",
    "        #Calculate bleu  \n",
    "        # if 'valid_bleu' in valid_dataset:\n",
    "        #     valid_examples, valid_features = valid_dataset['valid_bleu']\n",
    "        # else:\n",
    "        #     valid_examples = read_examples(valid_url)\n",
    "        #     valid_examples = random.sample(valid_examples, min(1000,len(valid_examples)))\n",
    "        #     valid_features = convert_examples_to_features(valid_examples, tokenizer,stage='test')  \n",
    "        #     valid_dataset['valid_bleu']= valid_examples, valid_features\n",
    "\n",
    "        # valid_sampler = SequentialSampler(valid_features)\n",
    "        # valid_dataloader = DataLoader(valid_features, sampler=valid_sampler, batch_size=batch_size)\n",
    "\n",
    "        model.eval() \n",
    "        p=[]\n",
    "        # i = 0\n",
    "        for data in valid_dataloader:\n",
    "            # print('i', i)\n",
    "            # i += 1\n",
    "            data = data.to(device)\n",
    "            subgraph_node_num = torch.stack(torch.split(data.subgraph_node_num, max_subgraph_num))\n",
    "            real_graph_num = torch.stack(torch.split(data.real_graph_num, 1))\n",
    "            target_ids = torch.stack(torch.split(data.target_ids, max_target_length))\n",
    "            target_mask = torch.stack(torch.split(data.target_mask, max_target_length))                  \n",
    "            with torch.no_grad():\n",
    "                preds = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, subgraph_node_num=subgraph_node_num, \n",
    "                        real_graph_num=real_graph_num, batch=data.batch, ptr=data.ptr)\n",
    "                for pred in preds:\n",
    "                    t=pred[0].cpu().numpy()\n",
    "                    t=list(t)\n",
    "                    if 0 in t:\n",
    "                        t=t[:t.index(0)]\n",
    "                    text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "                    p.append(text)\n",
    "        model.train()\n",
    "        predictions=[]\n",
    "        with open(os.path.join(output_dir,\"valid.output\"),'w', encoding='utf-8') as f, open(os.path.join(output_dir,\"valid.gold\"),'w', encoding='utf-8') as f1:\n",
    "            for ref, gold in zip(p, valid_examples):\n",
    "                predictions.append(str(gold.idx)+'\\t'+ref)\n",
    "                f.write(str(gold.idx)+'\\t'+ref+'\\n')\n",
    "                f1.write(str(gold.idx)+'\\t'+gold.target+'\\n')     \n",
    "\n",
    "        (goldMap, predictionMap) = bleu.computeMaps(predictions, os.path.join(output_dir, \"valid.gold\")) \n",
    "        valid_bleu=round(bleu.bleuFromMaps(goldMap, predictionMap)[0],2)\n",
    "        msgr.print_msg(\"  {} = {}\".format(\"bleu-4\", str(valid_bleu)))\n",
    "        msgr.print_msg(\"  \"+\"*\"*20)    \n",
    "        if valid_bleu>best_bleu:\n",
    "            msgr.print_msg(\"  Best bleu:{}\".format(valid_bleu))\n",
    "            msgr.print_msg(\"  \"+\"*\"*20)\n",
    "            best_bleu=valid_bleu\n",
    "            # Save best checkpoint for best bleu\n",
    "            best_output_dir = os.path.join(output_dir, 'checkpoint-best-bleu')\n",
    "            if not os.path.exists(best_output_dir):\n",
    "                os.makedirs(best_output_dir)\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "            output_model_file = os.path.join(best_output_dir, \"pytorch_model.bin\")\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dgnn ***** Running training *****\n",
      "dgnn   Num examples = 164814\n",
      "dgnn   Batch size = 32\n",
      "dgnn   Num epoch = 0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67025401512749bbaf71ac91eedbf385"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "test_examples = read_examples(test_url)\n",
    "test_features = convert_examples_to_features(test_examples, tokenizer, stage='test')\n",
    "# Calculate bleu\n",
    "test_sampler = SequentialSampler(test_features)\n",
    "test_dataloader = DataLoader(test_features, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "best_ppl_model = output_dir + '/checkpoint-best-ppl/pytorch_model.bin' \n",
    "model.load_state_dict(torch.load(best_ppl_model))\n",
    "model.eval() \n",
    "p=[]\n",
    "for batch in tqdm(test_dataloader,total=len(test_dataloader)):\n",
    "    x = data.x.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    edge_attr = data.edge_attr.to(device)\n",
    "    batch = data.batch.to(device)                     \n",
    "    with torch.no_grad():\n",
    "        preds = model(x=x, edge_index=edge_index, edge_attr=edge_attr, batch=batch)   \n",
    "        for pred in preds:\n",
    "            t=pred[0].cpu().numpy()\n",
    "            t=list(t)\n",
    "            if 0 in t:\n",
    "                t=t[:t.index(0)]\n",
    "            text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "            p.append(text)\n",
    "model.train()\n",
    "predictions=[]\n",
    "with open(os.path.join(output_dir,\"test.output\"),'w', encoding='utf-8') as f, open(os.path.join(output_dir,\"test.gold\"),'w', encoding='utf-8') as f1:\n",
    "    for ref,gold in zip(p,test_examples):\n",
    "        predictions.append(str(gold.idx)+'\\t'+ref)\n",
    "        f.write(str(gold.idx)+'\\t'+ref+'\\n')\n",
    "        f1.write(str(gold.idx)+'\\t'+gold.target+'\\n')     \n",
    "\n",
    "(goldMap, predictionMap) = bleu.computeMaps(predictions, os.path.join(output_dir, \"test.gold\")) \n",
    "dev_bleu=round(bleu.bleuFromMaps(goldMap, predictionMap)[0],2)\n",
    "msgr.print_msg(\" {} = {} \".format(\"bleu-4\", str(dev_bleu)))\n",
    "msgr.print_msg(\"  \"+\"*\"*20)     "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3308dd3d2a5647fea16be3e980f1a789",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "dgnn  bleu-4 = 9.43 \n",
      "dgnn   ********************\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Total: 1095\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "best_bleu_model = output_dir + '/checkpoint-best-bleu/pytorch_model.bin' \n",
    "model.load_state_dict(torch.load(best_bleu_model))\n",
    "model.eval() \n",
    "p=[]\n",
    "for batch in tqdm(test_dataloader,total=len(test_dataloader)):\n",
    "    x = data.x.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    edge_attr = data.edge_attr.to(device)\n",
    "    batch = data.batch.to(device)                 \n",
    "    with torch.no_grad():\n",
    "        preds = model(x=x, edge_index=edge_index, edge_attr=edge_attr, batch=batch)   \n",
    "        for pred in preds:\n",
    "            t=pred[0].cpu().numpy()\n",
    "            t=list(t)\n",
    "            if 0 in t:\n",
    "                t=t[:t.index(0)]\n",
    "            text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "            p.append(text)\n",
    "model.train()\n",
    "predictions=[]\n",
    "with open(os.path.join(output_dir,\"checkpoint-best-bleu/test.output\"),'w', encoding='utf-8') as f, open(os.path.join(output_dir,\"checkpoint-best-bleu/test.gold\"),'w', encoding='utf-8') as f1:\n",
    "    for ref,gold in zip(p,test_examples):\n",
    "        predictions.append(str(gold.idx)+'\\t'+ref)\n",
    "        f.write(str(gold.idx)+'\\t'+ref+'\\n')\n",
    "        f1.write(str(gold.idx)+'\\t'+gold.target+'\\n')     \n",
    "\n",
    "(goldMap, predictionMap) = bleu.computeMaps(predictions, os.path.join(output_dir, \"test.gold\")) \n",
    "dev_bleu=round(bleu.bleuFromMaps(goldMap, predictionMap)[0],2)\n",
    "msgr.print_msg(\" {} = {} \".format(\"bleu-4\", str(dev_bleu)))\n",
    "msgr.print_msg(\"  \"+\"*\"*20)     "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c14a2c186f4d05a201e69625b1d711",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "dgnn  bleu-4 = 9.68 \n",
      "dgnn   ********************\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Total: 1095\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "last_model = output_dir + '/checkpoint-last/pytorch_model.bin' \n",
    "model.load_state_dict(torch.load(last_model))\n",
    "model.eval() \n",
    "p=[]\n",
    "for batch in tqdm(test_dataloader,total=len(test_dataloader)):\n",
    "    x = data.x.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    edge_attr = data.edge_attr.to(device)\n",
    "    batch = data.batch.to(device)                   \n",
    "    with torch.no_grad():\n",
    "        preds = model(x=x, edge_index=edge_index, edge_attr=edge_attr, batch=batch)   \n",
    "        for pred in preds:\n",
    "            t=pred[0].cpu().numpy()\n",
    "            t=list(t)\n",
    "            if 0 in t:\n",
    "                t=t[:t.index(0)]\n",
    "            text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "            p.append(text)\n",
    "model.train()\n",
    "predictions=[]\n",
    "with open(os.path.join(output_dir,\"checkpoint-last/test.output\"),'w', encoding='utf-8') as f, open(os.path.join(output_dir,\"checkpoint-last/test.gold\"),'w', encoding='utf-8') as f1:\n",
    "    for ref,gold in zip(p,test_examples):\n",
    "        predictions.append(str(gold.idx)+'\\t'+ref)\n",
    "        f.write(str(gold.idx)+'\\t'+ref+'\\n')\n",
    "        f1.write(str(gold.idx)+'\\t'+gold.target+'\\n')     \n",
    "\n",
    "(goldMap, predictionMap) = bleu.computeMaps(predictions, os.path.join(output_dir, \"test.gold\")) \n",
    "dev_bleu=round(bleu.bleuFromMaps(goldMap, predictionMap)[0],2)\n",
    "msgr.print_msg(\" {} = {} \".format(\"bleu-4\", str(dev_bleu)))\n",
    "msgr.print_msg(\"  \"+\"*\"*20)     "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be23c9962e984919b37193d55aea14ea",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "dgnn  bleu-4 = 8.89 \n",
      "dgnn   ********************\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Total: 1095\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}