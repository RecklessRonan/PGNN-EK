{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd \n",
    "import javalang\n",
    "from javalang.ast import Node\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules.linear import Linear\n",
    "from torch_geometric.nn.glob import GlobalAttention\n",
    "from torch_geometric.nn import MessagePassing, GatedGraphConv, GCNConv, global_mean_pool\n",
    "from anytree import AnyNode\n",
    "from torch_geometric.data import Data, DataLoader, ClusterData, ClusterLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config_dgnn.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(config_file), Loader=yaml.FullLoader)\n",
    "\n",
    "# data source\n",
    "raw_code_url = config['ccd_data']['data']\n",
    "train_url = config['ccd_data']['train']\n",
    "valid_url = config['ccd_data']['valid']\n",
    "test_url = config['ccd_data']['test']\n",
    "\n",
    "# training parameter\n",
    "# batch_size = config['training']['batch_size']\n",
    "batch_size = 64\n",
    "num_epoches = config['training']['num_epoches']\n",
    "lr = config['training']['lr']\n",
    "decay_ratio = config['training']['lr']\n",
    "save_name = config['training']['save_name']\n",
    "warm_up = config['training']['warm_up']\n",
    "patience = config['training']['patience']\n",
    "\n",
    "# model design\n",
    "graph_embedding_size = config['model']['graph_embedding_size']\n",
    "lstm_hidden_size = config['model']['lstm_hidden_size']\n",
    "divide_node_num = config['model']['divide_node_num']\n",
    "gnn_layers_num = config['model']['gnn_layers_num']\n",
    "lstm_layers_num = config['model']['lstm_layers_num']\n",
    "decoder_input_size = config['model']['decoder_input_size']\n",
    "\n",
    "# logs\n",
    "info_prefix = config['logs']['info_prefix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = datetime.now().strftime('%Y-%m-%d--%H-%M-%S')\n",
    "log_file = 'logs/' + run_id + '.log'\n",
    "exp_dir = 'runs/' + run_id\n",
    "os.mkdir(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Info(object):\n",
    "    def __init__(self, info_prefix=''):\n",
    "        self.info_prefix = info_prefix\n",
    "    \n",
    "    def print_msg(self, msg):\n",
    "        text = self.info_prefix + ' ' + msg\n",
    "        print(text)\n",
    "        logging.info(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn run_id : 2021-07-23--08-26-16\n",
      "dgnn log_file : logs/2021-07-23--08-26-16.log\n",
      "dgnn exp_dir: runs/2021-07-23--08-26-16\n",
      "dgnn {'data': {'train': '/data/code/represent-code-in-human/data/code-summarization-new/train.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-new/valid.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-new/test.jsonl'}, 'small_data': {'train': '/data/code/represent-code-in-human/data/code-summarization-small/train.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-small/valid.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-small/test.jsonl'}, 'middle_data': {'train': '/data/code/represent-code-in-human/data/code-summarization-middle/train.jsonl', 'valid': '/data/code/represent-code-in-human/data/code-summarization-middle/valid.jsonl', 'test': '/data/code/represent-code-in-human/data/code-summarization-middle/test.jsonl'}, 'ccd_data': {'data': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/data.jsonl', 'train': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/train.txt', 'valid': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/test.txt', 'test': '/data/dataset/CodeXGLUE/Code-Code/Clone-detection-BigCloneBench/dataset/valid.txt'}, 'preprocess': {'max_seq_len': 32}, 'training': {'batch_size': 128, 'num_epoches': 100, 'lr': 0.001, 'decay_ratio': 0.95, 'save_name': '/model.pth', 'warm_up': 5, 'patience': 10}, 'model': {'graph_embedding_size': 100, 'gnn_layers_num': 4, 'lstm_layers_num': 3, 'lstm_hidden_size': 128, 'divide_node_num': 30, 'decoder_input_size': 300, 'decoder_hidden_size': 128, 'decoder_num_layers': 2, 'decoder_rnn_dropout': 0.5, 'gine_dim': 128}, 'logs': {'info_prefix': 'dgnn'}}\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s | %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', filename=log_file, level=logging.DEBUG)\n",
    "msgr = Info(info_prefix)\n",
    "\n",
    "msgr.print_msg('run_id : {}'.format(run_id))\n",
    "msgr.print_msg('log_file : {}'.format(log_file))\n",
    "msgr.print_msg('exp_dir: {}'.format(exp_dir))\n",
    "msgr.print_msg(str(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define one extra keywords \n",
    "UNK_TOKEN = '<UNK>'\n",
    "UNK = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000832</th>\n",
       "      <td>public static void main(String[] args) {\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005623</th>\n",
       "      <td>public synchronized String getSerialNumber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005624</th>\n",
       "      <td>public Object run() {\\n           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005674</th>\n",
       "      <td>public String post() {\\n        if (conten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005879</th>\n",
       "      <td>@Override\\n    public void onCreate(Bundle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       func\n",
       "idx                                                        \n",
       "10000832      public static void main(String[] args) {\\n...\n",
       "10005623      public synchronized String getSerialNumber...\n",
       "10005624              public Object run() {\\n           ...\n",
       "10005674      public String post() {\\n        if (conten...\n",
       "10005879      @Override\\n    public void onCreate(Bundle..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_code = pd.read_json(path_or_buf=raw_code_url, lines=True)\n",
    "raw_code = raw_code.set_index('idx')\n",
    "raw_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_code_index = raw_code.index.tolist()\n",
    "\n",
    "over_length_ids = [10000832, 10151623, 10540676, 10690321, 10717656, 10793825, 10934628, 11339042, 11603577, 11940679, 12082150, 12119068, 12335897, 12352751, 12389873, 12415477, 12838273, 12838274, 12914531, 13099033, 13292215, 13292580, 13456795, 1349815, 13563706, 13586003, 13644040, 13650923, 13747998, 13776078, 13961100, 14020143, 14190765, 14310068, 14661394, 1477292, 14794142, 15295408, 15453012, 15723802, 15758923, 16002345, 16002347, 16006791, 16142591, 1637147, 16518661, 17314208, 17551920, 17573144, 17750515, 17829989, 17874921, 17917053, 18284812, 18433984, 18574455, 18790182, 18822890, 19074021, 19090289, 19276021, 19276022, 19340788, 19382420, 19434890, 19434892, 1944490, 19478367, 19556732, 1962490, 19634773, 19841853, 19942676, 20122631, 20275058, 2067794, 20833509, 20856391, 20885480, 21028028, 21161120, 21318345, 21493541, 2157431, 21652119, 22031237, 22033685, 22035132, 22114133, 22222255, 2235431, 2247987, 22580642, 22673614, 2285441, 23041161, 23094550, 23188198, 23248619, 23370708, 23510383, 23611768, 2450, 2476569, 2511576, 2769195, 2771573, 2771574, 285947, 2996859, 325062, 3375714, 3375715, 3375723, 3400236, 37044, 3867253, 416857, 4420769, 4494367, 4581365, 4660318, 4681906, 4780347, 4792385, 4854974, 5021563, 5189131, 5252227, 5389524, 5430189, 552318, 557726, 5620476, 564191, 5691586, 592597, 6008880, 6121196, 6147227, 6304372, 6304373, 6333737, 6403868, 6644748, 6961579, 6966398, 7005223, 7149578, 726690, 7300257, 7300264, 7300267, 733283, 7394826, 7665877, 7687037, 7727956, 793122, 8079516, 8109022, 8335944, 83802, 8581437, 8641070, 9050003, 9221721, 9261908, 9530015, 9581835, 961457, 9647574, 9687064, 9705209, 9782243, 979163, 98309, 98428, 9980609]\n",
    "# over_length_ids = [10690321, 10717656, 10793825, 11339042, 12119068, 12352751, 12415477, 13099033, 15723802, 1637147, 16518661, 17750515, 18822890, 19276021, 2067794, 20833509, 20856391, 20885480, 21028028, 22033685, 22035132, 2235431, 2247987, 22580642, 2285441, 23094550, 23248619, 2996859, 325062, 3375723, 3867253, 4494367, 4660318, 4780347, 5021563, 5189131, 5252227, 564191, 6147227, 7005223, 7300267, 793122, 8109022, 8581437, 9221721, 9647574, 98309]\n",
    "\n",
    "def read_ccd_pairs(url):\n",
    "    data = []\n",
    "    with open(url) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            id1, id2, label = line.split('\\t')\n",
    "            if int(id1) not in raw_code_index or int(id2) not in raw_code_index or int(id1) in over_length_ids or int(id2) in over_length_ids:\n",
    "                continue\n",
    "            label = 0 if label == '0' else 1\n",
    "            data.append((int(id1), int(id2), label))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn train size: 864660, valid size: 402753, test size: 395605\n"
     ]
    }
   ],
   "source": [
    "train_data = read_ccd_pairs(train_url)\n",
    "valid_data = read_ccd_pairs(valid_url)\n",
    "test_data = read_ccd_pairs(test_url)\n",
    "\n",
    "msgr.print_msg('train size: {}, valid size: {}, test size: {}'.format(len(train_data), len(valid_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_small = random.sample(train_data, 1000)\n",
    "valid_data_small = random.sample(valid_data, 500)\n",
    "test_data_small = random.sample(test_data, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vocab class\n",
    "class Vocab(object):\n",
    "    def __init__(self, word2id={}):\n",
    "        self.word2id = dict(word2id)\n",
    "        self.id2word = {v: k for k, v in self.word2id.items()}\n",
    "\n",
    "    def build_vocab(self, sentences, min_count=1):\n",
    "        word_counter = {}\n",
    "        for word in sentences:\n",
    "            word_counter[word] = word_counter.get(word, 0) + 1\n",
    "        \n",
    "        for word, count in sorted(word_counter.items(), key=lambda x: -x[1]):\n",
    "            if count < min_count:\n",
    "                break\n",
    "            _id = len(self.word2id)\n",
    "            self.word2id.setdefault(word, _id)\n",
    "            self.id2word[_id] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct two vocabulary for ast nodes and natural language repectively\n",
    "word2id = {\n",
    "    UNK_TOKEN: UNK\n",
    "}\n",
    "vocab_astnodes = Vocab(word2id=word2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use javalang to generate ASTs and depth-first traverse to generate ast nodes corpus\n",
    "def get_token(node):\n",
    "    token = ''\n",
    "    if isinstance(node, str):\n",
    "        token = node\n",
    "    elif isinstance(node, set):\n",
    "        token = 'Modifier'\n",
    "    elif isinstance(node, Node):\n",
    "        token = node.__class__.__name__\n",
    "    return token\n",
    "\n",
    "\n",
    "def get_child(root):\n",
    "    if isinstance(root, Node):\n",
    "        children = root.children\n",
    "    elif isinstance(root, set):\n",
    "        children = list(root)\n",
    "    else:\n",
    "        children = []\n",
    "\n",
    "    def expand(nested_list):\n",
    "        for item in nested_list:\n",
    "            if isinstance(item, list):\n",
    "                for sub_item in expand(item):\n",
    "                    yield sub_item\n",
    "            elif item:\n",
    "                yield item\n",
    "\n",
    "    return list(expand(children))\n",
    "\n",
    "\n",
    "def get_sequence(node, sequence):\n",
    "    token, children = get_token(node), get_child(node)\n",
    "    sequence.append(token)\n",
    "    for child in children:\n",
    "        get_sequence(child, sequence)\n",
    "\n",
    "\n",
    "def parse_program(func):\n",
    "    tokens = javalang.tokenizer.tokenize(func)\n",
    "    parser = javalang.parser.Parser(tokens)\n",
    "    tree = parser.parse_member_declaration()\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use train data to construction ast nodes corpus\n",
    "astnodes_tokens = []\n",
    "train_ids = []\n",
    "for i in range(len(train_data)):\n",
    "    train_ids.append(train_data[i][0])\n",
    "    train_ids.append(train_data[i][1])\n",
    "\n",
    "train_ids = list(set(train_ids))\n",
    "\n",
    "for id in train_ids:\n",
    "    sequence = []\n",
    "    get_sequence(parse_program(raw_code['func'][id]), sequence)\n",
    "    astnodes_tokens.extend(sequence)\n",
    "\n",
    "vocab_astnodes.build_vocab(astnodes_tokens, min_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn vocab_astnodes_size: 54866\n"
     ]
    }
   ],
   "source": [
    "vocab_astnodes_size = len(vocab_astnodes.id2word)\n",
    "msgr.print_msg('vocab_astnodes_size: ' + str(vocab_astnodes_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Dataflow to AST to generate D-AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  generate tree for AST Node\n",
    "def create_tree(root, node, node_list, parent=None):\n",
    "    id = len(node_list)\n",
    "    token, children = get_token(node), get_child(node)\n",
    "    if id == 0:\n",
    "        root.token = token\n",
    "        root.data = node\n",
    "    else:\n",
    "        new_node = AnyNode(id=id, token=token, data=node, parent=parent)\n",
    "    node_list.append(node)\n",
    "    for child in children:\n",
    "        if id == 0:\n",
    "            create_tree(root, child, node_list, parent=root)\n",
    "        else:\n",
    "            create_tree(root, child, node_list, parent=new_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traverse the AST tree to get all the nodes and edges\n",
    "def get_node_and_edge(node, node_index_list, vocab_dict, src, tgt, variable_token_list, variable_id_list):\n",
    "    token = node.token\n",
    "    # print('token', token)\n",
    "    node_index_list.append([vocab_dict.word2id.get(token, UNK)])\n",
    "    # find out all variables\n",
    "    if token in ['VariableDeclarator', 'MemberReference']:\n",
    "        variable_token_list.append(node.children[0].token)\n",
    "        variable_id_list.append(node.children[0].id)\n",
    "    for child in node.children:\n",
    "        # print('child', child.token)\n",
    "        src.append(node.id)\n",
    "        tgt.append(child.id)\n",
    "        src.append(child.id)\n",
    "        tgt.append(node.id)\n",
    "        get_node_and_edge(child, node_index_list, vocab_dict, src, tgt, variable_token_list, variable_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pytorch_geometric input format data from ast\n",
    "def get_pyg_data_from_ast(ast, vocab_dict):\n",
    "    node_list = []\n",
    "    new_tree = AnyNode(id=0, token=None, data=None)\n",
    "    create_tree(new_tree, ast, node_list)\n",
    "    x = []\n",
    "    edge_src = []\n",
    "    edge_tgt = []\n",
    "    edge_attr = []\n",
    "    # record variable tokens and ids to add data flow edge in AST graph\n",
    "    variable_token_list = []\n",
    "    variable_id_list = []\n",
    "    get_node_and_edge(new_tree, x, vocab_dict, edge_src, edge_tgt, variable_token_list, variable_id_list)\n",
    "    # print('variable_token_list', variable_token_list)\n",
    "    # print('variable_id_list', variable_id_list)\n",
    "\n",
    "    ast_edge_num = len(edge_src)\n",
    "    # print('ast_edge_num', ast_edge_num)\n",
    "    # set ast edge type to 0\n",
    "    for _ in range(ast_edge_num):\n",
    "        edge_attr.append([0])\n",
    "\n",
    "    # add data flow edge\n",
    "    variable_dict = {}\n",
    "    for i in range(len(variable_token_list)):\n",
    "        # print('variable_dict', variable_dict)\n",
    "        if variable_token_list[i] not in variable_dict:\n",
    "            variable_dict.setdefault(variable_token_list[i], variable_id_list[i])\n",
    "        else:\n",
    "            # print('edge', variable_dict.get(variable_token_list[i]), variable_id_list[i])\n",
    "            edge_src.append(variable_dict.get(variable_token_list[i]))\n",
    "            edge_tgt.append(variable_id_list[i])\n",
    "            edge_src.append(variable_id_list[i])\n",
    "            edge_tgt.append(variable_dict.get(variable_token_list[i]))\n",
    "            variable_dict[variable_token_list[i]] = variable_id_list[i]\n",
    "    \n",
    "    edge_index = [edge_src, edge_tgt]\n",
    "\n",
    "    # set data flow edge type to 1\n",
    "    dataflow_edge_num = len(edge_src) - ast_edge_num\n",
    "    for _ in range(dataflow_edge_num):\n",
    "        edge_attr.append([1])\n",
    "    # print('dataflow_edge_num', dataflow_edge_num)\n",
    "    return x, edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_pygdata(code):\n",
    "    ast = parse_program(code)\n",
    "    x, edge_index, edge_attr = get_pyg_data_from_ast(ast, vocab_astnodes)\n",
    "    return Data(x=torch.tensor(x, dtype=torch.long),\n",
    "                    edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
    "                    edge_attr=torch.tensor(edge_attr, dtype=torch.long))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg_datas = []\n",
    "for index in raw_code_index:\n",
    "    pyg_datas.append(transform_to_pygdata(raw_code['func'][index]))\n",
    "\n",
    "raw_code['pyg_data'] = pyg_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[3752, 1], edge_index=[2, 3752], x=[1774, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_code['pyg_data'][10000832]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairData(Data):\n",
    "    def __init__(self, edge_index_s, edge_attr_s, x_s, edge_index_t, edge_attr_t, x_t, label):\n",
    "        super(PairData, self).__init__()\n",
    "        self.edge_index_s = edge_index_s\n",
    "        self.edge_attr_s = edge_attr_s\n",
    "        self.x_s = x_s\n",
    "        self.edge_index_t = edge_index_t\n",
    "        self.edge_attr_t = edge_attr_t\n",
    "        self.x_t = x_t\n",
    "        self.label = label\n",
    "    \n",
    "    def __inc__(self, key, value):\n",
    "        if key == 'edge_index_s':\n",
    "            return self.x_s.size(0)\n",
    "        if key == 'edge_index_t':\n",
    "            return self.x_t.size(0)\n",
    "        # if key == 'edge_attr_s':\n",
    "        #     return self.x_s.size(0)\n",
    "        # if key == 'edge_attr_t':\n",
    "        #     return self.x_t.size(0)\n",
    "        # if key == 'label':\n",
    "        #     return self.x_s.size(0)\n",
    "        else:\n",
    "            return super().__inc__(key, value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data):\n",
    "    batches = []\n",
    "    for i in range(len(data)):\n",
    "        pyg1 = raw_code['pyg_data'][data[i][0]]\n",
    "        pyg2 = raw_code['pyg_data'][data[i][1]]\n",
    "        label = torch.tensor(data[i][2], dtype=torch.long)\n",
    "        # print('attr 1', pyg1.edge_attr)\n",
    "        # print('attr 2', pyg2.edge_attr)\n",
    "        pair_data = PairData(x_s=pyg1.x, edge_index_s=pyg1.edge_index, edge_attr_s = pyg1.edge_attr,\n",
    "                                x_t=pyg2.x, edge_index_t=pyg2.edge_index, edge_attr_t = pyg2.edge_attr,\n",
    "                                label=label)\n",
    "        batches.append(pair_data)    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = batch_data(train_data_small)\n",
    "valid_batch = batch_data(valid_data_small)\n",
    "test_batch = batch_data(test_data_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_batch, batch_size=batch_size, follow_batch=['x_s', 'x_t'])\n",
    "valid_loader = DataLoader(valid_batch, batch_size=batch_size, follow_batch=['x_s', 'x_t'])\n",
    "test_loader = DataLoader(test_batch, batch_size=batch_size, follow_batch=['x_s', 'x_t'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioning D-AST in model instead of data-prepocessing\n",
    "# partitioning D-AST in model by the num of nodes, which is set in the hyper-parameter `divide_node_num`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceGNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_len, graph_embedding_size, gnn_layers_num, lstm_layers_num, lstm_hidden_size, divide_node_num,\n",
    "                    decoder_input_size, device):\n",
    "        super(SequenceGNNEncoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.embed = nn.Embedding(vocab_len, graph_embedding_size)\n",
    "        self.edge_embed = nn.Embedding(2, 1) # only two edge types to be set weights, which are AST edge and data flow edge\n",
    "        self.ggnnlayer = GatedGraphConv(graph_embedding_size, gnn_layers_num)\n",
    "        self.mlp_gate = nn.Sequential(\n",
    "            nn.Linear(graph_embedding_size, 300), nn.Sigmoid(), nn.Linear(300, 1), nn.Sigmoid())\n",
    "        self.pool = GlobalAttention(gate_nn=self.mlp_gate)\n",
    "        self.divide_node_num = divide_node_num\n",
    "        self.lstm = nn.LSTM(input_size=graph_embedding_size, hidden_size=lstm_hidden_size, num_layers=lstm_layers_num)\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_layers_num = lstm_layers_num\n",
    "        self.fc = nn.Linear(graph_embedding_size + lstm_hidden_size, decoder_input_size)\n",
    "\n",
    "    def subgraph_forward(self, x, edge_index, edge_attr, batch):\n",
    "        # print('edge_attr', edge_attr)\n",
    "        # print('shape', edge_attr.shape)\n",
    "        if type(edge_attr) == type(None):\n",
    "            edge_weight = None\n",
    "        else:\n",
    "            edge_weight = self.edge_embed(edge_attr)\n",
    "            edge_weight = edge_weight.squeeze(1)\n",
    "        x = self.ggnnlayer(x, edge_index, edge_weight)\n",
    "        return self.pool(x, batch=batch)\n",
    "    \n",
    "    # partitioning multiple subgraphs by dynamic allocating edges\n",
    "    def partition_graph(self, x, edge_index, edge_attr, batch):        \n",
    "        nodes_list = [] # record all nodes number for each subgraph in total batch\n",
    "        graph_pos_in_batch, graph_length = self.get_subgraph_info_from_batch(batch)\n",
    "        max_seq_len = max(graph_length)\n",
    "        subgraph_num = int(max_seq_len/self.divide_node_num) + 1\n",
    "        for i in range(subgraph_num):\n",
    "            nodes = []\n",
    "            for j in range(len(graph_pos_in_batch)):\n",
    "                if graph_length[j] > i * self.divide_node_num:\n",
    "                    if graph_length[j] > (i+1) * self.divide_node_num:\n",
    "                        subgraph_len = self.divide_node_num\n",
    "                    else:\n",
    "                        subgraph_len = graph_length[j] - i * self.divide_node_num   \n",
    "                    for m in range(subgraph_len):\n",
    "                        nodes.append(graph_pos_in_batch[j] + m)          \n",
    "            nodes_list.append(set(nodes)) \n",
    "        # only count the edge whose target node in subgraph\n",
    "        sub_edge_src = [[] for _ in range(subgraph_num)]\n",
    "        sub_edge_tgt = [[] for _ in range(subgraph_num)]\n",
    "        sub_edge_attr = [[] for _ in range(subgraph_num)]\n",
    "        # print('nodes_list', nodes_list)\n",
    "        node_num = len(x)\n",
    "        node_subgraph_index = [0 for _ in range(node_num)] # use a list to store the subgraph numbers for all nodes\n",
    "        for i in range(len(nodes_list)):\n",
    "            for node in nodes_list[i]:\n",
    "                node_subgraph_index[node] = i\n",
    "    \n",
    "        for i in range(len(edge_index[1])):\n",
    "            src = edge_index[0][i].item()\n",
    "            tgt = edge_index[1][i].item()\n",
    "            sub_edge_src[node_subgraph_index[tgt]].append(src)\n",
    "            sub_edge_tgt[node_subgraph_index[tgt]].append(tgt)\n",
    "            sub_edge_attr[node_subgraph_index[tgt]].append(edge_attr[i].item())\n",
    "        edge_index_list = []\n",
    "        edge_attr_list = []\n",
    "        for i in range(subgraph_num):\n",
    "            edge_index_list.append(torch.tensor([sub_edge_src[i], sub_edge_tgt[i]], dtype=torch.long))\n",
    "            edge_attr_list.append(torch.tensor(sub_edge_attr[i], dtype=torch.long))\n",
    "        return edge_index_list, edge_attr_list\n",
    "\n",
    "    def get_subgraph_info_from_batch(self, batch):\n",
    "        comp = 0\n",
    "        pos = 0\n",
    "        graph_pos_in_batch = [0] # record begin positions and end positions of every subgraph\n",
    "        graph_length = [] # use a list to store the node nums in subgraph\n",
    "        for i in range(len(batch)):\n",
    "            if batch[i] != comp:\n",
    "                graph_pos_in_batch.append(i)\n",
    "                graph_length.append(i-pos)\n",
    "                comp = batch[i]\n",
    "                pos = i\n",
    "        graph_length.append(len(batch)-pos)\n",
    "        return graph_pos_in_batch, graph_length        \n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        edge_index_list, edge_attr_list = self.partition_graph(x, edge_index, edge_attr, batch)\n",
    "        x = self.embed(x)\n",
    "        x = x.squeeze(1)\n",
    "        subgraph_pool_list = [\n",
    "            self.subgraph_forward(x, edge_index_list[i].to(self.device), edge_attr_list[i].to(self.device), batch)\n",
    "            for i in range(len(edge_index_list))\n",
    "        ]\n",
    "        graph_pool = self.subgraph_forward(x, edge_index, edge_attr, batch)\n",
    "        subgraph_pool_seq = torch.stack(subgraph_pool_list)\n",
    "        h0 = torch.zeros(self.lstm_layers_num, subgraph_pool_seq.size(1) ,self.lstm_hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.lstm_layers_num, subgraph_pool_seq.size(1) ,self.lstm_hidden_size).to(self.device)\n",
    "        subgraph_output, (_, _) = self.lstm(subgraph_pool_seq, (h0, c0))\n",
    "        return self.fc(torch.cat((subgraph_output[-1], graph_pool), dim=1))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDecoder(nn.Module):\n",
    "    def __init__(self, vocab_len, graph_embedding_size, gnn_layers_num, lstm_layers_num, lstm_hidden_size, divide_node_num, \n",
    "    decoder_input_size, device):\n",
    "        super(SiameseDecoder, self).__init__()\n",
    "        self.encoder = SequenceGNNEncoder(vocab_len, graph_embedding_size, gnn_layers_num, lstm_layers_num, lstm_hidden_size, divide_node_num, \n",
    "    decoder_input_size, device)\n",
    "        self.fc = nn.Linear(2* decoder_input_size, 2)\n",
    "\n",
    "    \n",
    "    def forward(self, x_s, edge_index_s, edge_attr_s, x_t, edge_index_t, edge_attr_t, x_s_batch, x_t_batch):\n",
    "        decoder_input1 = self.encoder(x_s, edge_index_s, edge_attr_s, x_s_batch)\n",
    "        decoder_input2 = self.encoder(x_t, edge_index_t, edge_attr_t, x_t_batch)\n",
    "        output = torch.cat((decoder_input1, decoder_input2), dim=1)\n",
    "        logits = self.fc(output) \n",
    "        return F.softmax(logits)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda: 0')\n",
    "\n",
    "model_args = {\n",
    "    'vocab_len': vocab_astnodes_size,\n",
    "    'graph_embedding_size': graph_embedding_size,\n",
    "    'gnn_layers_num': gnn_layers_num,\n",
    "    'lstm_layers_num': lstm_layers_num,\n",
    "    'lstm_hidden_size': lstm_hidden_size,\n",
    "    'divide_node_num': divide_node_num,\n",
    "    'decoder_input_size': decoder_input_size,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "model = SiameseDecoder(**model_args).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda= lambda epoch: decay_ratio ** epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─SequenceGNNEncoder: 1-1                --\n",
      "|    └─Embedding: 2-1                    5,486,600\n",
      "|    └─Embedding: 2-2                    2\n",
      "|    └─GatedGraphConv: 2-3               --\n",
      "|    |    └─GRUCell: 3-1                 60,600\n",
      "|    └─Sequential: 2-4                   --\n",
      "|    |    └─Linear: 3-2                  30,300\n",
      "|    |    └─Sigmoid: 3-3                 --\n",
      "|    |    └─Linear: 3-4                  301\n",
      "|    |    └─Sigmoid: 3-5                 --\n",
      "|    └─GlobalAttention: 2-5              --\n",
      "|    |    └─Sequential: 3-6              (recursive)\n",
      "|    └─LSTM: 2-6                         381,952\n",
      "|    └─Linear: 2-7                       68,700\n",
      "├─Linear: 1-2                            1,202\n",
      "=================================================================\n",
      "Total params: 6,029,657\n",
      "Trainable params: 6,029,657\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "model_summary = summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(data, model, optimizer=None, is_train=True):\n",
    "    x_s = (data.x_s).to(device)\n",
    "    edge_index_s = (data.edge_index_s).to(device)\n",
    "    edge_attr_s = (data.edge_attr_s).to(device)\n",
    "    x_t = (data.x_t).to(device)\n",
    "    edge_index_t = (data.edge_index_t).to(device)\n",
    "    edge_attr_t = (data.edge_attr_t).to(device)\n",
    "    x_s_batch = (data.x_s_batch).to(device)\n",
    "    x_t_batch = (data.x_t_batch).to(device)\n",
    "    label = (data.label).to(device)\n",
    "    pred = model(x_s, edge_index_s, edge_attr_s, x_t, edge_index_t, edge_attr_t, x_s_batch, x_t_batch)\n",
    "    loss = criterion(pred, label)\n",
    "\n",
    "    if is_train:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "    \n",
    "    return loss.item(), label.cpu().detach().numpy(), pred.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, filename = None, patience=3, warm_up=0, verbose=False):\n",
    "\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.warm_up = warm_up\n",
    "        self.filename = filename\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(score, model)\n",
    "            \n",
    "        elif (score <= self.best_score) and (epoch > self.warm_up) :\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            if (epoch <= self.warm_up):\n",
    "                print('Warming up until epoch', self.warm_up)\n",
    "            \n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print(f'Score improved. ({self.best_score:.6f} --> {score:.6f}).')\n",
    "                \n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(score, model)\n",
    "                self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, score, model):\n",
    "        \n",
    "        if self.filename is not None:\n",
    "            torch.save(model.state_dict(), self.filename)\n",
    "            \n",
    "        if self.verbose:\n",
    "            print('Model saved...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = exp_dir + save_name\n",
    "early_stopping = EarlyStopping(fname, patience, warm_up, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate(logits, y_trues):\n",
    "    logits=np.concatenate(logits,0)\n",
    "    y_trues=np.concatenate(y_trues,0)\n",
    "    best_threshold=0\n",
    "    best_f1=0\n",
    "    for i in range(1,100):\n",
    "        threshold=i/100\n",
    "        y_preds=logits[:,1]>threshold        \n",
    "        recall=recall_score(y_trues, y_preds, average='macro')        \n",
    "        precision=precision_score(y_trues, y_preds, average='macro')           \n",
    "        f1=f1_score(y_trues, y_preds, average='macro') \n",
    "        if f1>best_f1:\n",
    "            best_f1=f1\n",
    "            best_threshold=threshold\n",
    "\n",
    "    y_preds=logits[:,1]>best_threshold\n",
    "    recall=recall_score(y_trues, y_preds, average='macro')\n",
    "    precision=precision_score(y_trues, y_preds, average='macro')   \n",
    "    f1=f1_score(y_trues, y_preds, average='macro')\n",
    "    return recall, precision, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9501a7ef83d340a6bfdd74b58caa70a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='TRAIN', max=16, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn train loss 0.6926808953285217\n",
      "dgnn train loss 0.6931845545768738\n",
      "dgnn train loss 0.6895528435707092\n",
      "dgnn train loss 0.699258029460907\n",
      "dgnn train loss 0.702467679977417\n",
      "dgnn train loss 0.6882095336914062\n",
      "dgnn train loss 0.6894508004188538\n",
      "dgnn train loss 0.6884142160415649\n",
      "dgnn train loss 0.6927498579025269\n",
      "dgnn train loss 0.685588002204895\n",
      "dgnn train loss 0.6796486973762512\n",
      "dgnn train loss 0.7059070467948914\n",
      "dgnn train loss 0.6701700687408447\n",
      "dgnn train loss 0.7042304277420044\n",
      "dgnn train loss 0.6709396839141846\n",
      "dgnn train loss 0.6727725267410278\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ac6cc87d4c497988dda6ea12e9598a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='VALID', max=8, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dgnn train_hyps [[0.49625507 0.50374496]\n",
      " [0.50160646 0.49839354]\n",
      " [0.5055386  0.49446145]\n",
      " [0.5079428  0.49205717]\n",
      " [0.5050729  0.49492714]\n",
      " [0.49973947 0.50026053]\n",
      " [0.50332236 0.49667767]\n",
      " [0.50439996 0.49560004]\n",
      " [0.5056411  0.49435887]\n",
      " [0.50214636 0.49785367]\n",
      " [0.5032346  0.49676535]\n",
      " [0.5021597  0.49784026]\n",
      " [0.5037326  0.4962674 ]\n",
      " [0.50338    0.49662003]\n",
      " [0.5016635  0.4983365 ]\n",
      " [0.5023695  0.49763054]\n",
      " [0.5034854  0.4965146 ]\n",
      " [0.49722376 0.5027762 ]\n",
      " [0.50073653 0.49926347]\n",
      " [0.5017966  0.49820343]\n",
      " [0.49923396 0.50076604]\n",
      " [0.50598824 0.49401173]\n",
      " [0.5083487  0.49165127]\n",
      " [0.5018837  0.4981163 ]\n",
      " [0.49981126 0.5001887 ]\n",
      " [0.5023577  0.49764228]\n",
      " [0.50135994 0.4986401 ]\n",
      " [0.50269186 0.4973081 ]\n",
      " [0.5016433  0.4983567 ]\n",
      " [0.5036248  0.49637526]\n",
      " [0.5026432  0.4973568 ]\n",
      " [0.5001802  0.49981984]\n",
      " [0.50496596 0.49503404]\n",
      " [0.49902567 0.5009743 ]\n",
      " [0.5006911  0.4993089 ]\n",
      " [0.506674   0.49332598]\n",
      " [0.5019294  0.49807057]\n",
      " [0.50247645 0.49752355]\n",
      " [0.49809998 0.5019    ]\n",
      " [0.5025757  0.49742424]\n",
      " [0.502388   0.497612  ]\n",
      " [0.50150794 0.4984921 ]\n",
      " [0.50638425 0.49361575]\n",
      " [0.49803454 0.50196546]\n",
      " [0.50166583 0.49833417]\n",
      " [0.50310725 0.49689278]\n",
      " [0.50109303 0.49890697]\n",
      " [0.50176483 0.4982352 ]\n",
      " [0.5007581  0.49924183]\n",
      " [0.49921942 0.5007806 ]\n",
      " [0.5030656  0.4969344 ]\n",
      " [0.5017151  0.49828488]\n",
      " [0.49790463 0.5020954 ]\n",
      " [0.5047296  0.49527037]\n",
      " [0.5015393  0.49846065]\n",
      " [0.50368965 0.4963103 ]\n",
      " [0.503457   0.496543  ]\n",
      " [0.5001499  0.49985006]\n",
      " [0.50428396 0.49571604]\n",
      " [0.49797106 0.50202894]\n",
      " [0.5029683  0.49703172]\n",
      " [0.50284785 0.4971522 ]\n",
      " [0.4988967  0.50110334]\n",
      " [0.5058868  0.49411318]]\n",
      "dgnn valid_hyps [[0.6142356  0.3857644 ]\n",
      " [0.62344444 0.3765556 ]\n",
      " [0.510542   0.489458  ]\n",
      " [0.4430684  0.5569316 ]\n",
      " [0.6435405  0.35645956]\n",
      " [0.5914014  0.40859854]\n",
      " [0.5467669  0.45323315]\n",
      " [0.61641556 0.3835844 ]\n",
      " [0.5297708  0.47022924]\n",
      " [0.63621336 0.36378664]\n",
      " [0.5390588  0.46094123]\n",
      " [0.6050308  0.39496922]\n",
      " [0.57529414 0.4247059 ]\n",
      " [0.57930434 0.42069563]\n",
      " [0.51379806 0.486202  ]\n",
      " [0.66412574 0.33587432]\n",
      " [0.5906838  0.4093162 ]\n",
      " [0.53917897 0.46082103]\n",
      " [0.51566535 0.48433468]\n",
      " [0.6312902  0.36870986]\n",
      " [0.62460375 0.3753963 ]\n",
      " [0.54706854 0.4529315 ]\n",
      " [0.5908032  0.40919682]\n",
      " [0.52533215 0.47466785]\n",
      " [0.5941155  0.40588453]\n",
      " [0.64743227 0.35256776]\n",
      " [0.64268416 0.35731584]\n",
      " [0.6228836  0.3771164 ]\n",
      " [0.615328   0.38467202]\n",
      " [0.65926224 0.3407378 ]\n",
      " [0.5754055  0.42459452]\n",
      " [0.6192408  0.3807592 ]\n",
      " [0.53126436 0.46873564]\n",
      " [0.61235917 0.38764086]\n",
      " [0.5622744  0.43772557]\n",
      " [0.60146886 0.39853114]\n",
      " [0.51623493 0.48376504]\n",
      " [0.6641116  0.3358884 ]\n",
      " [0.41971496 0.580285  ]\n",
      " [0.5998292  0.40017083]\n",
      " [0.58122814 0.4187719 ]\n",
      " [0.5827182  0.4172818 ]\n",
      " [0.58057284 0.41942716]\n",
      " [0.54819787 0.45180213]\n",
      " [0.530428   0.469572  ]\n",
      " [0.59840006 0.40159988]\n",
      " [0.67972606 0.320274  ]\n",
      " [0.50647247 0.4935276 ]\n",
      " [0.6337917  0.36620837]\n",
      " [0.58435535 0.41564462]\n",
      " [0.6678138  0.3321862 ]\n",
      " [0.6147598  0.38524014]\n",
      " [0.622029   0.377971  ]\n",
      " [0.6700422  0.32995778]\n",
      " [0.61696345 0.3830365 ]\n",
      " [0.60260856 0.39739144]\n",
      " [0.632011   0.367989  ]\n",
      " [0.6223952  0.37760478]\n",
      " [0.5979222  0.40207776]\n",
      " [0.61161613 0.38838387]\n",
      " [0.53303343 0.46696657]\n",
      " [0.58198196 0.41801798]\n",
      " [0.49541822 0.50458175]\n",
      " [0.6329233  0.3670767 ]]\n",
      "dgnn Epoch 1: train_loss:  0.69 train_recall: 0.5379 train_precision: 0.5401  train_f1: 0.5252  valid_loss:  0.63  valid_recall: 0.6330 valid_precision: 0.6165 valid_f1: 0.6235\n",
      "Model saved...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7dc6a7ebbc04f59bbd813ecae047f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='TRAIN', max=16, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn train loss 0.662265419960022\n",
      "dgnn train loss 0.672351598739624\n",
      "dgnn train loss 0.6715599894523621\n",
      "dgnn train loss 0.6683922410011292\n",
      "dgnn train loss 0.6753723621368408\n",
      "dgnn train loss 0.6745390892028809\n",
      "dgnn train loss 0.6707051992416382\n",
      "dgnn train loss 0.6577792763710022\n",
      "dgnn train loss 0.6754913330078125\n",
      "dgnn train loss 0.6622796058654785\n",
      "dgnn train loss 0.6639368534088135\n",
      "dgnn train loss 0.6793146729469299\n",
      "dgnn train loss 0.6486077904701233\n",
      "dgnn train loss 0.6866417527198792\n",
      "dgnn train loss 0.6646010875701904\n",
      "dgnn train loss 0.6661267280578613\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ec00bde6ec465cbf101621cf2e6fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='VALID', max=8, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dgnn train_hyps [[0.5712152  0.42878482]\n",
      " [0.5786814  0.4213186 ]\n",
      " [0.5691468  0.43085316]\n",
      " [0.6107492  0.3892508 ]\n",
      " [0.5853761  0.41462395]\n",
      " [0.5469747  0.4530253 ]\n",
      " [0.52432084 0.47567916]\n",
      " [0.509219   0.49078098]\n",
      " [0.5226795  0.47732046]\n",
      " [0.62569314 0.3743069 ]\n",
      " [0.58384186 0.41615817]\n",
      " [0.6230456  0.37695435]\n",
      " [0.556782   0.443218  ]\n",
      " [0.593134   0.406866  ]\n",
      " [0.57714486 0.42285517]\n",
      " [0.6144007  0.38559932]\n",
      " [0.49863553 0.50136447]\n",
      " [0.46248645 0.53751355]\n",
      " [0.6092166  0.39078343]\n",
      " [0.57340455 0.42659542]\n",
      " [0.5997918  0.40020815]\n",
      " [0.6508155  0.34918448]\n",
      " [0.6137325  0.38626745]\n",
      " [0.49766272 0.5023372 ]\n",
      " [0.5319243  0.46807566]\n",
      " [0.60647756 0.3935225 ]\n",
      " [0.54412425 0.45587578]\n",
      " [0.6562408  0.34375915]\n",
      " [0.5579286  0.44207138]\n",
      " [0.5526726  0.44732732]\n",
      " [0.46309915 0.5369008 ]\n",
      " [0.46563485 0.5343652 ]\n",
      " [0.6687622  0.33123776]\n",
      " [0.49215314 0.5078469 ]\n",
      " [0.50864935 0.4913507 ]\n",
      " [0.65341306 0.34658697]\n",
      " [0.6149729  0.3850271 ]\n",
      " [0.4950189  0.5049811 ]\n",
      " [0.56177634 0.43822366]\n",
      " [0.55152357 0.4484765 ]\n",
      " [0.59409785 0.40590212]\n",
      " [0.58727807 0.41272196]\n",
      " [0.5868436  0.4131564 ]\n",
      " [0.42667097 0.5733291 ]\n",
      " [0.5757841  0.4242159 ]\n",
      " [0.5065071  0.49349296]\n",
      " [0.5781012  0.42189884]\n",
      " [0.5243949  0.47560513]\n",
      " [0.5541496  0.4458504 ]\n",
      " [0.5866317  0.41336825]\n",
      " [0.55513954 0.4448605 ]\n",
      " [0.48346806 0.51653194]\n",
      " [0.51545787 0.48454216]\n",
      " [0.58992374 0.41007623]\n",
      " [0.58491725 0.41508278]\n",
      " [0.6119546  0.3880454 ]\n",
      " [0.6040167  0.39598328]\n",
      " [0.47797537 0.52202463]\n",
      " [0.55777717 0.4422228 ]\n",
      " [0.57332003 0.42667994]\n",
      " [0.553051   0.44694895]\n",
      " [0.586681   0.41331902]\n",
      " [0.59082633 0.4091737 ]\n",
      " [0.57681984 0.4231802 ]]\n",
      "dgnn valid_hyps [[0.61439764 0.3856024 ]\n",
      " [0.62357223 0.37642777]\n",
      " [0.51026636 0.48973364]\n",
      " [0.4423015  0.5576985 ]\n",
      " [0.6437439  0.35625616]\n",
      " [0.59143686 0.40856314]\n",
      " [0.5465938  0.45340616]\n",
      " [0.6165387  0.3834613 ]\n",
      " [0.5295864  0.47041366]\n",
      " [0.63646793 0.36353207]\n",
      " [0.53883535 0.46116465]\n",
      " [0.6051393  0.39486074]\n",
      " [0.57532716 0.4246728 ]\n",
      " [0.5792845  0.42071557]\n",
      " [0.5133604  0.48663965]\n",
      " [0.6645101  0.33548993]\n",
      " [0.59071285 0.40928715]\n",
      " [0.5388013  0.46119872]\n",
      " [0.51521486 0.48478517]\n",
      " [0.63145965 0.36854032]\n",
      " [0.6247686  0.37523144]\n",
      " [0.5468525  0.45314747]\n",
      " [0.5908304  0.4091696 ]\n",
      " [0.5248781  0.47512195]\n",
      " [0.59417474 0.4058253 ]\n",
      " [0.64773417 0.3522659 ]\n",
      " [0.6430294  0.35697058]\n",
      " [0.62298435 0.37701562]\n",
      " [0.61543936 0.3845606 ]\n",
      " [0.6596715  0.34032857]\n",
      " [0.5752994  0.4247006 ]\n",
      " [0.61937785 0.38062212]\n",
      " [0.5309042  0.46909577]\n",
      " [0.61247617 0.38752383]\n",
      " [0.56215143 0.43784854]\n",
      " [0.6014578  0.39854223]\n",
      " [0.5158668  0.4841332 ]\n",
      " [0.6643988  0.3356012 ]\n",
      " [0.41882342 0.58117664]\n",
      " [0.5998079  0.4001921 ]\n",
      " [0.5812003  0.41879967]\n",
      " [0.58270556 0.41729447]\n",
      " [0.5803516  0.4196484 ]\n",
      " [0.54807514 0.45192486]\n",
      " [0.5301625  0.46983746]\n",
      " [0.5983773  0.40162274]\n",
      " [0.68022513 0.31977484]\n",
      " [0.5059442  0.49405587]\n",
      " [0.63403755 0.36596245]\n",
      " [0.5842659  0.4157341 ]\n",
      " [0.6682697  0.33173037]\n",
      " [0.61495775 0.38504222]\n",
      " [0.62215114 0.37784886]\n",
      " [0.67048943 0.32951057]\n",
      " [0.6170381  0.38296193]\n",
      " [0.60262096 0.397379  ]\n",
      " [0.6321768  0.36782315]\n",
      " [0.6225676  0.37743238]\n",
      " [0.5978844  0.40211552]\n",
      " [0.61163676 0.38836327]\n",
      " [0.5327159  0.46728405]\n",
      " [0.58192986 0.41807014]\n",
      " [0.49483687 0.5051631 ]\n",
      " [0.6330481  0.36695185]]\n",
      "dgnn Epoch 2: train_loss:  0.67 train_recall: 0.6943 train_precision: 0.7006  train_f1: 0.6948  valid_loss:  0.63  valid_recall: 0.6330 valid_precision: 0.6165 valid_f1: 0.6235\n",
      "Warming up until epoch 5\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0695fb3672334f20abb9c9d6c7569315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='TRAIN', max=16, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn train loss 0.6621484756469727\n",
      "dgnn train loss 0.6722412109375\n",
      "dgnn train loss 0.6714584231376648\n",
      "dgnn train loss 0.6682616472244263\n",
      "dgnn train loss 0.675236701965332\n",
      "dgnn train loss 0.6744804978370667\n",
      "dgnn train loss 0.6706343293190002\n",
      "dgnn train loss 0.6576984524726868\n",
      "dgnn train loss 0.6754196882247925\n",
      "dgnn train loss 0.6622290015220642\n",
      "dgnn train loss 0.6639038920402527\n",
      "dgnn train loss 0.6792457103729248\n",
      "dgnn train loss 0.648556113243103\n",
      "dgnn train loss 0.6866062879562378\n",
      "dgnn train loss 0.66459059715271\n",
      "dgnn train loss 0.6661160588264465\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeef4e79d6e7470ba5b952940e99cf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='VALID', max=8, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dgnn train_hyps [[0.5711071  0.42889288]\n",
      " [0.5786027  0.4213973 ]\n",
      " [0.56905174 0.4309483 ]\n",
      " [0.6109412  0.38905883]\n",
      " [0.58539784 0.41460213]\n",
      " [0.5467439  0.4532561 ]\n",
      " [0.52397335 0.47602668]\n",
      " [0.5088192  0.49118084]\n",
      " [0.52228016 0.47771984]\n",
      " [0.62580156 0.37419847]\n",
      " [0.58382314 0.41617683]\n",
      " [0.6232514  0.37674865]\n",
      " [0.55658746 0.44341254]\n",
      " [0.5931774  0.4068226 ]\n",
      " [0.5771294  0.42287058]\n",
      " [0.6145575  0.38544253]\n",
      " [0.49803102 0.501969  ]\n",
      " [0.4617925  0.5382075 ]\n",
      " [0.6092539  0.3907461 ]\n",
      " [0.57328993 0.42671007]\n",
      " [0.5997144  0.4002856 ]\n",
      " [0.6511838  0.34881628]\n",
      " [0.6139261  0.38607392]\n",
      " [0.49726418 0.5027358 ]\n",
      " [0.5315606  0.4684394 ]\n",
      " [0.60653293 0.39346707]\n",
      " [0.5437617  0.45623836]\n",
      " [0.65646213 0.34353787]\n",
      " [0.55771935 0.44228062]\n",
      " [0.55244124 0.44755873]\n",
      " [0.46231288 0.5376871 ]\n",
      " [0.46498504 0.5350149 ]\n",
      " [0.669112   0.330888  ]\n",
      " [0.49150574 0.50849426]\n",
      " [0.5081967  0.4918033 ]\n",
      " [0.6537694  0.34623066]\n",
      " [0.6151089  0.38489106]\n",
      " [0.4945415  0.50545853]\n",
      " [0.56154925 0.43845078]\n",
      " [0.551317   0.44868302]\n",
      " [0.5941489  0.40585113]\n",
      " [0.587306   0.41269398]\n",
      " [0.58685493 0.4131451 ]\n",
      " [0.4257194  0.57428056]\n",
      " [0.5756998  0.42430016]\n",
      " [0.5060531  0.4939469 ]\n",
      " [0.578088   0.42191198]\n",
      " [0.5240391  0.47596088]\n",
      " [0.55392003 0.44607994]\n",
      " [0.5865158  0.41348425]\n",
      " [0.5549134  0.4450866 ]\n",
      " [0.4828741  0.51712596]\n",
      " [0.5149291  0.48507085]\n",
      " [0.58994436 0.41005558]\n",
      " [0.58483094 0.41516903]\n",
      " [0.61219317 0.38780683]\n",
      " [0.6041387  0.3958613 ]\n",
      " [0.4773916  0.5226084 ]\n",
      " [0.557544   0.442456  ]\n",
      " [0.5732336  0.4267664 ]\n",
      " [0.55287087 0.44712913]\n",
      " [0.5866033  0.41339675]\n",
      " [0.5906882  0.4093118 ]\n",
      " [0.5767352  0.4232648 ]]\n",
      "dgnn valid_hyps [[0.6143977  0.38560227]\n",
      " [0.6235724  0.37642762]\n",
      " [0.5102663  0.4897337 ]\n",
      " [0.4423012  0.5576988 ]\n",
      " [0.64374405 0.356256  ]\n",
      " [0.5914369  0.4085631 ]\n",
      " [0.5465938  0.4534062 ]\n",
      " [0.6165388  0.38346118]\n",
      " [0.5295863  0.47041366]\n",
      " [0.6364681  0.36353192]\n",
      " [0.5388353  0.4611647 ]\n",
      " [0.6051393  0.39486066]\n",
      " [0.5753272  0.42467275]\n",
      " [0.57928455 0.42071548]\n",
      " [0.5133602  0.48663977]\n",
      " [0.6645103  0.33548972]\n",
      " [0.5907129  0.4092871 ]\n",
      " [0.5388012  0.4611988 ]\n",
      " [0.5152147  0.48478532]\n",
      " [0.6314598  0.3685402 ]\n",
      " [0.6247687  0.37523127]\n",
      " [0.5468525  0.4531475 ]\n",
      " [0.59083045 0.40916952]\n",
      " [0.52487797 0.475122  ]\n",
      " [0.5941748  0.4058252 ]\n",
      " [0.6477343  0.35226572]\n",
      " [0.64302963 0.3569704 ]\n",
      " [0.62298447 0.37701553]\n",
      " [0.6154394  0.38456053]\n",
      " [0.65967166 0.34032828]\n",
      " [0.57529944 0.4247006 ]\n",
      " [0.6193779  0.38062206]\n",
      " [0.5309041  0.46909592]\n",
      " [0.61247635 0.3875237 ]\n",
      " [0.5621515  0.43784854]\n",
      " [0.60145783 0.39854214]\n",
      " [0.5158667  0.48413333]\n",
      " [0.66439897 0.33560106]\n",
      " [0.4188231  0.58117694]\n",
      " [0.5998079  0.40019202]\n",
      " [0.58120036 0.41879967]\n",
      " [0.58270556 0.4172944 ]\n",
      " [0.58035153 0.41964844]\n",
      " [0.54807514 0.45192486]\n",
      " [0.53016245 0.46983752]\n",
      " [0.5983773  0.40162268]\n",
      " [0.68022543 0.31977454]\n",
      " [0.50594395 0.49405605]\n",
      " [0.63403773 0.36596227]\n",
      " [0.5842659  0.41573408]\n",
      " [0.66826993 0.33173007]\n",
      " [0.6149579  0.38504207]\n",
      " [0.6221513  0.3778487 ]\n",
      " [0.6704897  0.32951033]\n",
      " [0.6170382  0.38296184]\n",
      " [0.602621   0.39737898]\n",
      " [0.632177   0.36782306]\n",
      " [0.6225677  0.37743226]\n",
      " [0.59788454 0.40211552]\n",
      " [0.61163676 0.3883632 ]\n",
      " [0.53271586 0.46728414]\n",
      " [0.5819299  0.4180701 ]\n",
      " [0.4948367  0.5051633 ]\n",
      " [0.63304824 0.3669518 ]]\n",
      "dgnn Epoch 3: train_loss:  0.67 train_recall: 0.6943 train_precision: 0.7006  train_f1: 0.6948  valid_loss:  0.63  valid_recall: 0.6330 valid_precision: 0.6165 valid_f1: 0.6235\n",
      "Warming up until epoch 5\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d8ad2fc7724defaef807f7e52cc6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='TRAIN', max=16, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn train loss 0.6621484756469727\n",
      "dgnn train loss 0.6722412109375\n",
      "dgnn train loss 0.67145836353302\n",
      "dgnn train loss 0.6682615876197815\n",
      "dgnn train loss 0.6752366423606873\n",
      "dgnn train loss 0.6744804978370667\n",
      "dgnn train loss 0.6706343293190002\n",
      "dgnn train loss 0.6576984524726868\n",
      "dgnn train loss 0.6754196882247925\n",
      "dgnn train loss 0.6622290015220642\n",
      "dgnn train loss 0.6639038920402527\n",
      "dgnn train loss 0.6792457103729248\n",
      "dgnn train loss 0.6485561728477478\n",
      "dgnn train loss 0.6866061687469482\n",
      "dgnn train loss 0.6645904779434204\n",
      "dgnn train loss 0.6661160588264465\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae0f32cceb343fca2628df23c59e148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='VALID', max=8, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dgnn train_hyps [[0.5711071  0.42889288]\n",
      " [0.5786027  0.4213973 ]\n",
      " [0.56905174 0.43094823]\n",
      " [0.6109413  0.38905865]\n",
      " [0.5853979  0.4146021 ]\n",
      " [0.5467438  0.45325616]\n",
      " [0.5239732  0.47602677]\n",
      " [0.50881904 0.49118093]\n",
      " [0.52228004 0.47771996]\n",
      " [0.6258016  0.37419838]\n",
      " [0.5838232  0.41617677]\n",
      " [0.62325156 0.3767485 ]\n",
      " [0.55658746 0.44341257]\n",
      " [0.5931775  0.4068225 ]\n",
      " [0.5771295  0.42287052]\n",
      " [0.6145576  0.38544238]\n",
      " [0.49803084 0.5019692 ]\n",
      " [0.46179223 0.53820777]\n",
      " [0.60925394 0.39074603]\n",
      " [0.57328993 0.42671004]\n",
      " [0.5997144  0.40028557]\n",
      " [0.65118396 0.34881604]\n",
      " [0.61392623 0.3860738 ]\n",
      " [0.49726406 0.5027359 ]\n",
      " [0.5315605  0.4684395 ]\n",
      " [0.60653305 0.39346698]\n",
      " [0.54376155 0.45623845]\n",
      " [0.6564623  0.34353772]\n",
      " [0.55771935 0.44228065]\n",
      " [0.5524412  0.4475588 ]\n",
      " [0.4623126  0.5376874 ]\n",
      " [0.46498477 0.53501517]\n",
      " [0.66911227 0.33088773]\n",
      " [0.49150556 0.5084945 ]\n",
      " [0.5081966  0.4918034 ]\n",
      " [0.6537695  0.3462305 ]\n",
      " [0.615109   0.38489097]\n",
      " [0.49454132 0.50545865]\n",
      " [0.5615492  0.43845087]\n",
      " [0.5513169  0.44868305]\n",
      " [0.59414893 0.40585104]\n",
      " [0.5873061  0.41269392]\n",
      " [0.58685493 0.413145  ]\n",
      " [0.42571905 0.574281  ]\n",
      " [0.5756998  0.42430016]\n",
      " [0.506053   0.4939471 ]\n",
      " [0.57808805 0.42191198]\n",
      " [0.52403903 0.47596103]\n",
      " [0.55392003 0.44608   ]\n",
      " [0.5865157  0.41348425]\n",
      " [0.55491334 0.44508666]\n",
      " [0.4828738  0.5171262 ]\n",
      " [0.514929   0.48507103]\n",
      " [0.5899445  0.41005552]\n",
      " [0.584831   0.41516903]\n",
      " [0.6121933  0.38780668]\n",
      " [0.60413885 0.39586118]\n",
      " [0.47739136 0.52260864]\n",
      " [0.557544   0.44245607]\n",
      " [0.5732336  0.4267664 ]\n",
      " [0.5528708  0.44712916]\n",
      " [0.5866033  0.41339672]\n",
      " [0.5906882  0.40931177]\n",
      " [0.5767352  0.42326477]]\n",
      "dgnn valid_hyps [[0.61439776 0.38560224]\n",
      " [0.62357235 0.37642762]\n",
      " [0.51026624 0.4897337 ]\n",
      " [0.4423012  0.5576988 ]\n",
      " [0.64374405 0.356256  ]\n",
      " [0.5914369  0.4085631 ]\n",
      " [0.5465938  0.4534062 ]\n",
      " [0.61653876 0.3834612 ]\n",
      " [0.5295863  0.47041366]\n",
      " [0.6364681  0.36353186]\n",
      " [0.5388353  0.4611647 ]\n",
      " [0.6051393  0.39486066]\n",
      " [0.5753272  0.42467278]\n",
      " [0.57928455 0.42071548]\n",
      " [0.5133602  0.48663977]\n",
      " [0.6645103  0.33548972]\n",
      " [0.5907129  0.4092871 ]\n",
      " [0.5388012  0.46119878]\n",
      " [0.51521474 0.4847853 ]\n",
      " [0.63145983 0.3685402 ]\n",
      " [0.6247687  0.37523133]\n",
      " [0.5468525  0.45314753]\n",
      " [0.59083045 0.40916952]\n",
      " [0.52487797 0.47512203]\n",
      " [0.59417486 0.4058252 ]\n",
      " [0.64773434 0.3522657 ]\n",
      " [0.64302963 0.3569704 ]\n",
      " [0.62298447 0.37701553]\n",
      " [0.6154394  0.38456053]\n",
      " [0.65967166 0.34032828]\n",
      " [0.5752994  0.4247006 ]\n",
      " [0.6193779  0.38062206]\n",
      " [0.5309041  0.4690959 ]\n",
      " [0.61247635 0.3875237 ]\n",
      " [0.5621515  0.43784854]\n",
      " [0.60145783 0.39854217]\n",
      " [0.5158667  0.48413333]\n",
      " [0.66439897 0.33560103]\n",
      " [0.41882306 0.58117694]\n",
      " [0.5998079  0.40019202]\n",
      " [0.58120036 0.41879967]\n",
      " [0.5827056  0.4172944 ]\n",
      " [0.58035153 0.41964844]\n",
      " [0.54807514 0.45192483]\n",
      " [0.53016245 0.46983755]\n",
      " [0.5983773  0.40162268]\n",
      " [0.68022543 0.31977457]\n",
      " [0.50594395 0.49405605]\n",
      " [0.63403773 0.36596224]\n",
      " [0.5842659  0.41573408]\n",
      " [0.66826993 0.33173007]\n",
      " [0.6149579  0.38504207]\n",
      " [0.62215126 0.37784874]\n",
      " [0.6704897  0.32951033]\n",
      " [0.6170382  0.38296187]\n",
      " [0.602621   0.39737898]\n",
      " [0.63217694 0.36782306]\n",
      " [0.6225677  0.37743226]\n",
      " [0.59788454 0.40211552]\n",
      " [0.61163676 0.3883632 ]\n",
      " [0.53271586 0.46728414]\n",
      " [0.5819299  0.41807014]\n",
      " [0.4948367  0.5051633 ]\n",
      " [0.63304824 0.3669518 ]]\n",
      "dgnn Epoch 4: train_loss:  0.67 train_recall: 0.6943 train_precision: 0.7006  train_f1: 0.6948  valid_loss:  0.63  valid_recall: 0.6330 valid_precision: 0.6165 valid_f1: 0.6235\n",
      "Warming up until epoch 5\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f523c991669442d1a86e0b64d92193c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='TRAIN', max=16, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn train loss 0.6621484756469727\n",
      "dgnn train loss 0.6722412109375\n",
      "dgnn train loss 0.67145836353302\n",
      "dgnn train loss 0.6682615876197815\n",
      "dgnn train loss 0.6752366423606873\n",
      "dgnn train loss 0.6744804978370667\n",
      "dgnn train loss 0.6706343293190002\n",
      "dgnn train loss 0.6576984524726868\n",
      "dgnn train loss 0.6754196882247925\n",
      "dgnn train loss 0.6622289419174194\n",
      "dgnn train loss 0.6639038920402527\n",
      "dgnn train loss 0.6792457103729248\n",
      "dgnn train loss 0.648556113243103\n",
      "dgnn train loss 0.6866061687469482\n",
      "dgnn train loss 0.66459059715271\n",
      "dgnn train loss 0.6661160588264465\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b54c151b86a42e9a9d55ead25a3f04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='VALID', max=8, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dgnn train_hyps [[0.5711071  0.42889288]\n",
      " [0.5786027  0.4213973 ]\n",
      " [0.56905174 0.43094823]\n",
      " [0.6109413  0.38905865]\n",
      " [0.5853979  0.4146021 ]\n",
      " [0.5467438  0.45325616]\n",
      " [0.5239732  0.47602677]\n",
      " [0.50881904 0.49118093]\n",
      " [0.52228004 0.47771996]\n",
      " [0.6258016  0.37419838]\n",
      " [0.5838232  0.41617677]\n",
      " [0.62325156 0.3767485 ]\n",
      " [0.55658746 0.44341257]\n",
      " [0.5931775  0.4068225 ]\n",
      " [0.5771295  0.42287052]\n",
      " [0.6145576  0.38544238]\n",
      " [0.49803084 0.5019692 ]\n",
      " [0.46179223 0.5382077 ]\n",
      " [0.609254   0.390746  ]\n",
      " [0.57328993 0.42671004]\n",
      " [0.5997144  0.4002856 ]\n",
      " [0.65118396 0.34881604]\n",
      " [0.61392623 0.38607374]\n",
      " [0.4972641  0.5027359 ]\n",
      " [0.5315605  0.4684395 ]\n",
      " [0.606533   0.393467  ]\n",
      " [0.54376155 0.45623845]\n",
      " [0.6564623  0.34353772]\n",
      " [0.55771935 0.44228065]\n",
      " [0.5524412  0.4475588 ]\n",
      " [0.4623126  0.53768736]\n",
      " [0.46498477 0.53501517]\n",
      " [0.66911227 0.33088773]\n",
      " [0.49150556 0.5084945 ]\n",
      " [0.5081966  0.4918034 ]\n",
      " [0.6537695  0.34623045]\n",
      " [0.615109   0.38489094]\n",
      " [0.49454132 0.50545865]\n",
      " [0.5615492  0.43845087]\n",
      " [0.5513169  0.44868305]\n",
      " [0.59414893 0.40585104]\n",
      " [0.5873061  0.41269392]\n",
      " [0.58685493 0.413145  ]\n",
      " [0.42571908 0.574281  ]\n",
      " [0.5756998  0.42430016]\n",
      " [0.5060529  0.4939471 ]\n",
      " [0.57808805 0.42191198]\n",
      " [0.52403903 0.47596103]\n",
      " [0.55392003 0.44608   ]\n",
      " [0.5865158  0.41348422]\n",
      " [0.55491334 0.44508666]\n",
      " [0.48287383 0.51712614]\n",
      " [0.514929   0.48507103]\n",
      " [0.5899445  0.41005552]\n",
      " [0.584831   0.41516903]\n",
      " [0.6121933  0.38780668]\n",
      " [0.60413885 0.39586118]\n",
      " [0.4773914  0.5226086 ]\n",
      " [0.557544   0.44245607]\n",
      " [0.5732336  0.4267664 ]\n",
      " [0.5528708  0.44712916]\n",
      " [0.5866033  0.41339672]\n",
      " [0.5906882  0.40931177]\n",
      " [0.5767352  0.42326477]]\n",
      "dgnn valid_hyps [[0.6143977  0.38560224]\n",
      " [0.62357235 0.37642762]\n",
      " [0.51026624 0.4897337 ]\n",
      " [0.4423012  0.5576988 ]\n",
      " [0.643744   0.356256  ]\n",
      " [0.5914369  0.4085631 ]\n",
      " [0.5465938  0.4534062 ]\n",
      " [0.61653876 0.3834612 ]\n",
      " [0.5295863  0.47041366]\n",
      " [0.6364681  0.36353186]\n",
      " [0.5388353  0.4611647 ]\n",
      " [0.6051393  0.39486066]\n",
      " [0.5753272  0.42467278]\n",
      " [0.5792845  0.42071548]\n",
      " [0.5133602  0.48663977]\n",
      " [0.6645103  0.33548972]\n",
      " [0.5907129  0.4092871 ]\n",
      " [0.5388012  0.46119878]\n",
      " [0.5152146  0.48478538]\n",
      " [0.63145983 0.3685402 ]\n",
      " [0.6247687  0.37523133]\n",
      " [0.5468525  0.4531475 ]\n",
      " [0.59083045 0.40916952]\n",
      " [0.52487797 0.475122  ]\n",
      " [0.5941748  0.4058252 ]\n",
      " [0.6477343  0.35226572]\n",
      " [0.64302963 0.3569704 ]\n",
      " [0.62298447 0.37701553]\n",
      " [0.6154395  0.38456053]\n",
      " [0.65967166 0.34032828]\n",
      " [0.57529944 0.4247006 ]\n",
      " [0.619378   0.38062203]\n",
      " [0.5309041  0.4690959 ]\n",
      " [0.6124763  0.3875237 ]\n",
      " [0.5621515  0.43784854]\n",
      " [0.60145783 0.39854217]\n",
      " [0.5158667  0.48413333]\n",
      " [0.66439897 0.33560103]\n",
      " [0.4188231  0.58117694]\n",
      " [0.5998079  0.40019202]\n",
      " [0.58120036 0.41879967]\n",
      " [0.58270556 0.4172944 ]\n",
      " [0.58035153 0.41964844]\n",
      " [0.54807514 0.45192486]\n",
      " [0.53016245 0.46983752]\n",
      " [0.5983773  0.40162268]\n",
      " [0.68022543 0.31977457]\n",
      " [0.50594395 0.49405605]\n",
      " [0.63403773 0.36596227]\n",
      " [0.5842659  0.4157341 ]\n",
      " [0.66826993 0.33173007]\n",
      " [0.6149579  0.38504207]\n",
      " [0.6221512  0.37784874]\n",
      " [0.6704897  0.32951033]\n",
      " [0.61703813 0.38296187]\n",
      " [0.602621   0.39737898]\n",
      " [0.632177   0.367823  ]\n",
      " [0.6225677  0.37743226]\n",
      " [0.59788454 0.40211552]\n",
      " [0.6116369  0.38836318]\n",
      " [0.53271586 0.46728414]\n",
      " [0.5819299  0.4180701 ]\n",
      " [0.4948367  0.5051633 ]\n",
      " [0.63304824 0.3669518 ]]\n",
      "dgnn Epoch 5: train_loss:  0.67 train_recall: 0.6943 train_precision: 0.7006  train_f1: 0.6948  valid_loss:  0.63  valid_recall: 0.6330 valid_precision: 0.6165 valid_f1: 0.6235\n",
      "Warming up until epoch 5\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f281556e2d7b4f238df841af0cbe19d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='TRAIN', max=16, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn train loss 0.6621484756469727\n",
      "dgnn train loss 0.6722412109375\n",
      "dgnn train loss 0.67145836353302\n",
      "dgnn train loss 0.6682616472244263\n",
      "dgnn train loss 0.6752366423606873\n",
      "dgnn train loss 0.6744804978370667\n",
      "dgnn train loss 0.6706343293190002\n",
      "dgnn train loss 0.6576984524726868\n",
      "dgnn train loss 0.6754196882247925\n",
      "dgnn train loss 0.6622290015220642\n",
      "dgnn train loss 0.6639038920402527\n",
      "dgnn train loss 0.6792457103729248\n",
      "dgnn train loss 0.6485561728477478\n",
      "dgnn train loss 0.6866061687469482\n",
      "dgnn train loss 0.66459059715271\n",
      "dgnn train loss 0.6661160588264465\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbec4bcb7644a4ebf64ef620bd084f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='VALID', max=8, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dgnn train_hyps [[0.5711071  0.42889288]\n",
      " [0.5786027  0.4213973 ]\n",
      " [0.56905174 0.43094823]\n",
      " [0.6109413  0.38905865]\n",
      " [0.5853979  0.4146021 ]\n",
      " [0.5467438  0.45325616]\n",
      " [0.52397317 0.4760268 ]\n",
      " [0.50881904 0.49118093]\n",
      " [0.52228004 0.47771996]\n",
      " [0.6258016  0.37419838]\n",
      " [0.5838232  0.41617677]\n",
      " [0.62325144 0.3767485 ]\n",
      " [0.55658746 0.44341257]\n",
      " [0.5931775  0.4068225 ]\n",
      " [0.5771295  0.42287052]\n",
      " [0.6145576  0.38544238]\n",
      " [0.49803084 0.5019692 ]\n",
      " [0.46179223 0.5382077 ]\n",
      " [0.60925394 0.39074603]\n",
      " [0.57328993 0.42671004]\n",
      " [0.5997144  0.4002856 ]\n",
      " [0.65118396 0.34881604]\n",
      " [0.61392623 0.3860738 ]\n",
      " [0.4972641  0.5027359 ]\n",
      " [0.5315605  0.4684395 ]\n",
      " [0.606533   0.393467  ]\n",
      " [0.54376155 0.45623845]\n",
      " [0.6564623  0.34353772]\n",
      " [0.55771935 0.44228065]\n",
      " [0.5524412  0.4475588 ]\n",
      " [0.4623126  0.5376874 ]\n",
      " [0.4649848  0.53501517]\n",
      " [0.66911227 0.33088773]\n",
      " [0.49150556 0.5084945 ]\n",
      " [0.5081966  0.4918034 ]\n",
      " [0.6537695  0.34623045]\n",
      " [0.6151091  0.38489094]\n",
      " [0.49454132 0.5054587 ]\n",
      " [0.5615492  0.43845087]\n",
      " [0.5513169  0.44868305]\n",
      " [0.59414893 0.40585104]\n",
      " [0.5873061  0.41269392]\n",
      " [0.58685493 0.413145  ]\n",
      " [0.42571905 0.574281  ]\n",
      " [0.5756998  0.42430016]\n",
      " [0.506053   0.4939471 ]\n",
      " [0.57808805 0.42191198]\n",
      " [0.52403903 0.47596103]\n",
      " [0.55392003 0.44608   ]\n",
      " [0.5865157  0.41348428]\n",
      " [0.55491334 0.44508666]\n",
      " [0.4828738  0.5171262 ]\n",
      " [0.51492894 0.48507106]\n",
      " [0.5899445  0.41005552]\n",
      " [0.584831   0.41516903]\n",
      " [0.61219335 0.38780665]\n",
      " [0.60413885 0.39586118]\n",
      " [0.47739136 0.52260864]\n",
      " [0.557544   0.44245607]\n",
      " [0.5732336  0.4267664 ]\n",
      " [0.5528708  0.44712916]\n",
      " [0.5866033  0.41339672]\n",
      " [0.5906882  0.4093118 ]\n",
      " [0.5767352  0.42326477]]\n",
      "dgnn valid_hyps [[0.6143977  0.38560224]\n",
      " [0.62357235 0.37642762]\n",
      " [0.5102663  0.4897337 ]\n",
      " [0.4423012  0.5576988 ]\n",
      " [0.643744   0.356256  ]\n",
      " [0.5914369  0.4085631 ]\n",
      " [0.5465938  0.4534062 ]\n",
      " [0.61653876 0.3834612 ]\n",
      " [0.5295864  0.47041366]\n",
      " [0.6364681  0.36353186]\n",
      " [0.5388353  0.4611647 ]\n",
      " [0.6051393  0.39486066]\n",
      " [0.5753272  0.42467278]\n",
      " [0.57928455 0.42071548]\n",
      " [0.5133602  0.48663977]\n",
      " [0.6645103  0.33548972]\n",
      " [0.5907129  0.4092871 ]\n",
      " [0.5388012  0.4611988 ]\n",
      " [0.5152147  0.48478532]\n",
      " [0.63145983 0.3685402 ]\n",
      " [0.6247687  0.37523133]\n",
      " [0.5468525  0.45314753]\n",
      " [0.59083045 0.40916952]\n",
      " [0.52487797 0.47512203]\n",
      " [0.59417486 0.4058252 ]\n",
      " [0.6477343  0.35226572]\n",
      " [0.64302963 0.3569704 ]\n",
      " [0.62298447 0.37701553]\n",
      " [0.6154394  0.38456053]\n",
      " [0.65967166 0.34032828]\n",
      " [0.57529944 0.4247006 ]\n",
      " [0.619378   0.38062203]\n",
      " [0.5309041  0.4690959 ]\n",
      " [0.6124763  0.3875237 ]\n",
      " [0.5621515  0.43784854]\n",
      " [0.60145783 0.39854217]\n",
      " [0.5158667  0.48413336]\n",
      " [0.66439897 0.33560103]\n",
      " [0.41882306 0.58117694]\n",
      " [0.5998079  0.40019205]\n",
      " [0.58120036 0.41879967]\n",
      " [0.5827056  0.4172944 ]\n",
      " [0.58035153 0.41964844]\n",
      " [0.54807514 0.45192483]\n",
      " [0.5301625  0.4698375 ]\n",
      " [0.5983773  0.40162268]\n",
      " [0.68022543 0.31977457]\n",
      " [0.50594395 0.49405605]\n",
      " [0.63403773 0.36596227]\n",
      " [0.5842659  0.41573408]\n",
      " [0.66826993 0.3317301 ]\n",
      " [0.6149579  0.38504207]\n",
      " [0.62215126 0.37784874]\n",
      " [0.6704897  0.3295103 ]\n",
      " [0.6170382  0.38296187]\n",
      " [0.602621   0.39737898]\n",
      " [0.632177   0.36782306]\n",
      " [0.6225677  0.37743226]\n",
      " [0.59788454 0.40211552]\n",
      " [0.61163676 0.3883632 ]\n",
      " [0.53271586 0.46728414]\n",
      " [0.5819299  0.4180701 ]\n",
      " [0.4948367  0.5051633 ]\n",
      " [0.63304824 0.36695173]]\n",
      "dgnn Epoch 6: train_loss:  0.67 train_recall: 0.6943 train_precision: 0.7006  train_f1: 0.6948  valid_loss:  0.63  valid_recall: 0.6330 valid_precision: 0.6165 valid_f1: 0.6235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f10fd4fbbb547e4b64a94e73d1b6e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='TRAIN', max=16, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn train loss 0.6621484756469727\n",
      "dgnn train loss 0.6722412109375\n",
      "dgnn train loss 0.67145836353302\n",
      "dgnn train loss 0.6682616472244263\n",
      "dgnn train loss 0.6752366423606873\n",
      "dgnn train loss 0.6744804978370667\n",
      "dgnn train loss 0.6706343293190002\n",
      "dgnn train loss 0.6576984524726868\n",
      "dgnn train loss 0.6754196882247925\n",
      "dgnn train loss 0.6622290015220642\n",
      "dgnn train loss 0.6639038324356079\n",
      "dgnn train loss 0.6792457103729248\n",
      "dgnn train loss 0.6485561728477478\n",
      "dgnn train loss 0.6866061687469482\n",
      "dgnn train loss 0.66459059715271\n",
      "dgnn train loss 0.6661160588264465\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339fdd214a6349af95ae4678e362e67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='VALID', max=8, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dgnn train_hyps [[0.5711071  0.42889288]\n",
      " [0.5786027  0.4213973 ]\n",
      " [0.56905174 0.43094823]\n",
      " [0.61094135 0.38905865]\n",
      " [0.5853979  0.4146021 ]\n",
      " [0.5467438  0.45325616]\n",
      " [0.5239732  0.47602677]\n",
      " [0.50881904 0.49118093]\n",
      " [0.52228004 0.47771996]\n",
      " [0.6258016  0.37419838]\n",
      " [0.5838232  0.41617677]\n",
      " [0.62325156 0.3767485 ]\n",
      " [0.55658746 0.44341257]\n",
      " [0.5931775  0.40682256]\n",
      " [0.5771295  0.42287052]\n",
      " [0.6145576  0.3854424 ]\n",
      " [0.49803084 0.5019692 ]\n",
      " [0.46179223 0.53820777]\n",
      " [0.609254   0.390746  ]\n",
      " [0.57328993 0.42671004]\n",
      " [0.5997144  0.4002856 ]\n",
      " [0.65118396 0.34881604]\n",
      " [0.61392623 0.38607374]\n",
      " [0.4972641  0.5027359 ]\n",
      " [0.5315605  0.4684395 ]\n",
      " [0.60653305 0.39346698]\n",
      " [0.54376155 0.45623845]\n",
      " [0.6564623  0.34353772]\n",
      " [0.55771935 0.44228065]\n",
      " [0.5524412  0.4475588 ]\n",
      " [0.4623126  0.53768736]\n",
      " [0.46498477 0.53501517]\n",
      " [0.66911227 0.33088773]\n",
      " [0.49150556 0.5084945 ]\n",
      " [0.5081966  0.49180344]\n",
      " [0.6537695  0.3462305 ]\n",
      " [0.6151091  0.3848909 ]\n",
      " [0.49454132 0.50545865]\n",
      " [0.5615492  0.43845087]\n",
      " [0.5513169  0.44868305]\n",
      " [0.59414893 0.40585104]\n",
      " [0.5873061  0.41269392]\n",
      " [0.58685493 0.413145  ]\n",
      " [0.42571908 0.574281  ]\n",
      " [0.5756998  0.42430016]\n",
      " [0.506053   0.4939471 ]\n",
      " [0.57808805 0.42191198]\n",
      " [0.524039   0.47596103]\n",
      " [0.55392003 0.44608   ]\n",
      " [0.5865158  0.41348425]\n",
      " [0.55491334 0.44508666]\n",
      " [0.48287383 0.51712614]\n",
      " [0.51492894 0.48507106]\n",
      " [0.5899445  0.41005552]\n",
      " [0.584831   0.41516903]\n",
      " [0.61219335 0.38780665]\n",
      " [0.60413885 0.39586118]\n",
      " [0.4773914  0.5226086 ]\n",
      " [0.557544   0.44245607]\n",
      " [0.5732336  0.4267664 ]\n",
      " [0.5528708  0.44712916]\n",
      " [0.5866033  0.41339672]\n",
      " [0.5906882  0.4093118 ]\n",
      " [0.5767352  0.42326477]]\n",
      "dgnn valid_hyps [[0.6143977  0.38560224]\n",
      " [0.6235724  0.37642762]\n",
      " [0.51026624 0.4897337 ]\n",
      " [0.4423012  0.55769885]\n",
      " [0.643744   0.356256  ]\n",
      " [0.5914369  0.40856305]\n",
      " [0.5465938  0.4534062 ]\n",
      " [0.6165388  0.38346118]\n",
      " [0.5295863  0.47041366]\n",
      " [0.6364681  0.36353186]\n",
      " [0.5388353  0.4611647 ]\n",
      " [0.6051393  0.39486066]\n",
      " [0.5753272  0.42467275]\n",
      " [0.57928455 0.42071548]\n",
      " [0.5133602  0.4866398 ]\n",
      " [0.66451025 0.33548975]\n",
      " [0.5907129  0.4092871 ]\n",
      " [0.5388012  0.4611988 ]\n",
      " [0.5152147  0.48478532]\n",
      " [0.63145983 0.3685402 ]\n",
      " [0.6247687  0.37523133]\n",
      " [0.5468525  0.45314753]\n",
      " [0.59083045 0.40916952]\n",
      " [0.52487797 0.475122  ]\n",
      " [0.5941748  0.4058252 ]\n",
      " [0.6477343  0.35226572]\n",
      " [0.64302963 0.3569704 ]\n",
      " [0.62298447 0.37701553]\n",
      " [0.6154395  0.38456053]\n",
      " [0.65967166 0.34032828]\n",
      " [0.5752994  0.4247006 ]\n",
      " [0.619378   0.38062203]\n",
      " [0.5309041  0.4690959 ]\n",
      " [0.6124763  0.3875237 ]\n",
      " [0.5621515  0.43784854]\n",
      " [0.60145783 0.39854214]\n",
      " [0.5158667  0.48413336]\n",
      " [0.66439897 0.33560106]\n",
      " [0.4188231  0.5811769 ]\n",
      " [0.5998079  0.40019202]\n",
      " [0.58120036 0.41879967]\n",
      " [0.58270556 0.4172944 ]\n",
      " [0.58035153 0.41964844]\n",
      " [0.54807514 0.45192486]\n",
      " [0.53016245 0.46983755]\n",
      " [0.5983773  0.40162268]\n",
      " [0.68022543 0.31977457]\n",
      " [0.50594395 0.49405605]\n",
      " [0.63403773 0.36596227]\n",
      " [0.5842659  0.41573408]\n",
      " [0.66826993 0.3317301 ]\n",
      " [0.6149579  0.38504204]\n",
      " [0.6221512  0.37784874]\n",
      " [0.6704897  0.32951033]\n",
      " [0.61703813 0.38296187]\n",
      " [0.602621   0.39737898]\n",
      " [0.632177   0.36782306]\n",
      " [0.6225677  0.37743226]\n",
      " [0.59788454 0.4021155 ]\n",
      " [0.61163676 0.3883632 ]\n",
      " [0.53271586 0.46728414]\n",
      " [0.5819299  0.4180701 ]\n",
      " [0.4948367  0.5051633 ]\n",
      " [0.63304824 0.36695173]]\n",
      "dgnn Epoch 7: train_loss:  0.67 train_recall: 0.6943 train_precision: 0.7006  train_f1: 0.6948  valid_loss:  0.63  valid_recall: 0.6330 valid_precision: 0.6165 valid_f1: 0.6235\n",
      "EarlyStopping counter: 2 out of 10\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd86bab07bba4ef49fe8d1dba7c3daf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='TRAIN', max=16, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgnn train loss 0.6621484756469727\n",
      "dgnn train loss 0.6722412109375\n",
      "dgnn train loss 0.67145836353302\n",
      "dgnn train loss 0.6682616472244263\n",
      "dgnn train loss 0.6752366423606873\n",
      "dgnn train loss 0.6744804978370667\n",
      "dgnn train loss 0.6706343293190002\n",
      "dgnn train loss 0.6576984524726868\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-5f0c7996687e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TRAIN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmsgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train loss {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-7ff92985c683>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(data, model, optimizer, is_train)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx_t_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_t_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_s_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-a2a60a6d2002>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_s, edge_index_s, edge_attr_s, x_t, edge_index_t, edge_attr_t, x_s_batch, x_t_batch)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_s_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdecoder_input1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_s_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdecoder_input2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-776145f7c417>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0medge_index_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-776145f7c417>\u001b[0m in \u001b[0;36mpartition_graph\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartition_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnodes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# record all nodes number for each subgraph in total batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mgraph_pos_in_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_subgraph_info_from_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mmax_seq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0msubgraph_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide_node_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-776145f7c417>\u001b[0m in \u001b[0;36mget_subgraph_info_from_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mgraph_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# use a list to store the node nums in subgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0mgraph_pos_in_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mgraph_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epoches + 1):\n",
    "    train_loss = 0.\n",
    "    train_refs = []\n",
    "    train_hyps = []\n",
    "    valid_loss = 0.\n",
    "    valid_refs = []\n",
    "    valid_hyps = []\n",
    "\n",
    "    # train\n",
    "    model.train()\n",
    "    for data in tqdm(train_loader, total=len(train_loader), desc='TRAIN'):\n",
    "        loss, gold, pred = compute_loss(data, model, optimizer, is_train=True)\n",
    "        msgr.print_msg('train loss {}'.format(loss))\n",
    "        train_loss += loss\n",
    "        train_refs.append(gold)\n",
    "        train_hyps.append(pred)\n",
    "    \n",
    "\n",
    "    # valid\n",
    "    model.eval()\n",
    "    for data in tqdm(valid_loader, total=len(valid_loader), desc='VALID'):\n",
    "        loss, gold, pred = compute_loss(data, model, optimizer, is_train=False)\n",
    "        # msgr.print_msg('valid loss {}'.format(loss))\n",
    "        valid_loss += loss\n",
    "        valid_refs.append(gold)\n",
    "        valid_hyps.append(pred)\n",
    "    \n",
    "    \n",
    "    train_loss = np.sum(train_loss) / len(train_loader)\n",
    "    valid_loss = np.sum(valid_loss) / len(valid_loader)\n",
    "    \n",
    "    train_recall, train_precision, train_f1 = calculate(train_hyps, train_refs)\n",
    "    valid_recall, valid_precision, valid_f1 = calculate(valid_hyps, valid_refs)\n",
    "\n",
    "#     msgr.print_msg('train_hyps {}'.format(train_hyps[0]))\n",
    "#     msgr.print_msg('valid_hyps {}'.format(valid_hyps[0]))\n",
    "\n",
    "\n",
    "    msgr.print_msg('Epoch {}: train_loss: {:5.2f} train_recall: {:2.4f} train_precision: {:2.4f}  train_f1: {:2.4f}  valid_loss: {:5.2f}  valid_recall: {:2.4f} valid_precision: {:2.4f} valid_f1: {:2.4f}'.format(\n",
    "            epoch, train_loss, train_recall, train_precision, train_f1, valid_loss, valid_recall, valid_precision, valid_f1))\n",
    "    \n",
    "    early_stopping(valid_f1, model, epoch)\n",
    "    if early_stopping.early_stop:\n",
    "        msgr.print_msg(\"Early stopping\")\n",
    "        break  \n",
    "        \n",
    "    print('-'*80)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
